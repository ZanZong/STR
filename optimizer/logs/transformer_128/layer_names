transformer/mul
transformer/add
transformer/dropout/mul
transformer/dropout/mul_1
transformer/multi_head_attention/Reshape
transformer/multi_head_attention/MatMul
transformer/multi_head_attention/Reshape_2
transformer/multi_head_attention/MatMul_1
transformer/multi_head_attention/Reshape_5
transformer/multi_head_attention/MatMul_2
transformer/multi_head_attention/Reshape_8
transformer/multi_head_attention/split
transformer/multi_head_attention/concat
transformer/multi_head_attention/split_1
transformer/multi_head_attention/concat_1
transformer/multi_head_attention/split_2
transformer/multi_head_attention/concat_2
transformer/multi_head_attention/split_3
transformer/multi_head_attention/concat_3
transformer/add_1
transformer/layer_normalization/beta
transformer/layer_normalization/gamma
transformer/layer_normalization/sub
transformer/layer_normalization/add
transformer/layer_normalization/pow
transformer/layer_normalization/add_1
transformer/position_wise_feed_forward/weights_inner
transformer/position_wise_feed_forward/weights_out
transformer/position_wise_feed_forward/bias_inner
transformer/position_wise_feed_forward/bias_out
transformer/position_wise_feed_forward/Reshape
transformer/position_wise_feed_forward/MatMul
transformer/position_wise_feed_forward/Reshape_2
transformer/position_wise_feed_forward/add
transformer/position_wise_feed_forward/Relu
transformer/position_wise_feed_forward/Reshape_3
transformer/position_wise_feed_forward/MatMul_1
transformer/position_wise_feed_forward/Reshape_5
transformer/position_wise_feed_forward/add_1
transformer/add_2
transformer/layer_normalization_8/beta
transformer/layer_normalization_8/gamma
transformer/layer_normalization_8/sub
transformer/layer_normalization_8/add
transformer/layer_normalization_8/pow
transformer/layer_normalization_8/add_1
transformer/multi_head_attention_1/Reshape
transformer/multi_head_attention_1/MatMul
transformer/multi_head_attention_1/Reshape_2
transformer/multi_head_attention_1/MatMul_1
transformer/multi_head_attention_1/Reshape_5
transformer/multi_head_attention_1/MatMul_2
transformer/multi_head_attention_1/Reshape_8
transformer/multi_head_attention_1/split
transformer/multi_head_attention_1/concat
transformer/multi_head_attention_1/split_1
transformer/multi_head_attention_1/concat_1
transformer/multi_head_attention_1/split_2
transformer/multi_head_attention_1/concat_2
transformer/multi_head_attention_1/split_3
transformer/multi_head_attention_1/concat_3
transformer/add_3
transformer/layer_normalization_1/beta
transformer/layer_normalization_1/gamma
transformer/layer_normalization_1/sub
transformer/layer_normalization_1/add
transformer/layer_normalization_1/pow
transformer/layer_normalization_1/add_1
transformer/position_wise_feed_forward_1/weights_inner
transformer/position_wise_feed_forward_1/weights_out
transformer/position_wise_feed_forward_1/bias_inner
transformer/position_wise_feed_forward_1/bias_out
transformer/position_wise_feed_forward_1/Reshape
transformer/position_wise_feed_forward_1/MatMul
transformer/position_wise_feed_forward_1/Reshape_2
transformer/position_wise_feed_forward_1/add
transformer/position_wise_feed_forward_1/Relu
transformer/position_wise_feed_forward_1/Reshape_3
transformer/position_wise_feed_forward_1/MatMul_1
transformer/position_wise_feed_forward_1/Reshape_5
transformer/position_wise_feed_forward_1/add_1
transformer/add_4
transformer/layer_normalization_9/beta
transformer/layer_normalization_9/gamma
transformer/layer_normalization_9/sub
transformer/layer_normalization_9/add
transformer/layer_normalization_9/pow
transformer/layer_normalization_9/add_1
transformer/multi_head_attention_2/Reshape
transformer/multi_head_attention_2/MatMul
transformer/multi_head_attention_2/Reshape_2
transformer/multi_head_attention_2/MatMul_1
transformer/multi_head_attention_2/Reshape_5
transformer/multi_head_attention_2/MatMul_2
transformer/multi_head_attention_2/Reshape_8
transformer/multi_head_attention_2/split
transformer/multi_head_attention_2/concat
transformer/multi_head_attention_2/split_1
transformer/multi_head_attention_2/concat_1
transformer/multi_head_attention_2/split_2
transformer/multi_head_attention_2/concat_2
transformer/multi_head_attention_2/split_3
transformer/multi_head_attention_2/concat_3
transformer/add_5
transformer/layer_normalization_2/beta
transformer/layer_normalization_2/gamma
transformer/layer_normalization_2/sub
transformer/layer_normalization_2/add
transformer/layer_normalization_2/pow
transformer/layer_normalization_2/add_1
transformer/position_wise_feed_forward_2/weights_inner
transformer/position_wise_feed_forward_2/weights_out
transformer/position_wise_feed_forward_2/bias_inner
transformer/position_wise_feed_forward_2/bias_out
transformer/position_wise_feed_forward_2/Reshape
transformer/position_wise_feed_forward_2/MatMul
transformer/position_wise_feed_forward_2/Reshape_2
transformer/position_wise_feed_forward_2/add
transformer/position_wise_feed_forward_2/Relu
transformer/position_wise_feed_forward_2/Reshape_3
transformer/position_wise_feed_forward_2/MatMul_1
transformer/position_wise_feed_forward_2/Reshape_5
transformer/position_wise_feed_forward_2/add_1
transformer/add_6
transformer/layer_normalization_10/beta
transformer/layer_normalization_10/gamma
transformer/layer_normalization_10/sub
transformer/layer_normalization_10/add
transformer/layer_normalization_10/pow
transformer/layer_normalization_10/add_1
transformer/multi_head_attention_3/Reshape
transformer/multi_head_attention_3/MatMul
transformer/multi_head_attention_3/Reshape_2
transformer/multi_head_attention_3/MatMul_1
transformer/multi_head_attention_3/Reshape_5
transformer/multi_head_attention_3/MatMul_2
transformer/multi_head_attention_3/Reshape_8
transformer/multi_head_attention_3/split
transformer/multi_head_attention_3/concat
transformer/multi_head_attention_3/split_1
transformer/multi_head_attention_3/concat_1
transformer/multi_head_attention_3/split_2
transformer/multi_head_attention_3/concat_2
transformer/multi_head_attention_3/split_3
transformer/multi_head_attention_3/concat_3
transformer/add_7
transformer/layer_normalization_3/beta
transformer/layer_normalization_3/gamma
transformer/layer_normalization_3/sub
transformer/layer_normalization_3/add
transformer/layer_normalization_3/pow
transformer/layer_normalization_3/add_1
transformer/position_wise_feed_forward_3/weights_inner
transformer/position_wise_feed_forward_3/weights_out
transformer/position_wise_feed_forward_3/bias_inner
transformer/position_wise_feed_forward_3/bias_out
transformer/position_wise_feed_forward_3/Reshape
transformer/position_wise_feed_forward_3/MatMul
transformer/position_wise_feed_forward_3/Reshape_2
transformer/position_wise_feed_forward_3/add
transformer/position_wise_feed_forward_3/Relu
transformer/position_wise_feed_forward_3/Reshape_3
transformer/position_wise_feed_forward_3/MatMul_1
transformer/position_wise_feed_forward_3/Reshape_5
transformer/position_wise_feed_forward_3/add_1
transformer/add_8
transformer/layer_normalization_11/beta
transformer/layer_normalization_11/gamma
transformer/layer_normalization_11/sub
transformer/layer_normalization_11/add
transformer/layer_normalization_11/pow
transformer/layer_normalization_11/add_1
transformer/multi_head_attention_4/Reshape
transformer/multi_head_attention_4/MatMul
transformer/multi_head_attention_4/Reshape_2
transformer/multi_head_attention_4/MatMul_1
transformer/multi_head_attention_4/Reshape_5
transformer/multi_head_attention_4/MatMul_2
transformer/multi_head_attention_4/Reshape_8
transformer/multi_head_attention_4/split
transformer/multi_head_attention_4/concat
transformer/multi_head_attention_4/split_1
transformer/multi_head_attention_4/concat_1
transformer/multi_head_attention_4/split_2
transformer/multi_head_attention_4/concat_2
transformer/multi_head_attention_4/split_3
transformer/multi_head_attention_4/concat_3
transformer/add_9
transformer/layer_normalization_4/beta
transformer/layer_normalization_4/gamma
transformer/layer_normalization_4/sub
transformer/layer_normalization_4/add
transformer/layer_normalization_4/pow
transformer/layer_normalization_4/add_1
transformer/position_wise_feed_forward_4/weights_inner
transformer/position_wise_feed_forward_4/weights_out
transformer/position_wise_feed_forward_4/bias_inner
transformer/position_wise_feed_forward_4/bias_out
transformer/position_wise_feed_forward_4/Reshape
transformer/position_wise_feed_forward_4/MatMul
transformer/position_wise_feed_forward_4/Reshape_2
transformer/position_wise_feed_forward_4/add
transformer/position_wise_feed_forward_4/Relu
transformer/position_wise_feed_forward_4/Reshape_3
transformer/position_wise_feed_forward_4/MatMul_1
transformer/position_wise_feed_forward_4/Reshape_5
transformer/position_wise_feed_forward_4/add_1
transformer/add_10
transformer/layer_normalization_12/beta
transformer/layer_normalization_12/gamma
transformer/layer_normalization_12/sub
transformer/layer_normalization_12/add
transformer/layer_normalization_12/pow
transformer/layer_normalization_12/add_1
transformer/multi_head_attention_5/Reshape
transformer/multi_head_attention_5/MatMul
transformer/multi_head_attention_5/Reshape_2
transformer/multi_head_attention_5/MatMul_1
transformer/multi_head_attention_5/Reshape_5
transformer/multi_head_attention_5/MatMul_2
transformer/multi_head_attention_5/Reshape_8
transformer/multi_head_attention_5/split
transformer/multi_head_attention_5/concat
transformer/multi_head_attention_5/split_1
transformer/multi_head_attention_5/concat_1
transformer/multi_head_attention_5/split_2
transformer/multi_head_attention_5/concat_2
transformer/multi_head_attention_5/split_3
transformer/multi_head_attention_5/concat_3
transformer/add_11
transformer/layer_normalization_5/beta
transformer/layer_normalization_5/gamma
transformer/layer_normalization_5/sub
transformer/layer_normalization_5/add
transformer/layer_normalization_5/pow
transformer/layer_normalization_5/add_1
transformer/position_wise_feed_forward_5/weights_inner
transformer/position_wise_feed_forward_5/weights_out
transformer/position_wise_feed_forward_5/bias_inner
transformer/position_wise_feed_forward_5/bias_out
transformer/position_wise_feed_forward_5/Reshape
transformer/position_wise_feed_forward_5/MatMul
transformer/position_wise_feed_forward_5/Reshape_2
transformer/position_wise_feed_forward_5/add
transformer/position_wise_feed_forward_5/Relu
transformer/position_wise_feed_forward_5/Reshape_3
transformer/position_wise_feed_forward_5/MatMul_1
transformer/position_wise_feed_forward_5/Reshape_5
transformer/position_wise_feed_forward_5/add_1
transformer/add_12
transformer/layer_normalization_13/beta
transformer/layer_normalization_13/gamma
transformer/layer_normalization_13/sub
transformer/layer_normalization_13/add
transformer/layer_normalization_13/pow
transformer/layer_normalization_13/add_1
transformer/multi_head_attention_6/Reshape
transformer/multi_head_attention_6/MatMul
transformer/multi_head_attention_6/Reshape_2
transformer/multi_head_attention_6/MatMul_1
transformer/multi_head_attention_6/Reshape_5
transformer/multi_head_attention_6/MatMul_2
transformer/multi_head_attention_6/Reshape_8
transformer/multi_head_attention_6/split
transformer/multi_head_attention_6/concat
transformer/multi_head_attention_6/split_1
transformer/multi_head_attention_6/concat_1
transformer/multi_head_attention_6/split_2
transformer/multi_head_attention_6/concat_2
transformer/multi_head_attention_6/split_3
transformer/multi_head_attention_6/concat_3
transformer/add_13
transformer/layer_normalization_6/beta
transformer/layer_normalization_6/gamma
transformer/layer_normalization_6/sub
transformer/layer_normalization_6/add
transformer/layer_normalization_6/pow
transformer/layer_normalization_6/add_1
transformer/position_wise_feed_forward_6/weights_inner
transformer/position_wise_feed_forward_6/weights_out
transformer/position_wise_feed_forward_6/bias_inner
transformer/position_wise_feed_forward_6/bias_out
transformer/position_wise_feed_forward_6/Reshape
transformer/position_wise_feed_forward_6/MatMul
transformer/position_wise_feed_forward_6/Reshape_2
transformer/position_wise_feed_forward_6/add
transformer/position_wise_feed_forward_6/Relu
transformer/position_wise_feed_forward_6/Reshape_3
transformer/position_wise_feed_forward_6/MatMul_1
transformer/position_wise_feed_forward_6/Reshape_5
transformer/position_wise_feed_forward_6/add_1
transformer/add_14
transformer/layer_normalization_14/beta
transformer/layer_normalization_14/gamma
transformer/layer_normalization_14/sub
transformer/layer_normalization_14/add
transformer/layer_normalization_14/pow
transformer/layer_normalization_14/add_1
transformer/multi_head_attention_7/Reshape
transformer/multi_head_attention_7/MatMul
transformer/multi_head_attention_7/Reshape_2
transformer/multi_head_attention_7/MatMul_1
transformer/multi_head_attention_7/Reshape_5
transformer/multi_head_attention_7/MatMul_2
transformer/multi_head_attention_7/Reshape_8
transformer/multi_head_attention_7/split
transformer/multi_head_attention_7/concat
transformer/multi_head_attention_7/split_1
transformer/multi_head_attention_7/concat_1
transformer/multi_head_attention_7/split_2
transformer/multi_head_attention_7/concat_2
transformer/multi_head_attention_7/split_3
transformer/multi_head_attention_7/concat_3
transformer/add_15
transformer/layer_normalization_7/beta
transformer/layer_normalization_7/gamma
transformer/layer_normalization_7/sub
transformer/layer_normalization_7/add
transformer/layer_normalization_7/pow
transformer/layer_normalization_7/add_1
transformer/position_wise_feed_forward_7/weights_inner
transformer/position_wise_feed_forward_7/weights_out
transformer/position_wise_feed_forward_7/bias_inner
transformer/position_wise_feed_forward_7/bias_out
transformer/position_wise_feed_forward_7/Reshape
transformer/position_wise_feed_forward_7/MatMul
transformer/position_wise_feed_forward_7/Reshape_2
transformer/position_wise_feed_forward_7/add
transformer/position_wise_feed_forward_7/Relu
transformer/position_wise_feed_forward_7/Reshape_3
transformer/position_wise_feed_forward_7/MatMul_1
transformer/position_wise_feed_forward_7/Reshape_5
transformer/position_wise_feed_forward_7/add_1
transformer/add_16
transformer/layer_normalization_15/beta
transformer/layer_normalization_15/gamma
transformer/layer_normalization_15/sub
transformer/layer_normalization_15/add
transformer/layer_normalization_15/pow
transformer/layer_normalization_15/add_1
transformer/mul_1
transformer/add_17
transformer/dropout_1/mul
transformer/dropout_1/mul_1
transformer/multi_head_attention_8/Reshape
transformer/multi_head_attention_8/MatMul
transformer/multi_head_attention_8/Reshape_2
transformer/multi_head_attention_8/MatMul_1
transformer/multi_head_attention_8/Reshape_5
transformer/multi_head_attention_8/MatMul_2
transformer/multi_head_attention_8/Reshape_8
transformer/multi_head_attention_8/split
transformer/multi_head_attention_8/concat
transformer/multi_head_attention_8/split_1
transformer/multi_head_attention_8/concat_1
transformer/multi_head_attention_8/split_2
transformer/multi_head_attention_8/concat_2
transformer/multi_head_attention_8/split_3
transformer/multi_head_attention_8/concat_3
transformer/add_18
transformer/layer_normalization_16/beta
transformer/layer_normalization_16/gamma
transformer/layer_normalization_16/sub
transformer/layer_normalization_16/add
transformer/layer_normalization_16/pow
transformer/layer_normalization_16/add_1
transformer/multi_head_attention_16/Reshape
transformer/multi_head_attention_16/MatMul
transformer/multi_head_attention_16/Reshape_2
transformer/multi_head_attention_16/Reshape_3
transformer/multi_head_attention_16/MatMul_1
transformer/multi_head_attention_16/Reshape_5
transformer/multi_head_attention_16/MatMul_2
transformer/multi_head_attention_16/Reshape_8
transformer/multi_head_attention_16/split
transformer/multi_head_attention_16/concat
transformer/multi_head_attention_16/split_1
transformer/multi_head_attention_16/concat_1
transformer/multi_head_attention_16/split_2
transformer/multi_head_attention_16/concat_2
transformer/multi_head_attention_16/split_3
transformer/multi_head_attention_16/concat_3
transformer/add_19
transformer/layer_normalization_24/beta
transformer/layer_normalization_24/gamma
transformer/layer_normalization_24/sub
transformer/layer_normalization_24/add
transformer/layer_normalization_24/pow
transformer/layer_normalization_24/add_1
transformer/position_wise_feed_forward_8/weights_inner
transformer/position_wise_feed_forward_8/weights_out
transformer/position_wise_feed_forward_8/bias_inner
transformer/position_wise_feed_forward_8/bias_out
transformer/position_wise_feed_forward_8/Reshape
transformer/position_wise_feed_forward_8/MatMul
transformer/position_wise_feed_forward_8/Reshape_2
transformer/position_wise_feed_forward_8/add
transformer/position_wise_feed_forward_8/Relu
transformer/position_wise_feed_forward_8/Reshape_3
transformer/position_wise_feed_forward_8/MatMul_1
transformer/position_wise_feed_forward_8/Reshape_5
transformer/position_wise_feed_forward_8/add_1
transformer/add_20
transformer/layer_normalization_32/beta
transformer/layer_normalization_32/gamma
transformer/layer_normalization_32/sub
transformer/layer_normalization_32/add
transformer/layer_normalization_32/pow
transformer/layer_normalization_32/add_1
transformer/multi_head_attention_9/Reshape
transformer/multi_head_attention_9/MatMul
transformer/multi_head_attention_9/Reshape_2
transformer/multi_head_attention_9/MatMul_1
transformer/multi_head_attention_9/Reshape_5
transformer/multi_head_attention_9/MatMul_2
transformer/multi_head_attention_9/Reshape_8
transformer/multi_head_attention_9/split
transformer/multi_head_attention_9/concat
transformer/multi_head_attention_9/split_1
transformer/multi_head_attention_9/concat_1
transformer/multi_head_attention_9/split_2
transformer/multi_head_attention_9/concat_2
transformer/multi_head_attention_9/split_3
transformer/multi_head_attention_9/concat_3
transformer/add_21
transformer/layer_normalization_17/beta
transformer/layer_normalization_17/gamma
transformer/layer_normalization_17/sub
transformer/layer_normalization_17/add
transformer/layer_normalization_17/pow
transformer/layer_normalization_17/add_1
transformer/multi_head_attention_17/Reshape
transformer/multi_head_attention_17/MatMul
transformer/multi_head_attention_17/Reshape_2
transformer/multi_head_attention_17/MatMul_1
transformer/multi_head_attention_17/Reshape_5
transformer/multi_head_attention_17/MatMul_2
transformer/multi_head_attention_17/Reshape_8
transformer/multi_head_attention_17/split
transformer/multi_head_attention_17/concat
transformer/multi_head_attention_17/split_1
transformer/multi_head_attention_17/concat_1
transformer/multi_head_attention_17/split_2
transformer/multi_head_attention_17/concat_2
transformer/multi_head_attention_17/split_3
transformer/multi_head_attention_17/concat_3
transformer/add_22
transformer/layer_normalization_25/beta
transformer/layer_normalization_25/gamma
transformer/layer_normalization_25/sub
transformer/layer_normalization_25/add
transformer/layer_normalization_25/pow
transformer/layer_normalization_25/add_1
transformer/position_wise_feed_forward_9/weights_inner
transformer/position_wise_feed_forward_9/weights_out
transformer/position_wise_feed_forward_9/bias_inner
transformer/position_wise_feed_forward_9/bias_out
transformer/position_wise_feed_forward_9/Reshape
transformer/position_wise_feed_forward_9/MatMul
transformer/position_wise_feed_forward_9/Reshape_2
transformer/position_wise_feed_forward_9/add
transformer/position_wise_feed_forward_9/Relu
transformer/position_wise_feed_forward_9/Reshape_3
transformer/position_wise_feed_forward_9/MatMul_1
transformer/position_wise_feed_forward_9/Reshape_5
transformer/position_wise_feed_forward_9/add_1
transformer/add_23
transformer/layer_normalization_33/beta
transformer/layer_normalization_33/gamma
transformer/layer_normalization_33/sub
transformer/layer_normalization_33/add
transformer/layer_normalization_33/pow
transformer/layer_normalization_33/add_1
transformer/multi_head_attention_10/Reshape
transformer/multi_head_attention_10/MatMul
transformer/multi_head_attention_10/Reshape_2
transformer/multi_head_attention_10/MatMul_1
transformer/multi_head_attention_10/Reshape_5
transformer/multi_head_attention_10/MatMul_2
transformer/multi_head_attention_10/Reshape_8
transformer/multi_head_attention_10/split
transformer/multi_head_attention_10/concat
transformer/multi_head_attention_10/split_1
transformer/multi_head_attention_10/concat_1
transformer/multi_head_attention_10/split_2
transformer/multi_head_attention_10/concat_2
transformer/multi_head_attention_10/split_3
transformer/multi_head_attention_10/concat_3
transformer/add_24
transformer/layer_normalization_18/beta
transformer/layer_normalization_18/gamma
transformer/layer_normalization_18/sub
transformer/layer_normalization_18/add
transformer/layer_normalization_18/pow
transformer/layer_normalization_18/add_1
transformer/multi_head_attention_18/Reshape
transformer/multi_head_attention_18/MatMul
transformer/multi_head_attention_18/Reshape_2
transformer/multi_head_attention_18/MatMul_1
transformer/multi_head_attention_18/Reshape_5
transformer/multi_head_attention_18/MatMul_2
transformer/multi_head_attention_18/Reshape_8
transformer/multi_head_attention_18/split
transformer/multi_head_attention_18/concat
transformer/multi_head_attention_18/split_1
transformer/multi_head_attention_18/concat_1
transformer/multi_head_attention_18/split_2
transformer/multi_head_attention_18/concat_2
transformer/multi_head_attention_18/split_3
transformer/multi_head_attention_18/concat_3
transformer/add_25
transformer/layer_normalization_26/beta
transformer/layer_normalization_26/gamma
transformer/layer_normalization_26/sub
transformer/layer_normalization_26/add
transformer/layer_normalization_26/pow
transformer/layer_normalization_26/add_1
transformer/position_wise_feed_forward_10/weights_inner
transformer/position_wise_feed_forward_10/weights_out
transformer/position_wise_feed_forward_10/bias_inner
transformer/position_wise_feed_forward_10/bias_out
transformer/position_wise_feed_forward_10/Reshape
transformer/position_wise_feed_forward_10/MatMul
transformer/position_wise_feed_forward_10/Reshape_2
transformer/position_wise_feed_forward_10/add
transformer/position_wise_feed_forward_10/Relu
transformer/position_wise_feed_forward_10/Reshape_3
transformer/position_wise_feed_forward_10/MatMul_1
transformer/position_wise_feed_forward_10/Reshape_5
transformer/position_wise_feed_forward_10/add_1
transformer/add_26
transformer/layer_normalization_34/beta
transformer/layer_normalization_34/gamma
transformer/layer_normalization_34/sub
transformer/layer_normalization_34/add
transformer/layer_normalization_34/pow
transformer/layer_normalization_34/add_1
transformer/multi_head_attention_11/Reshape
transformer/multi_head_attention_11/MatMul
transformer/multi_head_attention_11/Reshape_2
transformer/multi_head_attention_11/MatMul_1
transformer/multi_head_attention_11/Reshape_5
transformer/multi_head_attention_11/MatMul_2
transformer/multi_head_attention_11/Reshape_8
transformer/multi_head_attention_11/split
transformer/multi_head_attention_11/concat
transformer/multi_head_attention_11/split_1
transformer/multi_head_attention_11/concat_1
transformer/multi_head_attention_11/split_2
transformer/multi_head_attention_11/concat_2
transformer/multi_head_attention_11/split_3
transformer/multi_head_attention_11/concat_3
transformer/add_27
transformer/layer_normalization_19/beta
transformer/layer_normalization_19/gamma
transformer/layer_normalization_19/sub
transformer/layer_normalization_19/add
transformer/layer_normalization_19/pow
transformer/layer_normalization_19/add_1
transformer/multi_head_attention_19/Reshape
transformer/multi_head_attention_19/MatMul
transformer/multi_head_attention_19/Reshape_2
transformer/multi_head_attention_19/MatMul_1
transformer/multi_head_attention_19/Reshape_5
transformer/multi_head_attention_19/MatMul_2
transformer/multi_head_attention_19/Reshape_8
transformer/multi_head_attention_19/split
transformer/multi_head_attention_19/concat
transformer/multi_head_attention_19/split_1
transformer/multi_head_attention_19/concat_1
transformer/multi_head_attention_19/split_2
transformer/multi_head_attention_19/concat_2
transformer/multi_head_attention_19/split_3
transformer/multi_head_attention_19/concat_3
transformer/add_28
transformer/layer_normalization_27/beta
transformer/layer_normalization_27/gamma
transformer/layer_normalization_27/sub
transformer/layer_normalization_27/add
transformer/layer_normalization_27/pow
transformer/layer_normalization_27/add_1
transformer/position_wise_feed_forward_11/weights_inner
transformer/position_wise_feed_forward_11/weights_out
transformer/position_wise_feed_forward_11/bias_inner
transformer/position_wise_feed_forward_11/bias_out
transformer/position_wise_feed_forward_11/Reshape
transformer/position_wise_feed_forward_11/MatMul
transformer/position_wise_feed_forward_11/Reshape_2
transformer/position_wise_feed_forward_11/add
transformer/position_wise_feed_forward_11/Relu
transformer/position_wise_feed_forward_11/Reshape_3
transformer/position_wise_feed_forward_11/MatMul_1
transformer/position_wise_feed_forward_11/Reshape_5
transformer/position_wise_feed_forward_11/add_1
transformer/add_29
transformer/layer_normalization_35/beta
transformer/layer_normalization_35/gamma
transformer/layer_normalization_35/sub
transformer/layer_normalization_35/add
transformer/layer_normalization_35/pow
transformer/layer_normalization_35/add_1
transformer/multi_head_attention_12/Reshape
transformer/multi_head_attention_12/MatMul
transformer/multi_head_attention_12/Reshape_2
transformer/multi_head_attention_12/MatMul_1
transformer/multi_head_attention_12/Reshape_5
transformer/multi_head_attention_12/MatMul_2
transformer/multi_head_attention_12/Reshape_8
transformer/multi_head_attention_12/split
transformer/multi_head_attention_12/concat
transformer/multi_head_attention_12/split_1
transformer/multi_head_attention_12/concat_1
transformer/multi_head_attention_12/split_2
transformer/multi_head_attention_12/concat_2
transformer/multi_head_attention_12/split_3
transformer/multi_head_attention_12/concat_3
transformer/add_30
transformer/layer_normalization_20/beta
transformer/layer_normalization_20/gamma
transformer/layer_normalization_20/sub
transformer/layer_normalization_20/add
transformer/layer_normalization_20/pow
transformer/layer_normalization_20/add_1
transformer/multi_head_attention_20/Reshape
transformer/multi_head_attention_20/MatMul
transformer/multi_head_attention_20/Reshape_2
transformer/multi_head_attention_20/MatMul_1
transformer/multi_head_attention_20/Reshape_5
transformer/multi_head_attention_20/MatMul_2
transformer/multi_head_attention_20/Reshape_8
transformer/multi_head_attention_20/split
transformer/multi_head_attention_20/concat
transformer/multi_head_attention_20/split_1
transformer/multi_head_attention_20/concat_1
transformer/multi_head_attention_20/split_2
transformer/multi_head_attention_20/concat_2
transformer/multi_head_attention_20/split_3
transformer/multi_head_attention_20/concat_3
transformer/add_31
transformer/layer_normalization_28/beta
transformer/layer_normalization_28/gamma
transformer/layer_normalization_28/sub
transformer/layer_normalization_28/add
transformer/layer_normalization_28/pow
transformer/layer_normalization_28/add_1
transformer/position_wise_feed_forward_12/weights_inner
transformer/position_wise_feed_forward_12/weights_out
transformer/position_wise_feed_forward_12/bias_inner
transformer/position_wise_feed_forward_12/bias_out
transformer/position_wise_feed_forward_12/Reshape
transformer/position_wise_feed_forward_12/MatMul
transformer/position_wise_feed_forward_12/Reshape_2
transformer/position_wise_feed_forward_12/add
transformer/position_wise_feed_forward_12/Relu
transformer/position_wise_feed_forward_12/Reshape_3
transformer/position_wise_feed_forward_12/MatMul_1
transformer/position_wise_feed_forward_12/Reshape_5
transformer/position_wise_feed_forward_12/add_1
transformer/add_32
transformer/layer_normalization_36/beta
transformer/layer_normalization_36/gamma
transformer/layer_normalization_36/sub
transformer/layer_normalization_36/add
transformer/layer_normalization_36/pow
transformer/layer_normalization_36/add_1
transformer/multi_head_attention_13/Reshape
transformer/multi_head_attention_13/MatMul
transformer/multi_head_attention_13/Reshape_2
transformer/multi_head_attention_13/MatMul_1
transformer/multi_head_attention_13/Reshape_5
transformer/multi_head_attention_13/MatMul_2
transformer/multi_head_attention_13/Reshape_8
transformer/multi_head_attention_13/split
transformer/multi_head_attention_13/concat
transformer/multi_head_attention_13/split_1
transformer/multi_head_attention_13/concat_1
transformer/multi_head_attention_13/split_2
transformer/multi_head_attention_13/concat_2
transformer/multi_head_attention_13/split_3
transformer/multi_head_attention_13/concat_3
transformer/add_33
transformer/layer_normalization_21/beta
transformer/layer_normalization_21/gamma
transformer/layer_normalization_21/sub
transformer/layer_normalization_21/add
transformer/layer_normalization_21/pow
transformer/layer_normalization_21/add_1
transformer/multi_head_attention_21/Reshape
transformer/multi_head_attention_21/MatMul
transformer/multi_head_attention_21/Reshape_2
transformer/multi_head_attention_21/MatMul_1
transformer/multi_head_attention_21/Reshape_5
transformer/multi_head_attention_21/MatMul_2
transformer/multi_head_attention_21/Reshape_8
transformer/multi_head_attention_21/split
transformer/multi_head_attention_21/concat
transformer/multi_head_attention_21/split_1
transformer/multi_head_attention_21/concat_1
transformer/multi_head_attention_21/split_2
transformer/multi_head_attention_21/concat_2
transformer/multi_head_attention_21/split_3
transformer/multi_head_attention_21/concat_3
transformer/add_34
transformer/layer_normalization_29/beta
transformer/layer_normalization_29/gamma
transformer/layer_normalization_29/sub
transformer/layer_normalization_29/add
transformer/layer_normalization_29/pow
transformer/layer_normalization_29/add_1
transformer/position_wise_feed_forward_13/weights_inner
transformer/position_wise_feed_forward_13/weights_out
transformer/position_wise_feed_forward_13/bias_inner
transformer/position_wise_feed_forward_13/bias_out
transformer/position_wise_feed_forward_13/Reshape
transformer/position_wise_feed_forward_13/MatMul
transformer/position_wise_feed_forward_13/Reshape_2
transformer/position_wise_feed_forward_13/add
transformer/position_wise_feed_forward_13/Relu
transformer/position_wise_feed_forward_13/Reshape_3
transformer/position_wise_feed_forward_13/MatMul_1
transformer/position_wise_feed_forward_13/Reshape_5
transformer/position_wise_feed_forward_13/add_1
transformer/add_35
transformer/layer_normalization_37/beta
transformer/layer_normalization_37/gamma
transformer/layer_normalization_37/sub
transformer/layer_normalization_37/add
transformer/layer_normalization_37/pow
transformer/layer_normalization_37/add_1
transformer/multi_head_attention_14/Reshape
transformer/multi_head_attention_14/MatMul
transformer/multi_head_attention_14/Reshape_2
transformer/multi_head_attention_14/MatMul_1
transformer/multi_head_attention_14/Reshape_5
transformer/multi_head_attention_14/MatMul_2
transformer/multi_head_attention_14/Reshape_8
transformer/multi_head_attention_14/split
transformer/multi_head_attention_14/concat
transformer/multi_head_attention_14/split_1
transformer/multi_head_attention_14/concat_1
transformer/multi_head_attention_14/split_2
transformer/multi_head_attention_14/concat_2
transformer/multi_head_attention_14/split_3
transformer/multi_head_attention_14/concat_3
transformer/add_36
transformer/layer_normalization_22/beta
transformer/layer_normalization_22/gamma
transformer/layer_normalization_22/sub
transformer/layer_normalization_22/add
transformer/layer_normalization_22/pow
transformer/layer_normalization_22/add_1
transformer/multi_head_attention_22/Reshape
transformer/multi_head_attention_22/MatMul
transformer/multi_head_attention_22/Reshape_2
transformer/multi_head_attention_22/MatMul_1
transformer/multi_head_attention_22/Reshape_5
transformer/multi_head_attention_22/MatMul_2
transformer/multi_head_attention_22/Reshape_8
transformer/multi_head_attention_22/split
transformer/multi_head_attention_22/concat
transformer/multi_head_attention_22/split_1
transformer/multi_head_attention_22/concat_1
transformer/multi_head_attention_22/split_2
transformer/multi_head_attention_22/concat_2
transformer/multi_head_attention_22/split_3
transformer/multi_head_attention_22/concat_3
transformer/add_37
transformer/layer_normalization_30/beta
transformer/layer_normalization_30/gamma
transformer/layer_normalization_30/sub
transformer/layer_normalization_30/add
transformer/layer_normalization_30/pow
transformer/layer_normalization_30/add_1
transformer/position_wise_feed_forward_14/weights_inner
transformer/position_wise_feed_forward_14/weights_out
transformer/position_wise_feed_forward_14/bias_inner
transformer/position_wise_feed_forward_14/bias_out
transformer/position_wise_feed_forward_14/Reshape
transformer/position_wise_feed_forward_14/MatMul
transformer/position_wise_feed_forward_14/Reshape_2
transformer/position_wise_feed_forward_14/add
transformer/position_wise_feed_forward_14/Relu
transformer/position_wise_feed_forward_14/Reshape_3
transformer/position_wise_feed_forward_14/MatMul_1
transformer/position_wise_feed_forward_14/Reshape_5
transformer/position_wise_feed_forward_14/add_1
transformer/add_38
transformer/layer_normalization_38/beta
transformer/layer_normalization_38/gamma
transformer/layer_normalization_38/sub
transformer/layer_normalization_38/add
transformer/layer_normalization_38/pow
transformer/layer_normalization_38/add_1
transformer/multi_head_attention_15/Reshape
transformer/multi_head_attention_15/MatMul
transformer/multi_head_attention_15/Reshape_2
transformer/multi_head_attention_15/MatMul_1
transformer/multi_head_attention_15/Reshape_5
transformer/multi_head_attention_15/MatMul_2
transformer/multi_head_attention_15/Reshape_8
transformer/multi_head_attention_15/split
transformer/multi_head_attention_15/concat
transformer/multi_head_attention_15/split_1
transformer/multi_head_attention_15/concat_1
transformer/multi_head_attention_15/split_2
transformer/multi_head_attention_15/concat_2
transformer/multi_head_attention_15/split_3
transformer/multi_head_attention_15/concat_3
transformer/add_39
transformer/layer_normalization_23/beta
transformer/layer_normalization_23/gamma
transformer/layer_normalization_23/sub
transformer/layer_normalization_23/add
transformer/layer_normalization_23/pow
transformer/layer_normalization_23/add_1
transformer/multi_head_attention_23/Reshape
transformer/multi_head_attention_23/MatMul
transformer/multi_head_attention_23/Reshape_2
transformer/multi_head_attention_23/MatMul_1
transformer/multi_head_attention_23/Reshape_5
transformer/multi_head_attention_23/MatMul_2
transformer/multi_head_attention_23/Reshape_8
transformer/multi_head_attention_23/split
transformer/multi_head_attention_23/concat
transformer/multi_head_attention_23/split_1
transformer/multi_head_attention_23/concat_1
transformer/multi_head_attention_23/split_2
transformer/multi_head_attention_23/concat_2
transformer/multi_head_attention_23/split_3
transformer/multi_head_attention_23/concat_3
transformer/add_40
transformer/layer_normalization_31/beta
transformer/layer_normalization_31/gamma
transformer/layer_normalization_31/sub
transformer/layer_normalization_31/add
transformer/layer_normalization_31/pow
transformer/layer_normalization_31/add_1
transformer/position_wise_feed_forward_15/weights_inner
transformer/position_wise_feed_forward_15/weights_out
transformer/position_wise_feed_forward_15/bias_inner
transformer/position_wise_feed_forward_15/bias_out
transformer/position_wise_feed_forward_15/Reshape
transformer/position_wise_feed_forward_15/MatMul
transformer/position_wise_feed_forward_15/Reshape_2
transformer/position_wise_feed_forward_15/add
transformer/position_wise_feed_forward_15/Relu
transformer/position_wise_feed_forward_15/Reshape_3
transformer/position_wise_feed_forward_15/MatMul_1
transformer/position_wise_feed_forward_15/Reshape_5
transformer/position_wise_feed_forward_15/add_1
transformer/add_41
transformer/layer_normalization_39/beta
transformer/layer_normalization_39/gamma
transformer/layer_normalization_39/sub
transformer/layer_normalization_39/add
transformer/layer_normalization_39/pow
transformer/layer_normalization_39/add_1
transformer/Reshape
transformer/Reshape_2
transformer/Softmax
global_average_pooling1d/Mean
dense/MatMul
dense/BiasAdd
dense/Softmax
