transformer/mul
transformer/add
transformer/dropout/mul
transformer/dropout/mul_1
transformer/multi_head_attention/Reshape
transformer/multi_head_attention/MatMul
transformer/multi_head_attention/Reshape_2
transformer/multi_head_attention/MatMul_1
transformer/multi_head_attention/Reshape_5
transformer/multi_head_attention/MatMul_2
transformer/multi_head_attention/Reshape_8
transformer/multi_head_attention/split
transformer/multi_head_attention/concat
transformer/multi_head_attention/split_1
transformer/multi_head_attention/concat_1
transformer/multi_head_attention/split_2
transformer/multi_head_attention/concat_2
transformer/multi_head_attention/split_3
transformer/multi_head_attention/concat_3
transformer/add_1
transformer/layer_normalization/beta
transformer/layer_normalization/gamma
transformer/layer_normalization/sub
transformer/layer_normalization/add
transformer/layer_normalization/pow
transformer/layer_normalization/add_1
transformer/position_wise_feed_forward/weights_inner
transformer/position_wise_feed_forward/weights_out
transformer/position_wise_feed_forward/bias_inner
transformer/position_wise_feed_forward/bias_out
transformer/position_wise_feed_forward/Reshape
transformer/position_wise_feed_forward/MatMul
transformer/position_wise_feed_forward/Reshape_2
transformer/position_wise_feed_forward/add
transformer/position_wise_feed_forward/Relu
transformer/position_wise_feed_forward/Reshape_3
transformer/position_wise_feed_forward/MatMul_1
transformer/position_wise_feed_forward/Reshape_5
transformer/position_wise_feed_forward/add_1
transformer/add_2
transformer/layer_normalization_4/beta
transformer/layer_normalization_4/gamma
transformer/layer_normalization_4/sub
transformer/layer_normalization_4/add
transformer/layer_normalization_4/pow
transformer/layer_normalization_4/add_1
transformer/multi_head_attention_1/Reshape
transformer/multi_head_attention_1/MatMul
transformer/multi_head_attention_1/Reshape_2
transformer/multi_head_attention_1/MatMul_1
transformer/multi_head_attention_1/Reshape_5
transformer/multi_head_attention_1/MatMul_2
transformer/multi_head_attention_1/Reshape_8
transformer/multi_head_attention_1/split
transformer/multi_head_attention_1/concat
transformer/multi_head_attention_1/split_1
transformer/multi_head_attention_1/concat_1
transformer/multi_head_attention_1/split_2
transformer/multi_head_attention_1/concat_2
transformer/multi_head_attention_1/split_3
transformer/multi_head_attention_1/concat_3
transformer/add_3
transformer/layer_normalization_1/beta
transformer/layer_normalization_1/gamma
transformer/layer_normalization_1/sub
transformer/layer_normalization_1/add
transformer/layer_normalization_1/pow
transformer/layer_normalization_1/add_1
transformer/position_wise_feed_forward_1/weights_inner
transformer/position_wise_feed_forward_1/weights_out
transformer/position_wise_feed_forward_1/bias_inner
transformer/position_wise_feed_forward_1/bias_out
transformer/position_wise_feed_forward_1/Reshape
transformer/position_wise_feed_forward_1/MatMul
transformer/position_wise_feed_forward_1/Reshape_2
transformer/position_wise_feed_forward_1/add
transformer/position_wise_feed_forward_1/Relu
transformer/position_wise_feed_forward_1/Reshape_3
transformer/position_wise_feed_forward_1/MatMul_1
transformer/position_wise_feed_forward_1/Reshape_5
transformer/position_wise_feed_forward_1/add_1
transformer/add_4
transformer/layer_normalization_5/beta
transformer/layer_normalization_5/gamma
transformer/layer_normalization_5/sub
transformer/layer_normalization_5/add
transformer/layer_normalization_5/pow
transformer/layer_normalization_5/add_1
transformer/multi_head_attention_2/Reshape
transformer/multi_head_attention_2/MatMul
transformer/multi_head_attention_2/Reshape_2
transformer/multi_head_attention_2/MatMul_1
transformer/multi_head_attention_2/Reshape_5
transformer/multi_head_attention_2/MatMul_2
transformer/multi_head_attention_2/Reshape_8
transformer/multi_head_attention_2/split
transformer/multi_head_attention_2/concat
transformer/multi_head_attention_2/split_1
transformer/multi_head_attention_2/concat_1
transformer/multi_head_attention_2/split_2
transformer/multi_head_attention_2/concat_2
transformer/multi_head_attention_2/split_3
transformer/multi_head_attention_2/concat_3
transformer/add_5
transformer/layer_normalization_2/beta
transformer/layer_normalization_2/gamma
transformer/layer_normalization_2/sub
transformer/layer_normalization_2/add
transformer/layer_normalization_2/pow
transformer/layer_normalization_2/add_1
transformer/position_wise_feed_forward_2/weights_inner
transformer/position_wise_feed_forward_2/weights_out
transformer/position_wise_feed_forward_2/bias_inner
transformer/position_wise_feed_forward_2/bias_out
transformer/position_wise_feed_forward_2/Reshape
transformer/position_wise_feed_forward_2/MatMul
transformer/position_wise_feed_forward_2/Reshape_2
transformer/position_wise_feed_forward_2/add
transformer/position_wise_feed_forward_2/Relu
transformer/position_wise_feed_forward_2/Reshape_3
transformer/position_wise_feed_forward_2/MatMul_1
transformer/position_wise_feed_forward_2/Reshape_5
transformer/position_wise_feed_forward_2/add_1
transformer/add_6
transformer/layer_normalization_6/beta
transformer/layer_normalization_6/gamma
transformer/layer_normalization_6/sub
transformer/layer_normalization_6/add
transformer/layer_normalization_6/pow
transformer/layer_normalization_6/add_1
transformer/multi_head_attention_3/Reshape
transformer/multi_head_attention_3/MatMul
transformer/multi_head_attention_3/Reshape_2
transformer/multi_head_attention_3/MatMul_1
transformer/multi_head_attention_3/Reshape_5
transformer/multi_head_attention_3/MatMul_2
transformer/multi_head_attention_3/Reshape_8
transformer/multi_head_attention_3/split
transformer/multi_head_attention_3/concat
transformer/multi_head_attention_3/split_1
transformer/multi_head_attention_3/concat_1
transformer/multi_head_attention_3/split_2
transformer/multi_head_attention_3/concat_2
transformer/multi_head_attention_3/split_3
transformer/multi_head_attention_3/concat_3
transformer/add_7
transformer/layer_normalization_3/beta
transformer/layer_normalization_3/gamma
transformer/layer_normalization_3/sub
transformer/layer_normalization_3/add
transformer/layer_normalization_3/pow
transformer/layer_normalization_3/add_1
transformer/position_wise_feed_forward_3/weights_inner
transformer/position_wise_feed_forward_3/weights_out
transformer/position_wise_feed_forward_3/bias_inner
transformer/position_wise_feed_forward_3/bias_out
transformer/position_wise_feed_forward_3/Reshape
transformer/position_wise_feed_forward_3/MatMul
transformer/position_wise_feed_forward_3/Reshape_2
transformer/position_wise_feed_forward_3/add
transformer/position_wise_feed_forward_3/Relu
transformer/position_wise_feed_forward_3/Reshape_3
transformer/position_wise_feed_forward_3/MatMul_1
transformer/position_wise_feed_forward_3/Reshape_5
transformer/position_wise_feed_forward_3/add_1
transformer/add_8
transformer/layer_normalization_7/beta
transformer/layer_normalization_7/gamma
transformer/layer_normalization_7/sub
transformer/layer_normalization_7/add
transformer/layer_normalization_7/pow
transformer/layer_normalization_7/add_1
transformer/mul_1
transformer/add_9
transformer/dropout_1/mul
transformer/dropout_1/mul_1
transformer/multi_head_attention_4/Reshape
transformer/multi_head_attention_4/MatMul
transformer/multi_head_attention_4/Reshape_2
transformer/multi_head_attention_4/MatMul_1
transformer/multi_head_attention_4/Reshape_5
transformer/multi_head_attention_4/MatMul_2
transformer/multi_head_attention_4/Reshape_8
transformer/multi_head_attention_4/split
transformer/multi_head_attention_4/concat
transformer/multi_head_attention_4/split_1
transformer/multi_head_attention_4/concat_1
transformer/multi_head_attention_4/split_2
transformer/multi_head_attention_4/concat_2
transformer/multi_head_attention_4/split_3
transformer/multi_head_attention_4/concat_3
transformer/add_10
transformer/layer_normalization_8/beta
transformer/layer_normalization_8/gamma
transformer/layer_normalization_8/sub
transformer/layer_normalization_8/add
transformer/layer_normalization_8/pow
transformer/layer_normalization_8/add_1
transformer/multi_head_attention_8/Reshape
transformer/multi_head_attention_8/MatMul
transformer/multi_head_attention_8/Reshape_2
transformer/multi_head_attention_8/MatMul_1
transformer/multi_head_attention_8/Reshape_5
transformer/multi_head_attention_8/MatMul_2
transformer/multi_head_attention_8/Reshape_8
transformer/multi_head_attention_8/split
transformer/multi_head_attention_8/concat
transformer/multi_head_attention_8/split_1
transformer/multi_head_attention_8/concat_1
transformer/multi_head_attention_8/split_2
transformer/multi_head_attention_8/concat_2
transformer/multi_head_attention_8/split_3
transformer/multi_head_attention_8/concat_3
transformer/add_11
transformer/layer_normalization_12/beta
transformer/layer_normalization_12/gamma
transformer/layer_normalization_12/sub
transformer/layer_normalization_12/add
transformer/layer_normalization_12/pow
transformer/layer_normalization_12/add_1
transformer/position_wise_feed_forward_4/weights_inner
transformer/position_wise_feed_forward_4/weights_out
transformer/position_wise_feed_forward_4/bias_inner
transformer/position_wise_feed_forward_4/bias_out
transformer/position_wise_feed_forward_4/Reshape
transformer/position_wise_feed_forward_4/MatMul
transformer/position_wise_feed_forward_4/Reshape_2
transformer/position_wise_feed_forward_4/add
transformer/position_wise_feed_forward_4/Relu
transformer/position_wise_feed_forward_4/Reshape_3
transformer/position_wise_feed_forward_4/MatMul_1
transformer/position_wise_feed_forward_4/Reshape_5
transformer/position_wise_feed_forward_4/add_1
transformer/add_12
transformer/layer_normalization_16/beta
transformer/layer_normalization_16/gamma
transformer/layer_normalization_16/sub
transformer/layer_normalization_16/add
transformer/layer_normalization_16/pow
transformer/layer_normalization_16/add_1
transformer/multi_head_attention_5/Reshape
transformer/multi_head_attention_5/MatMul
transformer/multi_head_attention_5/Reshape_2
transformer/multi_head_attention_5/MatMul_1
transformer/multi_head_attention_5/Reshape_5
transformer/multi_head_attention_5/MatMul_2
transformer/multi_head_attention_5/Reshape_8
transformer/multi_head_attention_5/split
transformer/multi_head_attention_5/concat
transformer/multi_head_attention_5/split_1
transformer/multi_head_attention_5/concat_1
transformer/multi_head_attention_5/split_2
transformer/multi_head_attention_5/concat_2
transformer/multi_head_attention_5/split_3
transformer/multi_head_attention_5/concat_3
transformer/add_13
transformer/layer_normalization_9/beta
transformer/layer_normalization_9/gamma
transformer/layer_normalization_9/sub
transformer/layer_normalization_9/add
transformer/layer_normalization_9/pow
transformer/layer_normalization_9/add_1
transformer/multi_head_attention_9/Reshape
transformer/multi_head_attention_9/MatMul
transformer/multi_head_attention_9/Reshape_2
transformer/multi_head_attention_9/MatMul_1
transformer/multi_head_attention_9/Reshape_5
transformer/multi_head_attention_9/MatMul_2
transformer/multi_head_attention_9/Reshape_8
transformer/multi_head_attention_9/split
transformer/multi_head_attention_9/concat
transformer/multi_head_attention_9/split_1
transformer/multi_head_attention_9/concat_1
transformer/multi_head_attention_9/split_2
transformer/multi_head_attention_9/concat_2
transformer/multi_head_attention_9/split_3
transformer/multi_head_attention_9/concat_3
transformer/add_14
transformer/layer_normalization_13/beta
transformer/layer_normalization_13/gamma
transformer/layer_normalization_13/sub
transformer/layer_normalization_13/add
transformer/layer_normalization_13/pow
transformer/layer_normalization_13/add_1
transformer/position_wise_feed_forward_5/weights_inner
transformer/position_wise_feed_forward_5/weights_out
transformer/position_wise_feed_forward_5/bias_inner
transformer/position_wise_feed_forward_5/bias_out
transformer/position_wise_feed_forward_5/Reshape
transformer/position_wise_feed_forward_5/MatMul
transformer/position_wise_feed_forward_5/Reshape_2
transformer/position_wise_feed_forward_5/add
transformer/position_wise_feed_forward_5/Relu
transformer/position_wise_feed_forward_5/Reshape_3
transformer/position_wise_feed_forward_5/MatMul_1
transformer/position_wise_feed_forward_5/Reshape_5
transformer/position_wise_feed_forward_5/add_1
transformer/add_15
transformer/layer_normalization_17/beta
transformer/layer_normalization_17/gamma
transformer/layer_normalization_17/sub
transformer/layer_normalization_17/add
transformer/layer_normalization_17/pow
transformer/layer_normalization_17/add_1
transformer/multi_head_attention_6/Reshape
transformer/multi_head_attention_6/MatMul
transformer/multi_head_attention_6/Reshape_2
transformer/multi_head_attention_6/MatMul_1
transformer/multi_head_attention_6/Reshape_5
transformer/multi_head_attention_6/MatMul_2
transformer/multi_head_attention_6/Reshape_8
transformer/multi_head_attention_6/split
transformer/multi_head_attention_6/concat
transformer/multi_head_attention_6/split_1
transformer/multi_head_attention_6/concat_1
transformer/multi_head_attention_6/split_2
transformer/multi_head_attention_6/concat_2
transformer/multi_head_attention_6/split_3
transformer/multi_head_attention_6/concat_3
transformer/add_16
transformer/layer_normalization_10/beta
transformer/layer_normalization_10/gamma
transformer/layer_normalization_10/sub
transformer/layer_normalization_10/add
transformer/layer_normalization_10/pow
transformer/layer_normalization_10/add_1
transformer/multi_head_attention_10/Reshape
transformer/multi_head_attention_10/MatMul
transformer/multi_head_attention_10/Reshape_2
transformer/multi_head_attention_10/MatMul_1
transformer/multi_head_attention_10/Reshape_5
transformer/multi_head_attention_10/MatMul_2
transformer/multi_head_attention_10/Reshape_8
transformer/multi_head_attention_10/split
transformer/multi_head_attention_10/concat
transformer/multi_head_attention_10/split_1
transformer/multi_head_attention_10/concat_1
transformer/multi_head_attention_10/split_2
transformer/multi_head_attention_10/concat_2
transformer/multi_head_attention_10/split_3
transformer/multi_head_attention_10/concat_3
transformer/add_17
transformer/layer_normalization_14/beta
transformer/layer_normalization_14/gamma
transformer/layer_normalization_14/sub
transformer/layer_normalization_14/add
transformer/layer_normalization_14/pow
transformer/layer_normalization_14/add_1
transformer/position_wise_feed_forward_6/weights_inner
transformer/position_wise_feed_forward_6/weights_out
transformer/position_wise_feed_forward_6/bias_inner
transformer/position_wise_feed_forward_6/bias_out
transformer/position_wise_feed_forward_6/Reshape
transformer/position_wise_feed_forward_6/MatMul
transformer/position_wise_feed_forward_6/Reshape_2
transformer/position_wise_feed_forward_6/add
transformer/position_wise_feed_forward_6/Relu
transformer/position_wise_feed_forward_6/Reshape_3
transformer/position_wise_feed_forward_6/MatMul_1
transformer/position_wise_feed_forward_6/Reshape_5
transformer/position_wise_feed_forward_6/add_1
transformer/add_18
transformer/layer_normalization_18/beta
transformer/layer_normalization_18/gamma
transformer/layer_normalization_18/sub
transformer/layer_normalization_18/add
transformer/layer_normalization_18/pow
transformer/layer_normalization_18/add_1
transformer/multi_head_attention_7/Reshape
transformer/multi_head_attention_7/MatMul
transformer/multi_head_attention_7/Reshape_2
transformer/multi_head_attention_7/MatMul_1
transformer/multi_head_attention_7/Reshape_5
transformer/multi_head_attention_7/MatMul_2
transformer/multi_head_attention_7/Reshape_8
transformer/multi_head_attention_7/split
transformer/multi_head_attention_7/concat
transformer/multi_head_attention_7/split_1
transformer/multi_head_attention_7/concat_1
transformer/multi_head_attention_7/split_2
transformer/multi_head_attention_7/concat_2
transformer/multi_head_attention_7/split_3
transformer/multi_head_attention_7/concat_3
transformer/add_19
transformer/layer_normalization_11/beta
transformer/layer_normalization_11/gamma
transformer/layer_normalization_11/sub
transformer/layer_normalization_11/add
transformer/layer_normalization_11/pow
transformer/layer_normalization_11/add_1
transformer/multi_head_attention_11/Reshape
transformer/multi_head_attention_11/MatMul
transformer/multi_head_attention_11/Reshape_2
transformer/multi_head_attention_11/MatMul_1
transformer/multi_head_attention_11/Reshape_5
transformer/multi_head_attention_11/MatMul_2
transformer/multi_head_attention_11/Reshape_8
transformer/multi_head_attention_11/split
transformer/multi_head_attention_11/concat
transformer/multi_head_attention_11/split_1
transformer/multi_head_attention_11/concat_1
transformer/multi_head_attention_11/split_2
transformer/multi_head_attention_11/concat_2
transformer/multi_head_attention_11/split_3
transformer/multi_head_attention_11/concat_3
transformer/add_20
transformer/layer_normalization_15/beta
transformer/layer_normalization_15/gamma
transformer/layer_normalization_15/sub
transformer/layer_normalization_15/add
transformer/layer_normalization_15/pow
transformer/layer_normalization_15/add_1
transformer/position_wise_feed_forward_7/weights_inner
transformer/position_wise_feed_forward_7/weights_out
transformer/position_wise_feed_forward_7/bias_inner
transformer/position_wise_feed_forward_7/bias_out
transformer/position_wise_feed_forward_7/Reshape
transformer/position_wise_feed_forward_7/MatMul
transformer/position_wise_feed_forward_7/Reshape_2
transformer/position_wise_feed_forward_7/add
transformer/position_wise_feed_forward_7/Relu
transformer/position_wise_feed_forward_7/Reshape_3
transformer/position_wise_feed_forward_7/MatMul_1
transformer/position_wise_feed_forward_7/Reshape_5
transformer/position_wise_feed_forward_7/add_1
transformer/add_21
transformer/layer_normalization_19/beta
transformer/layer_normalization_19/gamma
transformer/layer_normalization_19/sub
transformer/layer_normalization_19/add
transformer/layer_normalization_19/pow
transformer/layer_normalization_19/add_1
transformer/Reshape
transformer/Reshape_2
transformer/Softmax
global_average_pooling1d/Mean
dense/MatMul
dense/BiasAdd
dense/Softmax
