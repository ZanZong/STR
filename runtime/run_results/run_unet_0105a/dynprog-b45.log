WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 45), ('epochs', 1), ('model_name', 'vgg_unet'), ('strategy', 'dynprog'), ('verbose', False)]
Cannot find config for batch_size=45, use 40 instead
There are 367 and 367 images downloaded for train and test
Verifying train dataset
  0%|          | 0/367 [00:00<?, ?it/s]  4%|▎         | 13/367 [00:00<00:02, 124.03it/s]  7%|▋         | 26/367 [00:00<00:02, 125.28it/s] 11%|█         | 39/367 [00:00<00:02, 125.62it/s] 14%|█▍        | 53/367 [00:00<00:02, 127.66it/s] 18%|█▊        | 66/367 [00:00<00:02, 126.94it/s] 22%|██▏       | 79/367 [00:00<00:02, 126.90it/s] 26%|██▌       | 94/367 [00:00<00:02, 132.41it/s] 30%|██▉       | 110/367 [00:00<00:01, 140.51it/s] 34%|███▍      | 126/367 [00:00<00:01, 144.53it/s] 39%|███▊      | 142/367 [00:01<00:01, 146.63it/s] 43%|████▎     | 158/367 [00:01<00:01, 149.10it/s] 47%|████▋     | 174/367 [00:01<00:01, 151.05it/s] 52%|█████▏    | 190/367 [00:01<00:01, 152.73it/s] 56%|█████▌    | 206/367 [00:01<00:01, 152.98it/s] 60%|██████    | 222/367 [00:01<00:00, 153.73it/s] 65%|██████▍   | 238/367 [00:01<00:00, 153.43it/s] 69%|██████▉   | 254/367 [00:01<00:00, 154.72it/s] 74%|███████▎  | 270/367 [00:01<00:00, 154.52it/s] 78%|███████▊  | 286/367 [00:01<00:00, 155.09it/s] 82%|████████▏ | 302/367 [00:02<00:00, 155.39it/s] 87%|████████▋ | 318/367 [00:02<00:00, 154.28it/s] 91%|█████████ | 334/367 [00:02<00:00, 154.14it/s] 95%|█████████▌| 350/367 [00:02<00:00, 154.78it/s]100%|█████████▉| 366/367 [00:02<00:00, 154.20it/s]100%|██████████| 367/367 [00:02<00:00, 147.15it/s]
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:928: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
2022-01-05 02:21:15.557388: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:21:15.557450: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
Dataset verified! 
Starting Epoch  0
[STR DEBUG] Parsing STR configuration: [{'strategy': 'swap', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/layer_names'}, {'p': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/P-dynprog', 'q': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/Q-dynprog'}]
[STR DEBUG] Use swap strategy of DYNPROG
[STR DEBUG] Processing layer 2's swapping, swap out at [3], swap in at [41]
[STR DEBUG] Find swapout ops: name: "block1_conv2/Relu"
op: "Relu"
input: "block1_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block1_conv2/Relu:0", shape=(?, 320, 640, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block1_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block1_conv2/Relu"
input: "block1_pool/MaxPool"
input: "training/Adadelta/gradients/gradients/AddN_17"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 5's swapping, swap out at [6], swap in at [38]
[STR DEBUG] Find swapout ops: name: "block2_conv2/Relu"
op: "Relu"
input: "block2_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block2_conv2/Relu:0", shape=(?, 160, 320, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block2_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block2_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block2_conv2/Relu"
input: "block2_pool/MaxPool"
input: "training/Adadelta/gradients/gradients/AddN_16"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block2_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
 1/64 [..............................] - ETA: 27:40 - loss: 4.3862 - acc: 0.01402022-01-05 02:21:27.645641: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:21:37.646437: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.68GiB (rounded to 1802787840).  Current allocation summary follows.
2022-01-05 02:21:37.647661: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ******************************_****____*****______*********_____***********__***______**************
2022-01-05 02:21:37.647712: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_grad_input_ops.cc:420 : Resource exhausted: OOM when allocating tensor with shape[45,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File "../run_training.py", line 68, in <module>
    epochs=1)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/keras_segmentation-0.2.0remat-py3.6.egg/keras_segmentation/train.py", line 106, in train
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 1301, in fit_generator
    steps_name='steps_per_epoch')
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 1021, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3476, in __call__
    run_metadata=self.run_metadata)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1472, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted: OOM when allocating tensor with shape[45,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad/_434]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: OOM when allocating tensor with shape[45,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.
