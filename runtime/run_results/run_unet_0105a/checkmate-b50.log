WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 50), ('epochs', 1), ('model_name', 'vgg_unet'), ('strategy', 'checkmate'), ('verbose', False)]
Cannot find config for batch_size=50, use 40 instead
There are 367 and 367 images downloaded for train and test
Verifying train dataset
  0%|          | 0/367 [00:00<?, ?it/s]  4%|▎         | 13/367 [00:00<00:02, 126.07it/s]  8%|▊         | 29/367 [00:00<00:02, 145.12it/s] 12%|█▏        | 45/367 [00:00<00:02, 150.95it/s] 17%|█▋        | 61/367 [00:00<00:01, 153.32it/s] 21%|██        | 77/367 [00:00<00:01, 153.58it/s] 25%|██▌       | 93/367 [00:00<00:01, 154.56it/s] 30%|██▉       | 109/367 [00:00<00:01, 155.83it/s] 34%|███▍      | 125/367 [00:00<00:01, 155.92it/s] 38%|███▊      | 141/367 [00:00<00:01, 155.97it/s] 43%|████▎     | 158/367 [00:01<00:01, 157.66it/s] 47%|████▋     | 174/367 [00:01<00:01, 157.56it/s] 52%|█████▏    | 191/367 [00:01<00:01, 158.74it/s] 56%|█████▋    | 207/367 [00:01<00:01, 157.34it/s] 61%|██████    | 223/367 [00:01<00:00, 157.34it/s] 65%|██████▌   | 239/367 [00:01<00:00, 157.70it/s] 70%|██████▉   | 256/367 [00:01<00:00, 159.01it/s] 74%|███████▍  | 272/367 [00:01<00:00, 158.71it/s] 79%|███████▊  | 289/367 [00:01<00:00, 159.74it/s] 83%|████████▎ | 305/367 [00:01<00:00, 159.45it/s] 87%|████████▋ | 321/367 [00:02<00:00, 159.59it/s] 92%|█████████▏| 337/367 [00:02<00:00, 159.38it/s] 96%|█████████▋| 354/367 [00:02<00:00, 159.82it/s]100%|██████████| 367/367 [00:02<00:00, 156.77it/s]
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/str_strategy.py:122: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
Dataset verified! 
Starting Epoch  0
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/layer_names'}, {'r': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/R-checkmate'}]
[STR DEBUG] Use recomputing with Checkmate's solution
[STR DEBUG] Edit graph for recomputation ops
[STR DEBUG] Sorted forward ops: [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>]
[STR DEBUG] Ops to be recomputed: [<tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>]
[STR DEBUG] Supplementary tensors to be checkpoints: [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] Checkpointed tensors and distconnected: {<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>}
[STR DEBUG] Found 92 ops to copy within fwd_ops [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'loss/mul' type=Mul>], stop_at [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] ops_to_copy = [<tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/mul' type=Mul>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>]
[STR DEBUG] Processing list [<tf.Tensor 'loss/mul:0' shape=() dtype=float32>]
[STR DEBUG] Copied_svg: SubGraphView (graphid=139981245619672):
** ops[92]:
  training/Adadelta/gradients/block1_conv1/Conv2D
  training/Adadelta/gradients/block1_conv1/BiasAdd
  training/Adadelta/gradients/block1_conv1/Relu
  training/Adadelta/gradients/block1_conv2/Conv2D
  training/Adadelta/gradients/block1_conv2/BiasAdd
  training/Adadelta/gradients/block1_conv2/Relu
  training/Adadelta/gradients/block1_pool/MaxPool
  training/Adadelta/gradients/block2_pool/MaxPool
  training/Adadelta/gradients/block3_pool/MaxPool
  training/Adadelta/gradients/block4_conv2/Conv2D
  training/Adadelta/gradients/block4_conv2/BiasAdd
  training/Adadelta/gradients/block4_conv2/Relu
  training/Adadelta/gradients/block4_conv3/Conv2D
  training/Adadelta/gradients/block4_conv3/BiasAdd
  training/Adadelta/gradients/block4_conv3/Relu
  training/Adadelta/gradients/block4_pool/MaxPool
  training/Adadelta/gradients/zero_padding2d/Pad
  training/Adadelta/gradients/conv2d/Conv2D
  training/Adadelta/gradients/conv2d/BiasAdd
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3/Switch
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1/Switch
  training/Adadelta/gradients/batch_normalization/cond/Merge
  training/Adadelta/gradients/up_sampling2d/Shape
  training/Adadelta/gradients/up_sampling2d/strided_slice
  training/Adadelta/gradients/up_sampling2d/mul
  training/Adadelta/gradients/up_sampling2d/resize/ResizeNearestNeighbor
  training/Adadelta/gradients/concatenate/concat
  training/Adadelta/gradients/zero_padding2d_1/Pad
  training/Adadelta/gradients/conv2d_1/Conv2D
  training/Adadelta/gradients/conv2d_1/BiasAdd
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3/Switch
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1/Switch
  training/Adadelta/gradients/batch_normalization_1/cond/Merge
  training/Adadelta/gradients/up_sampling2d_1/Shape
  training/Adadelta/gradients/up_sampling2d_1/strided_slice
  training/Adadelta/gradients/up_sampling2d_1/mul
  training/Adadelta/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor
  training/Adadelta/gradients/concatenate_1/concat
  training/Adadelta/gradients/zero_padding2d_2/Pad
  training/Adadelta/gradients/conv2d_2/Conv2D
  training/Adadelta/gradients/conv2d_2/BiasAdd
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3/Switch
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1/Switch
  training/Adadelta/gradients/batch_normalization_2/cond/Merge
  training/Adadelta/gradients/up_sampling2d_2/Shape
  training/Adadelta/gradients/up_sampling2d_2/strided_slice
  training/Adadelta/gradients/up_sampling2d_2/mul
  training/Adadelta/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor
  training/Adadelta/gradients/concatenate_2/concat
  training/Adadelta/gradients/zero_padding2d_3/Pad
  training/Adadelta/gradients/conv2d_3/Conv2D
  training/Adadelta/gradients/conv2d_3/BiasAdd
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1/Switch
  training/Adadelta/gradients/batch_normalization_3/cond/Merge
  training/Adadelta/gradients/conv2d_4/Conv2D
  training/Adadelta/gradients/conv2d_4/BiasAdd
  training/Adadelta/gradients/reshape/Shape
  training/Adadelta/gradients/reshape/strided_slice
  training/Adadelta/gradients/reshape/Reshape/shape
  training/Adadelta/gradients/reshape/Reshape
  training/Adadelta/gradients/activation/Max
  training/Adadelta/gradients/activation/sub
  training/Adadelta/gradients/activation/Exp
  training/Adadelta/gradients/activation/Sum
  training/Adadelta/gradients/activation/truediv
  training/Adadelta/gradients/loss/activation_loss/Sum
  training/Adadelta/gradients/loss/activation_loss/truediv
  training/Adadelta/gradients/loss/activation_loss/clip_by_value/Minimum
  training/Adadelta/gradients/loss/activation_loss/clip_by_value
  training/Adadelta/gradients/loss/activation_loss/Log
  training/Adadelta/gradients/loss/activation_loss/mul
  training/Adadelta/gradients/loss/activation_loss/Sum_1
  training/Adadelta/gradients/loss/activation_loss/Neg
  training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like
  training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights
  training/Adadelta/gradients/loss/activation_loss/weighted_loss/Mul
  training/Adadelta/gradients/loss/activation_loss/Sum_2
  training/Adadelta/gradients/loss/activation_loss/num_elements
  training/Adadelta/gradients/loss/activation_loss/num_elements/Cast
  training/Adadelta/gradients/loss/activation_loss/Sum_3
  training/Adadelta/gradients/loss/activation_loss/value
  training/Adadelta/gradients/loss/mul
** inputs: empty
** outputs[53]:
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3:1
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3:2
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3:3
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3:4
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3:5
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3:1
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3:2
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3:3
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3:4
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3:5
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3:1
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3:2
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3:3
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3:4
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3:5
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3:1
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3:2
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3:3
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3:4
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3:5
  training/Adadelta/gradients/loss/mul:0
  training/Adadelta/gradients/batch_normalization_3/cond/Merge:1
  training/Adadelta/gradients/batch_normalization_2/cond/Merge:1
  training/Adadelta/gradients/batch_normalization_1/cond/Merge:1
  training/Adadelta/gradients/batch_normalization/cond/Merge:1
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1:1
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1:2
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1:3
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1:4
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1:5
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1:1
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1:2
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1:3
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1:4
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1:5
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1:1
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1:2
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1:3
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1:4
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1:5
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1/Switch:1
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1:1
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1:2
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1:3
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1:4
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1:5
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1/Switch:1
  training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch:0
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1/Switch:1
  training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3/Switch:0
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1/Switch:1
  training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3/Switch:0
  training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3/Switch:0

[STR DEBUG] Copied [<tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/mul' type=Mul>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate_1/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate_2/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/reshape/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/reshape/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/reshape/Reshape/shape' type=Pack>, <tf.Operation 'training/Adadelta/gradients/reshape/Reshape' type=Reshape>, <tf.Operation 'training/Adadelta/gradients/activation/Max' type=Max>, <tf.Operation 'training/Adadelta/gradients/activation/sub' type=Sub>, <tf.Operation 'training/Adadelta/gradients/activation/Exp' type=Exp>, <tf.Operation 'training/Adadelta/gradients/activation/Sum' type=Sum>, <tf.Operation 'training/Adadelta/gradients/activation/truediv' type=RealDiv>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Log' type=Log>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Neg' type=Neg>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/num_elements' type=Size>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'training/Adadelta/gradients/loss/mul' type=Mul>])
[STR DEBUG] Rewired dict_values([<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>]) in place of dict_keys([<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]) restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv3/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate_1/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'training/Adadelta/gradients/concatenate_2/concat' type=ConcatV2>, <tf.Operation 'training/Adadelta/gradients/zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'training/Adadelta/gradients/conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'training/Adadelta/gradients/batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'training/Adadelta/gradients/conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/reshape/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/reshape/strided_slice' type=StridedSlice>, <tf.Operation 'training/Adadelta/gradients/reshape/Reshape/shape' type=Pack>, <tf.Operation 'training/Adadelta/gradients/reshape/Reshape' type=Reshape>, <tf.Operation 'training/Adadelta/gradients/activation/Max' type=Max>, <tf.Operation 'training/Adadelta/gradients/activation/sub' type=Sub>, <tf.Operation 'training/Adadelta/gradients/activation/Exp' type=Exp>, <tf.Operation 'training/Adadelta/gradients/activation/Sum' type=Sum>, <tf.Operation 'training/Adadelta/gradients/activation/truediv' type=RealDiv>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Log' type=Log>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Neg' type=Neg>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/num_elements' type=Size>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'training/Adadelta/gradients/loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'training/Adadelta/gradients/loss/mul' type=Mul>])WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where

[STR DEBUG] Got gradients [None, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block2_pool/MaxPool_grad/MaxPoolGrad:0' shape=(?, 160, 320, 128) dtype=float32>, None, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block3_pool/MaxPool_grad/MaxPoolGrad:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 40, 80, 512) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_13:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_14:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_1/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_10:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_11:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_2/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_7:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_8:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_3/BiasAdd_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_4:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/AddN_5:0' shape=(?,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_4/BiasAdd_grad/BiasAddGrad:0' shape=(50,) dtype=float32>]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/loss/mul:0' shape=() dtype=float32>]
[STR DEBUG] with respect to ops, boundary:[<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] dv of checkpoints: {<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>: None, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block2_pool/MaxPool_grad/MaxPoolGrad:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>: None, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block3_pool/MaxPool_grad/MaxPoolGrad:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>: <tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 40, 80, 512) dtype=float32>}
[STR DEBUG] checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>], [<tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>], [<tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>], [<tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>], [<tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]]
[STR DEBUG] =========loop========
[STR DEBUG] Processing list [<tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] Found 4 ops to copy within [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'block4_conv1/Relu' type=Relu>], stop_at [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] ops_to_copy = [<tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Copied [<tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block3_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/Relu' type=Relu>])
[STR DEBUG] Rewired [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>] in place of [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>] restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block3_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block4_conv1/Relu' type=Relu>])
[STR DEBUG] Got gradients [None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_1/training/Adadelta/gradients/block3_pool/MaxPool_1_grad/MaxPoolGrad:0' shape=(?, 80, 160, 256) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_1/training/Adadelta/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_1/training/Adadelta/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0' shape=(512,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] with respect to boundary: [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>], xs: [<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] with boundary backprop substitutions [<tf.Tensor 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] =========end========
[STR DEBUG] =========loop========
[STR DEBUG] Processing list [<tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] Found 6 ops to copy within [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'block3_conv3/Relu' type=Relu>], stop_at [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] ops_to_copy = [<tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv3/Relu' type=Relu>]
[STR DEBUG] Copied [<tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv3/Relu' type=Relu>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/Relu' type=Relu>])
[STR DEBUG] Rewired [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>] in place of [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>] restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv2/Relu' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv3/Relu' type=Relu>])
[STR DEBUG] Got gradients [None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 80, 160, 256) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] with respect to boundary: [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>], xs: [<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] with boundary backprop substitutions [<tf.Tensor 'training/Adadelta/gradients/add:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] =========end========
[STR DEBUG] =========loop========
[STR DEBUG] Processing list [<tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] Found 4 ops to copy within [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'block3_conv1/Relu' type=Relu>], stop_at [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] ops_to_copy = [<tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>]
[STR DEBUG] Copied [<tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block2_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/Relu' type=Relu>])
[STR DEBUG] Rewired [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>] in place of [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>] restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block2_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block3_conv1/Relu' type=Relu>])
[STR DEBUG] Got gradients [None, <tf.Tensor 'training/Adadelta/gradients/gradients_3/training/Adadelta/gradients/block2_pool/MaxPool_1_grad/MaxPoolGrad:0' shape=(?, 160, 320, 128) dtype=float32>, None, None, None, None, None, None, None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_3/training/Adadelta/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_3/training/Adadelta/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0' shape=(256,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] with respect to boundary: [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>], xs: [<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] with boundary backprop substitutions [<tf.Tensor 'training/Adadelta/gradients/gradients_2/training/Adadelta/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 80, 160, 256) dtype=float32>]
[STR DEBUG] =========end========
[STR DEBUG] =========loop========
[STR DEBUG] Processing list [<tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] Found 3 ops to copy within [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'block2_conv2/Relu' type=Relu>], stop_at [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]
[STR DEBUG] ops_to_copy = [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv2/Relu' type=Relu>]
[STR DEBUG] Copied [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv2/Relu' type=Relu>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block2_conv2/Relu' type=Relu>])
[STR DEBUG] Rewired [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>] in place of [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>] restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block2_conv2/Relu' type=Relu>])
[STR DEBUG] Got gradients [<tf.Tensor 'training/Adadelta/gradients/gradients_4/training/Adadelta/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 160, 320, 128) dtype=float32>, None, None, None, None, None, None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_4/training/Adadelta/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_4/training/Adadelta/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] with respect to boundary: [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>], xs: [<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] with boundary backprop substitutions [<tf.Tensor 'training/Adadelta/gradients/add_1:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] =========end========
[STR DEBUG] =========loop========
[STR DEBUG] Processing list [<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] Found 10 ops to copy within [<tf.Operation 'block2_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'block3_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block4_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'block4_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'block3_conv3/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block4_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'block4_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'block3_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv2/Relu' type=Relu>, <tf.Operation 'block3_conv3/Relu' type=Relu>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'block4_conv2/Relu' type=Relu>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/Relu' type=Relu>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'block3_conv2/Relu' type=Relu>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'block4_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'activation/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'block3_pool/MaxPool' type=MaxPool>, <tf.Operation 'activation/Max' type=Max>, <tf.Operation 'block2_pool/MaxPool' type=MaxPool>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'activation/Exp' type=Exp>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>, <tf.Operation 'zero_padding2d/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'activation/Sum' type=Sum>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'activation/truediv' type=RealDiv>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'loss/activation_loss/truediv' type=RealDiv>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum' type=Sum>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'loss/activation_loss/clip_by_value/Minimum' type=Minimum>, <tf.Operation 'loss/activation_loss/clip_by_value' type=Maximum>, <tf.Operation 'loss/activation_loss/Log' type=Log>, <tf.Operation 'loss/activation_loss/mul' type=Mul>, <tf.Operation 'loss/activation_loss/Sum_1' type=Sum>, <tf.Operation 'loss/activation_loss/Neg' type=Neg>, <tf.Operation 'loss/activation_loss/weighted_loss/Mul' type=Mul>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like/Shape' type=Shape>, <tf.Operation 'loss/activation_loss/num_elements' type=Size>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights/ones_like' type=Fill>, <tf.Operation 'loss/activation_loss/Sum_2' type=Sum>, <tf.Operation 'loss/activation_loss/Sum_3' type=Sum>, <tf.Operation 'loss/activation_loss/weighted_loss/broadcast_weights' type=Mul>, <tf.Operation 'loss/activation_loss/num_elements/Cast' type=Cast>, <tf.Operation 'loss/activation_loss/value' type=DivNoNan>, <tf.Operation 'loss/mul' type=Mul>], seed [<tf.Operation 'block2_conv1/Relu' type=Relu>], stop_at [<tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>]2022-01-05 02:22:38.137908: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:22:38.137997: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:22:38.319774: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:22:38.319848: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:22:38.320660: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-05 02:22:38.320695: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2022-01-05 02:22:39.367778: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

[STR DEBUG] ops_to_copy = [<tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv2/Relu' type=Relu>]
[STR DEBUG] Copied [<tf.Operation 'block1_pool/MaxPool' type=MaxPool>, <tf.Operation 'block1_conv2/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block1_conv1/Relu' type=Relu>, <tf.Operation 'block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'block2_conv1/Relu' type=Relu>, <tf.Operation 'block1_conv2/BiasAdd' type=BiasAdd>, <tf.Operation 'block1_conv2/Relu' type=Relu>] to dict_values([<tf.Operation 'training/Adadelta/gradients/block1_conv1/Conv2D_1' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/BiasAdd_1' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/Relu_1' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Conv2D_1' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/BiasAdd_1' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Relu_1' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/Relu' type=Relu>])
[STR DEBUG] Rewired [<tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>] in place of [<tf.Tensor 'block2_conv2/Relu:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'block3_conv1/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block3_conv3/Relu:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'block4_conv1/Relu:0' shape=(?, 40, 80, 512) dtype=float32>] restricted to dict_values([<tf.Operation 'training/Adadelta/gradients/block1_conv1/Conv2D_1' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/BiasAdd_1' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv1/Relu_1' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Conv2D_1' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/BiasAdd_1' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block1_conv2/Relu_1' type=Relu>, <tf.Operation 'training/Adadelta/gradients/block1_pool/MaxPool_1' type=MaxPool>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/Conv2D' type=Conv2D>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/BiasAdd' type=BiasAdd>, <tf.Operation 'training/Adadelta/gradients/block2_conv1/Relu' type=Relu>])
[STR DEBUG] Got gradients [None, None, None, None, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block1_conv1/Conv2D_1_grad/Conv2DBackpropFilter:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block1_conv1/BiasAdd_1_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block1_conv2/Conv2D_1_grad/Conv2DBackpropFilter:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block1_conv2/BiasAdd_1_grad/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/gradients_5/training/Adadelta/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0' shape=(128,) dtype=float32>, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[STR DEBUG] for [<tf.Tensor 'training/Adadelta/gradients/block2_conv1/Relu:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] with respect to boundary: [<tf.Tensor 'training/Adadelta/gradients/block2_conv2/Relu_sg:0' shape=(?, 160, 320, 128) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv1/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block3_conv3/Relu_sg:0' shape=(?, 80, 160, 256) dtype=float32>, <tf.Tensor 'training/Adadelta/gradients/block4_conv1/Relu_sg:0' shape=(?, 40, 80, 512) dtype=float32>], xs: [<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'conv2d/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32>, <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 768, 256) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(256,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(256,) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 384, 128) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 192, 64) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 50) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(50,) dtype=float32>]
[STR DEBUG] with boundary backprop substitutions [<tf.Tensor 'training/Adadelta/gradients/gradients_4/training/Adadelta/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0' shape=(?, 160, 320, 128) dtype=float32>]
[STR DEBUG] =========end========
 1/64 [..............................] - ETA: 30:59 - loss: 4.4737 - acc: 0.0066 2/64 [..............................] - ETA: 17:26 - loss: 4.4659 - acc: 0.0066 3/64 [>.............................] - ETA: 12:54 - loss: 4.4601 - acc: 0.0068 4/64 [>.............................] - ETA: 10:34 - loss: 4.4606 - acc: 0.0068 5/64 [=>............................] - ETA: 9:08 - loss: 4.4673 - acc: 0.0067  6/64 [=>............................] - ETA: 8:11 - loss: 4.4681 - acc: 0.0066 7/64 [==>...........................] - ETA: 7:29 - loss: 4.4666 - acc: 0.0067 8/64 [==>...........................] - ETA: 6:56 - loss: 4.4629 - acc: 0.0069 9/64 [===>..........................] - ETA: 6:30 - loss: 4.4622 - acc: 0.006810/64 [===>..........................] - ETA: 6:07 - loss: 4.4592 - acc: 0.006911/64 [====>.........................] - ETA: 5:49 - loss: 4.4580 - acc: 0.006912/64 [====>.........................] - ETA: 5:33 - loss: 4.4585 - acc: 0.006913/64 [=====>........................] - ETA: 5:18 - loss: 4.4600 - acc: 0.006814/64 [=====>........................] - ETA: 5:04 - loss: 4.4595 - acc: 0.006915/64 [======>.......................] - ETA: 4:52 - loss: 4.4571 - acc: 0.006916/64 [======>.......................] - ETA: 4:42 - loss: 4.4566 - acc: 0.006917/64 [======>.......................] - ETA: 4:31 - loss: 4.4544 - acc: 0.007018/64 [=======>......................] - ETA: 4:22 - loss: 4.4532 - acc: 0.007019/64 [=======>......................] - ETA: 4:13 - loss: 4.4524 - acc: 0.007020/64 [========>.....................] - ETA: 4:04 - loss: 4.4540 - acc: 0.007021/64 [========>.....................] - ETA: 3:56 - loss: 4.4534 - acc: 0.007022/64 [=========>....................] - ETA: 3:49 - loss: 4.4517 - acc: 0.007023/64 [=========>....................] - ETA: 3:41 - loss: 4.4512 - acc: 0.007024/64 [==========>...................] - ETA: 3:34 - loss: 4.4499 - acc: 0.007025/64 [==========>...................] - ETA: 3:27 - loss: 4.4483 - acc: 0.007126/64 [===========>..................] - ETA: 3:21 - loss: 4.4476 - acc: 0.007127/64 [===========>..................] - ETA: 3:14 - loss: 4.4478 - acc: 0.007028/64 [============>.................] - ETA: 3:08 - loss: 4.4474 - acc: 0.007029/64 [============>.................] - ETA: 3:01 - loss: 4.4465 - acc: 0.007130/64 [=============>................] - ETA: 2:55 - loss: 4.4450 - acc: 0.007131/64 [=============>................] - ETA: 2:49 - loss: 4.4442 - acc: 0.007132/64 [==============>...............] - ETA: 2:43 - loss: 4.4427 - acc: 0.007133/64 [==============>...............] - ETA: 2:38 - loss: 4.4416 - acc: 0.007234/64 [==============>...............] - ETA: 2:32 - loss: 4.4412 - acc: 0.007135/64 [===============>..............] - ETA: 2:26 - loss: 4.4412 - acc: 0.007136/64 [===============>..............] - ETA: 2:21 - loss: 4.4405 - acc: 0.007137/64 [================>.............] - ETA: 2:15 - loss: 4.4391 - acc: 0.007238/64 [================>.............] - ETA: 2:10 - loss: 4.4383 - acc: 0.007239/64 [=================>............] - ETA: 2:04 - loss: 4.4371 - acc: 0.007240/64 [=================>............] - ETA: 1:59 - loss: 4.4359 - acc: 0.007241/64 [==================>...........] - ETA: 1:54 - loss: 4.4350 - acc: 0.007242/64 [==================>...........] - ETA: 1:48 - loss: 4.4353 - acc: 0.007243/64 [===================>..........] - ETA: 1:43 - loss: 4.4346 - acc: 0.007244/64 [===================>..........] - ETA: 1:38 - loss: 4.4334 - acc: 0.007345/64 [====================>.........] - ETA: 1:33 - loss: 4.4326 - acc: 0.007346/64 [====================>.........] - ETA: 1:28 - loss: 4.4316 - acc: 0.007347/64 [=====================>........] - ETA: 1:22 - loss: 4.4303 - acc: 0.007348/64 [=====================>........] - ETA: 1:17 - loss: 4.4295 - acc: 0.007349/64 [=====================>........] - ETA: 1:12 - loss: 4.4292 - acc: 0.007350/64 [======================>.......] - ETA: 1:07 - loss: 4.4287 - acc: 0.007351/64 [======================>.......] - ETA: 1:02 - loss: 4.4277 - acc: 0.007352/64 [=======================>......] - ETA: 57s - loss: 4.4266 - acc: 0.0074 53/64 [=======================>......] - ETA: 53s - loss: 4.4258 - acc: 0.007454/64 [========================>.....] - ETA: 48s - loss: 4.4245 - acc: 0.007455/64 [========================>.....] - ETA: 43s - loss: 4.4235 - acc: 0.007456/64 [=========================>....] - ETA: 38s - loss: 4.4229 - acc: 0.007457/64 [=========================>....] - ETA: 33s - loss: 4.4226 - acc: 0.007458/64 [==========================>...] - ETA: 28s - loss: 4.4218 - acc: 0.007459/64 [==========================>...] - ETA: 23s - loss: 4.4206 - acc: 0.007460/64 [===========================>..] - ETA: 19s - loss: 4.4199 - acc: 0.007461/64 [===========================>..] - ETA: 14s - loss: 4.4187 - acc: 0.007562/64 [============================>.] - ETA: 9s - loss: 4.4176 - acc: 0.0075 63/64 [============================>.] - ETA: 4s - loss: 4.4168 - acc: 0.007564/64 [==============================] - 303s 5s/step - loss: 4.4166 - acc: 0.0075
Finished Epoch 0
