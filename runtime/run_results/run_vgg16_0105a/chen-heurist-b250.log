WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/memory_saving_gradients.py:78: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 250), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'chen-heurist'), ('verbose', False)]
Shape of x_train: (50000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'false', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/layer_names'}, {}]
[STR DEBUG] Solution is not configured, use Chen's heuristic to select checkpoints
[STR DEBUG] Pure recomputing strategy with Chen's greedy strategy
DEBUG bwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Reshape/shape/1', 'flatten/Shape', 'flatten/strided_slice', 'flatten/strided_slice/stack', 'flatten/strided_slice/stack_1', 'flatten/strided_slice/stack_2', 'input_1', 'loss/mul', 'loss/mul/x', 'loss/predictions_loss/Const_1', 'loss/predictions_loss/Const_2', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/values_0', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/values_0', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Cast/x', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Const', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel', 'predictions_target']
DEBUG fwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel']
DEBUG bwd_ops after call the gradient function: ['training/RMSprop/gradients/1641274681034402/gradients/Fill', 'training/RMSprop/gradients/1641274681034402/gradients/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block1_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block2_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block2_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block3_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block3_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block4_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block4_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641274681034402/gradients/block5_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/block5_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641274681034402/gradients/fc1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/fc1/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641274681034402/gradients/fc1/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641274681034402/gradients/fc1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/fc2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/fc2/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641274681034402/gradients/fc2/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641274681034402/gradients/fc2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641274681034402/gradients/flatten/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/flatten/Reshape_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/grad_ys_0', 'training/RMSprop/gradients/1641274681034402/gradients/loss/mul_grad/Mul', 'training/RMSprop/gradients/1641274681034402/gradients/loss/mul_grad/Mul_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_1_grad/Const', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_1_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_1_grad/Reshape/shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_1_grad/Tile', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_grad/Reshape/shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/Sum_grad/Tile', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims/dim', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/LogSoftmax', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/Neg', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Neg', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Reshape_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Shape_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Sum', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/Sum_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/div_no_nan', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/div_no_nan_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/div_no_nan_2', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/value_grad/mul', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape_1', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum', 'training/RMSprop/gradients/1641274681034402/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum_1', 'training/RMSprop/gradients/1641274681034402/gradients/predictions/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641274681034402/gradients/predictions/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641274681034402/gradients/predictions/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641274681034402/gradients/zeros_like']
DEBUG Using tensors ['block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Relu:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Relu:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Relu:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Relu:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Relu:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Relu:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Relu:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Relu:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/Relu:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc2/MatMul/ReadVariableOp:0', 'flatten/Reshape:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Number of checkpoints: 5:
DEBUG [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>]


DEBUG checkpoints_disconnected: {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>}
DEBUG Found 27 ops to copy within fwd_ops ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['loss/mul'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp']
DEBUG Processing list ['loss/mul:0']
DEBUG Copied_svg: SubGraphView (graphid=140599234314816):
** ops[27]:
  training/RMSprop/gradients/fc2/MatMul/ReadVariableOp
  training/RMSprop/gradients/fc2/MatMul
  training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/fc2/BiasAdd
  training/RMSprop/gradients/fc2/Relu
  training/RMSprop/gradients/predictions/MatMul/ReadVariableOp
  training/RMSprop/gradients/predictions/MatMul
  training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/predictions/BiasAdd
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul
  training/RMSprop/gradients/loss/predictions_loss/Sum
  training/RMSprop/gradients/loss/predictions_loss/num_elements
  training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast
  training/RMSprop/gradients/loss/predictions_loss/Sum_1
  training/RMSprop/gradients/loss/predictions_loss/value
  training/RMSprop/gradients/loss/mul
** inputs: empty
** outputs[2]:
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits:1
  training/RMSprop/gradients/loss/mul:0

DEBUG Copied ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'] to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul_1:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/loss/mul:0']
DEBUG with respect to boundary:[<tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(4096, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]
DEBUG Checkpoint gradients before loop {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: None, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: None, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: None, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: None}
DEBUG checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>], [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>], [<tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>], [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>], [<tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]]
DEBUG Processing list ['fc1/Relu:0']
DEBUG Found 15 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['fc1/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0']
DEBUG ops_to_copy = ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice']
DEBUG Copied ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice'] to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0'] restricted to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/fc1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0']
DEBUG Processing list ['block5_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block5_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu']
DEBUG Copied ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu'] to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block5_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block4_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block4_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu']
DEBUG Copied ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu'] to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block4_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block3_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block3_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu']
DEBUG Copied ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu'] to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block3_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block2_conv1/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block2_conv1/Relu'], stop_at ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu']
DEBUG Copied ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu'] to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block2_conv1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0']
  1/200 [..............................] - ETA: 1:25:47 - loss: 2.4182 - acc: 0.0880  2/200 [..............................] - ETA: 46:36 - loss: 14788073.2091 - acc: 0.0840  3/200 [..............................] - ETA: 33:35 - loss: 9858717.8476 - acc: 0.0760   4/200 [..............................] - ETA: 27:05 - loss: 7394039.8657 - acc: 0.0810  5/200 [..............................] - ETA: 23:10 - loss: 5915235.4027 - acc: 0.0856  6/200 [..............................] - ETA: 20:42 - loss: 4929364.8564 - acc: 0.0933  7/200 [>.............................] - ETA: 19:13 - loss: 4225170.2151 - acc: 0.0937  8/200 [>.............................] - ETA: 17:56 - loss: 3697024.2889 - acc: 0.0960  9/200 [>.............................] - ETA: 16:56 - loss: 3286244.0687 - acc: 0.0987 10/200 [>.............................] - ETA: 16:08 - loss: 2957619.8914 - acc: 0.1000 11/200 [>.............................] - ETA: 15:24 - loss: 2688745.5843 - acc: 0.0982 12/200 [>.............................] - ETA: 14:45 - loss: 2464683.6440 - acc: 0.1010 13/200 [>.............................] - ETA: 14:14 - loss: 2275092.7718 - acc: 0.0985 14/200 [=>............................] - ETA: 13:53 - loss: 2112586.3097 - acc: 0.1017 15/200 [=>............................] - ETA: 13:44 - loss: 1971747.3759 - acc: 0.1051 16/200 [=>............................] - ETA: 13:35 - loss: 1848513.3085 - acc: 0.1042 17/200 [=>............................] - ETA: 13:21 - loss: 1739777.3650 - acc: 0.1052 18/200 [=>............................] - ETA: 13:08 - loss: 1643123.2133 - acc: 0.1053 19/200 [=>............................] - ETA: 12:56 - loss: 1556643.1655 - acc: 0.1042 20/200 [==>...........................] - ETA: 12:41 - loss: 1478811.1223 - acc: 0.1046 21/200 [==>...........................] - ETA: 12:28 - loss: 1408391.6548 - acc: 0.1053 22/200 [==>...........................] - ETA: 12:15 - loss: 1344373.9570 - acc: 0.1047 23/200 [==>...........................] - ETA: 12:08 - loss: 1285923.0153 - acc: 0.1054 24/200 [==>...........................] - ETA: 12:01 - loss: 1232342.9856 - acc: 0.1082 25/200 [==>...........................] - ETA: 11:54 - loss: 1183049.3582 - acc: 0.1074 26/200 [==>...........................] - ETA: 11:48 - loss: 1137547.5483 - acc: 0.1075 27/200 [===>..........................] - ETA: 11:42 - loss: 1095416.2427 - acc: 0.1074 28/200 [===>..........................] - ETA: 11:36 - loss: 1056294.3162 - acc: 0.1089 29/200 [===>..........................] - ETA: 11:30 - loss: 1019870.4556 - acc: 0.1088 30/200 [===>..........................] - ETA: 11:24 - loss: 985874.8505 - acc: 0.1075  31/200 [===>..........................] - ETA: 11:18 - loss: 954072.5102 - acc: 0.1077 32/200 [===>..........................] - ETA: 11:11 - loss: 924257.8163 - acc: 0.1076 33/200 [===>..........................] - ETA: 11:03 - loss: 896250.0735 - acc: 0.1067 34/200 [====>.........................] - ETA: 10:54 - loss: 869889.8450 - acc: 0.1061 35/200 [====>.........................] - ETA: 10:45 - loss: 845035.9152 - acc: 0.1064 36/200 [====>.........................] - ETA: 10:38 - loss: 821562.7592 - acc: 0.1073 37/200 [====>.........................] - ETA: 10:32 - loss: 799358.4226 - acc: 0.1075 38/200 [====>.........................] - ETA: 10:26 - loss: 778322.7351 - acc: 0.1076 39/200 [====>.........................] - ETA: 10:20 - loss: 758365.8010 - acc: 0.1078 40/200 [=====>........................] - ETA: 10:14 - loss: 739406.7134 - acc: 0.1083 41/200 [=====>........................] - ETA: 10:10 - loss: 721372.4599 - acc: 0.1077 42/200 [=====>........................] - ETA: 10:06 - loss: 704196.9800 - acc: 0.1084 43/200 [=====>........................] - ETA: 10:03 - loss: 687820.3595 - acc: 0.1088 44/200 [=====>........................] - ETA: 9:59 - loss: 672188.1309 - acc: 0.1083  45/200 [=====>........................] - ETA: 9:55 - loss: 657250.6681 - acc: 0.1076 46/200 [=====>........................] - ETA: 9:51 - loss: 642962.6600 - acc: 0.1075 47/200 [======>.......................] - ETA: 9:46 - loss: 629282.6521 - acc: 0.1079 48/200 [======>.......................] - ETA: 9:40 - loss: 616172.6438 - acc: 0.1082 49/200 [======>.......................] - ETA: 9:34 - loss: 603597.7388 - acc: 0.1083 50/200 [======>.......................] - ETA: 9:29 - loss: 591525.8322 - acc: 0.1081 51/200 [======>.......................] - ETA: 9:26 - loss: 579927.3318 - acc: 0.1075 52/200 [======>.......................] - ETA: 9:24 - loss: 568774.9273 - acc: 0.1075 53/200 [======>.......................] - ETA: 9:21 - loss: 558043.3683 - acc: 0.1078 54/200 [=======>......................] - ETA: 9:17 - loss: 547709.2745 - acc: 0.1079 55/200 [=======>......................] - ETA: 9:13 - loss: 537750.9659 - acc: 0.1081 56/200 [=======>......................] - ETA: 9:07 - loss: 528148.3112 - acc: 0.1076 57/200 [=======>......................] - ETA: 9:02 - loss: 518882.5917 - acc: 0.1081 58/200 [=======>......................] - ETA: 8:57 - loss: 509936.3799 - acc: 0.1077 59/200 [=======>......................] - ETA: 8:54 - loss: 501293.4295 - acc: 0.1071 60/200 [========>.....................] - ETA: 8:51 - loss: 492938.5773 - acc: 0.1066 61/200 [========>.....................] - ETA: 8:47 - loss: 484857.6547 - acc: 0.1075 62/200 [========>.....................] - ETA: 8:43 - loss: 477037.4130 - acc: 0.1075 63/200 [========>.....................] - ETA: 8:38 - loss: 469465.4270 - acc: 0.1075 64/200 [========>.....................] - ETA: 8:34 - loss: 462130.0660 - acc: 0.1067 65/200 [========>.....................] - ETA: 8:30 - loss: 455020.4081 - acc: 0.1068 66/200 [========>.....................] - ETA: 8:26 - loss: 448126.1944 - acc: 0.1063 67/200 [=========>....................] - ETA: 8:21 - loss: 441437.7781 - acc: 0.1056 68/200 [=========>....................] - ETA: 8:15 - loss: 434946.0799 - acc: 0.1057 69/200 [=========>....................] - ETA: 8:11 - loss: 428642.5490 - acc: 0.1059 70/200 [=========>....................] - ETA: 8:07 - loss: 422519.1169 - acc: 0.1058 71/200 [=========>....................] - ETA: 8:03 - loss: 416568.1759 - acc: 0.1060 72/200 [=========>....................] - ETA: 7:58 - loss: 410782.5387 - acc: 0.1057 73/200 [=========>....................] - ETA: 7:54 - loss: 405155.4122 - acc: 0.1056 74/200 [==========>...................] - ETA: 7:50 - loss: 399680.3701 - acc: 0.1058 75/200 [==========>...................] - ETA: 7:46 - loss: 394351.3576 - acc: 0.1058 76/200 [==========>...................] - ETA: 7:42 - loss: 389162.5543 - acc: 0.1059 77/200 [==========>...................] - ETA: 7:38 - loss: 384108.5250 - acc: 0.1058 78/200 [==========>...................] - ETA: 7:33 - loss: 379184.0863 - acc: 0.1054 79/200 [==========>...................] - ETA: 7:29 - loss: 374384.3169 - acc: 0.1054 80/200 [===========>..................] - ETA: 7:25 - loss: 369704.5434 - acc: 0.1054 81/200 [===========>..................] - ETA: 7:21 - loss: 365140.3182 - acc: 0.1054 82/200 [===========>..................] - ETA: 7:17 - loss: 360687.4155 - acc: 0.1057 83/200 [===========>..................] - ETA: 7:13 - loss: 356341.8117 - acc: 0.1058 84/200 [===========>..................] - ETA: 7:09 - loss: 352099.6758 - acc: 0.1057 85/200 [===========>..................] - ETA: 7:05 - loss: 347957.3538 - acc: 0.1054 86/200 [===========>..................] - ETA: 7:01 - loss: 343911.3648 - acc: 0.1064 87/200 [============>.................] - ETA: 6:57 - loss: 339958.3866 - acc: 0.1069 88/200 [============>.................] - ETA: 6:53 - loss: 336095.7867 - acc: 0.1066 89/200 [============>.................] - ETA: 6:50 - loss: 332319.4570 - acc: 0.1064 90/200 [============>.................] - ETA: 6:46 - loss: 328627.0441 - acc: 0.1061 91/200 [============>.................] - ETA: 6:42 - loss: 325015.7832 - acc: 0.1060 92/200 [============>.................] - ETA: 6:38 - loss: 321483.0280 - acc: 0.1060 93/200 [============>.................] - ETA: 6:34 - loss: 318026.2460 - acc: 0.1062 94/200 [=============>................] - ETA: 6:30 - loss: 314643.0126 - acc: 0.1058 95/200 [=============>................] - ETA: 6:26 - loss: 311331.0051 - acc: 0.1059 96/200 [=============>................] - ETA: 6:22 - loss: 308087.9978 - acc: 0.1062 97/200 [=============>................] - ETA: 6:19 - loss: 304911.8566 - acc: 0.1060 98/200 [=============>................] - ETA: 6:16 - loss: 301800.5351 - acc: 0.1057 99/200 [=============>................] - ETA: 6:12 - loss: 298752.0681 - acc: 0.1059100/200 [==============>...............] - ETA: 6:08 - loss: 295764.5705 - acc: 0.1062101/200 [==============>...............] - ETA: 6:05 - loss: 292836.2312 - acc: 0.1062102/200 [==============>...............] - ETA: 6:01 - loss: 289965.3103 - acc: 0.1060103/200 [==============>...............] - ETA: 5:57 - loss: 287150.1357 - acc: 0.1060104/200 [==============>...............] - ETA: 5:54 - loss: 284389.0989 - acc: 0.1055105/200 [==============>...............] - ETA: 5:50 - loss: 281680.6532 - acc: 0.1056106/200 [==============>...............] - ETA: 5:46 - loss: 279023.3104 - acc: 0.1059107/200 [===============>..............] - ETA: 5:43 - loss: 276415.6374 - acc: 0.1056108/200 [===============>..............] - ETA: 5:39 - loss: 273856.2547 - acc: 0.1055109/200 [===============>..............] - ETA: 5:35 - loss: 271343.8330 - acc: 0.1059110/200 [===============>..............] - ETA: 5:32 - loss: 268877.1055 - acc: 0.1061111/200 [===============>..............] - ETA: 5:28 - loss: 266454.8100 - acc: 0.1057112/200 [===============>..............] - ETA: 5:24 - loss: 264075.7696 - acc: 0.1059113/200 [===============>..............] - ETA: 5:20 - loss: 261738.8388 - acc: 0.1056114/200 [================>.............] - ETA: 5:16 - loss: 259442.9043 - acc: 0.1056115/200 [================>.............] - ETA: 5:12 - loss: 257186.8991 - acc: 0.1054116/200 [================>.............] - ETA: 5:08 - loss: 254969.7906 - acc: 0.1054117/200 [================>.............] - ETA: 5:04 - loss: 252790.5813 - acc: 0.1052118/200 [================>.............] - ETA: 5:00 - loss: 250648.3078 - acc: 0.1049119/200 [================>.............] - ETA: 4:56 - loss: 248542.0427 - acc: 0.1048120/200 [=================>............] - ETA: 4:53 - loss: 246470.8782 - acc: 0.1045121/200 [=================>............] - ETA: 4:49 - loss: 244433.9478 - acc: 0.1048122/200 [=================>............] - ETA: 4:46 - loss: 242430.4096 - acc: 0.1049123/200 [=================>............] - ETA: 4:42 - loss: 240459.4504 - acc: 0.1050124/200 [=================>............] - ETA: 4:39 - loss: 238520.2799 - acc: 0.1052125/200 [=================>............] - ETA: 4:36 - loss: 236612.1361 - acc: 0.1059126/200 [=================>............] - ETA: 4:32 - loss: 234734.2803 - acc: 0.1059127/200 [==================>...........] - ETA: 4:28 - loss: 232885.9970 - acc: 0.1057128/200 [==================>...........] - ETA: 4:25 - loss: 231066.5932 - acc: 0.1056129/200 [==================>...........] - ETA: 4:21 - loss: 229275.3971 - acc: 0.1054130/200 [==================>...........] - ETA: 4:17 - loss: 227511.7579 - acc: 0.1056131/200 [==================>...........] - ETA: 4:13 - loss: 225775.0447 - acc: 0.1060132/200 [==================>...........] - ETA: 4:09 - loss: 224064.6451 - acc: 0.1060133/200 [==================>...........] - ETA: 4:05 - loss: 222379.9658 - acc: 0.1060134/200 [===================>..........] - ETA: 4:02 - loss: 220720.4310 - acc: 0.1060135/200 [===================>..........] - ETA: 3:58 - loss: 219085.4819 - acc: 0.1059136/200 [===================>..........] - ETA: 3:53 - loss: 217474.5761 - acc: 0.1059137/200 [===================>..........] - ETA: 3:50 - loss: 215887.2006 - acc: 0.1059138/200 [===================>..........] - ETA: 3:47 - loss: 214322.8173 - acc: 0.1059139/200 [===================>..........] - ETA: 3:43 - loss: 212780.9431 - acc: 0.1059140/200 [====================>.........] - ETA: 3:40 - loss: 211261.0956 - acc: 0.1062141/200 [====================>.........] - ETA: 3:36 - loss: 209762.8063 - acc: 0.1062142/200 [====================>.........] - ETA: 3:32 - loss: 208285.6193 - acc: 0.1064143/200 [====================>.........] - ETA: 3:28 - loss: 206829.4284 - acc: 0.1065144/200 [====================>.........] - ETA: 3:24 - loss: 205393.1290 - acc: 0.1065145/200 [====================>.........] - ETA: 3:21 - loss: 203976.6405 - acc: 0.1065146/200 [====================>.........] - ETA: 3:17 - loss: 202579.5560 - acc: 0.1065147/200 [=====================>........] - ETA: 3:13 - loss: 201201.4794 - acc: 0.1065148/200 [=====================>........] - ETA: 3:10 - loss: 199842.0328 - acc: 0.1065149/200 [=====================>........] - ETA: 3:06 - loss: 198500.8265 - acc: 0.1064150/200 [=====================>........] - ETA: 3:02 - loss: 197177.5030 - acc: 0.1064151/200 [=====================>........] - ETA: 2:59 - loss: 195871.7070 - acc: 0.1063152/200 [=====================>........] - ETA: 2:55 - loss: 194583.0925 - acc: 0.1062153/200 [=====================>........] - ETA: 2:51 - loss: 193311.3226 - acc: 0.1061154/200 [======================>.......] - ETA: 2:48 - loss: 192056.0693 - acc: 0.1058155/200 [======================>.......] - ETA: 2:44 - loss: 190817.0128 - acc: 0.1056156/200 [======================>.......] - ETA: 2:40 - loss: 189593.8415 - acc: 0.1055157/200 [======================>.......] - ETA: 2:37 - loss: 188386.2521 - acc: 0.1057158/200 [======================>.......] - ETA: 2:33 - loss: 187193.9486 - acc: 0.1058159/200 [======================>.......] - ETA: 2:29 - loss: 186016.6425 - acc: 0.1059160/200 [=======================>......] - ETA: 2:26 - loss: 184854.0529 - acc: 0.1058161/200 [=======================>......] - ETA: 2:22 - loss: 183705.9054 - acc: 0.1059162/200 [=======================>......] - ETA: 2:18 - loss: 182571.9323 - acc: 0.1058163/200 [=======================>......] - ETA: 2:15 - loss: 181451.8833 - acc: 0.1057164/200 [=======================>......] - ETA: 2:11 - loss: 180345.4834 - acc: 0.1057165/200 [=======================>......] - ETA: 2:07 - loss: 179252.4944 - acc: 0.1056166/200 [=======================>......] - ETA: 2:04 - loss: 178172.6740 - acc: 0.1056167/200 [========================>.....] - ETA: 2:00 - loss: 177105.8186 - acc: 0.1057168/200 [========================>.....] - ETA: 1:56 - loss: 176051.6311 - acc: 0.1056169/200 [========================>.....] - ETA: 1:53 - loss: 175009.9191 - acc: 0.1059170/200 [========================>.....] - ETA: 1:49 - loss: 173980.4625 - acc: 0.1060171/200 [========================>.....] - ETA: 1:45 - loss: 172963.0463 - acc: 0.1061172/200 [========================>.....] - ETA: 1:42 - loss: 171957.4606 - acc: 0.1064173/200 [========================>.....] - ETA: 1:38 - loss: 170963.5002 - acc: 0.1063174/200 [=========================>....] - ETA: 1:34 - loss: 169980.9647 - acc: 0.1063175/200 [=========================>....] - ETA: 1:31 - loss: 169009.6581 - acc: 0.1063176/200 [=========================>....] - ETA: 1:27 - loss: 168049.3890 - acc: 0.1063177/200 [=========================>....] - ETA: 1:23 - loss: 167099.9703 - acc: 0.1065178/200 [=========================>....] - ETA: 1:20 - loss: 166161.2194 - acc: 0.1063179/200 [=========================>....] - ETA: 1:16 - loss: 165232.9573 - acc: 0.1063180/200 [==========================>...] - ETA: 1:12 - loss: 164315.0091 - acc: 0.1064181/200 [==========================>...] - ETA: 1:09 - loss: 163407.2047 - acc: 0.1067182/200 [==========================>...] - ETA: 1:05 - loss: 162509.3755 - acc: 0.1067183/200 [==========================>...] - ETA: 1:02 - loss: 161621.3587 - acc: 0.1066184/200 [==========================>...] - ETA: 58s - loss: 160742.9943 - acc: 0.1066 185/200 [==========================>...] - ETA: 54s - loss: 159874.1256 - acc: 0.1067186/200 [==========================>...] - ETA: 51s - loss: 159014.6050 - acc: 0.1067187/200 [===========================>..] - ETA: 47s - loss: 158164.2718 - acc: 0.1066188/200 [===========================>..] - ETA: 43s - loss: 157322.9847 - acc: 0.1065189/200 [===========================>..] - ETA: 40s - loss: 156490.6002 - acc: 0.1065190/200 [===========================>..] - ETA: 36s - loss: 155666.9775 - acc: 0.1068191/200 [===========================>..] - ETA: 32s - loss: 154851.9792 - acc: 0.1068192/200 [===========================>..] - ETA: 29s - loss: 154045.4705 - acc: 0.1069193/200 [===========================>..] - ETA: 25s - loss: 153247.3194 - acc: 0.1069194/200 [============================>.] - ETA: 21s - loss: 152457.3966 - acc: 0.1069195/200 [============================>.] - ETA: 18s - loss: 151675.5756 - acc: 0.1068196/200 [============================>.] - ETA: 14s - loss: 150901.7323 - acc: 0.1069197/200 [============================>.] - ETA: 10s - loss: 150135.7455 - acc: 0.1070198/200 [============================>.] - ETA: 7s - loss: 149377.4959 - acc: 0.1069 199/200 [============================>.] - ETA: 3s - loss: 148626.8667 - acc: 0.1070  1/200 [..............................] - ETA: 4:06 - loss: 2.3207 - acc: 0.1520  2/200 [..............................] - ETA: 3:32 - loss: 2.3164 - acc: 0.1520  3/200 [..............................] - ETA: 3:19 - loss: 2.3070 - acc: 0.1573  4/200 [..............................] - ETA: 3:12 - loss: 2.2992 - acc: 0.1500  5/200 [..............................] - ETA: 3:07 - loss: 2.2984 - acc: 0.1504  6/200 [..............................] - ETA: 3:05 - loss: 2.3025 - acc: 0.1440  7/200 [>.............................] - ETA: 3:03 - loss: 2.2989 - acc: 0.1394  8/200 [>.............................] - ETA: 3:02 - loss: 2.2970 - acc: 0.1395  9/200 [>.............................] - ETA: 3:00 - loss: 2.2971 - acc: 0.1369 10/200 [>.............................] - ETA: 2:58 - loss: 2.2977 - acc: 0.1404 11/200 [>.............................] - ETA: 2:57 - loss: 2.2981 - acc: 0.1385 12/200 [>.............................] - ETA: 2:56 - loss: 2.2962 - acc: 0.1350 13/200 [>.............................] - ETA: 2:55 - loss: 2.2999 - acc: 0.1335 14/200 [=>............................] - ETA: 2:52 - loss: 2.3007 - acc: 0.1311 15/200 [=>............................] - ETA: 2:52 - loss: 2.2996 - acc: 0.1312 16/200 [=>............................] - ETA: 2:54 - loss: 2.2990 - acc: 0.1310 17/200 [=>............................] - ETA: 2:54 - loss: 2.2974 - acc: 0.1315 18/200 [=>............................] - ETA: 2:54 - loss: 2.2998 - acc: 0.1313 19/200 [=>............................] - ETA: 2:53 - loss: 2.2974 - acc: 0.1339 20/200 [==>...........................] - ETA: 2:51 - loss: 2.2977 - acc: 0.1342 21/200 [==>...........................] - ETA: 2:50 - loss: 2.2977 - acc: 0.1345 22/200 [==>...........................] - ETA: 2:48 - loss: 2.2984 - acc: 0.1340 23/200 [==>...........................] - ETA: 2:46 - loss: 2.2967 - acc: 0.1350 24/200 [==>...........................] - ETA: 2:45 - loss: 2.2947 - acc: 0.1347 25/200 [==>...........................] - ETA: 2:44 - loss: 2.2968 - acc: 0.1323 26/200 [==>...........................] - ETA: 2:43 - loss: 2.2963 - acc: 0.1329 27/200 [===>..........................] - ETA: 2:42 - loss: 2.2955 - acc: 0.1336 28/200 [===>..........................] - ETA: 2:41 - loss: 2.2962 - acc: 0.1340 29/200 [===>..........................] - ETA: 2:40 - loss: 2.2960 - acc: 0.1334 30/200 [===>..........................] - ETA: 2:39 - loss: 2.2962 - acc: 0.1321 31/200 [===>..........................] - ETA: 2:38 - loss: 2.2955 - acc: 0.1321 32/200 [===>..........................] - ETA: 2:37 - loss: 2.2954 - acc: 0.1325 33/200 [===>..........................] - ETA: 2:36 - loss: 2.2957 - acc: 0.1327 34/200 [====>.........................] - ETA: 2:35 - loss: 2.2966 - acc: 0.1327 35/200 [====>.........................] - ETA: 2:33 - loss: 2.2956 - acc: 0.1341 36/200 [====>.........................] - ETA: 2:32 - loss: 2.2944 - acc: 0.1357 37/200 [====>.........................] - ETA: 2:31 - loss: 2.2944 - acc: 0.1351 38/200 [====>.........................] - ETA: 2:30 - loss: 2.2938 - acc: 0.1352 39/200 [====>.........................] - ETA: 2:29 - loss: 2.2931 - acc: 0.1366 40/200 [=====>........................] - ETA: 2:28 - loss: 2.2933 - acc: 0.1356200/200 [==============================] - 764s 4s/step - loss: 147883.7437 - acc: 0.1072 - val_loss: 2.2933 - val_acc: 0.1356
