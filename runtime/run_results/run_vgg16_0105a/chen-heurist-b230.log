WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/memory_saving_gradients.py:78: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 230), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'chen-heurist'), ('verbose', False)]
Shape of x_train: (50000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
Cannot find config for batch_size=230, use 256 instead
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/p32xlarge_VGG16_256_None/ilp_log/layer_names'}, {}]
[STR DEBUG] Solution is not configured, use Chen's heuristic to select checkpoints
[STR DEBUG] Pure recomputing strategy with Chen's greedy strategy
DEBUG bwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Reshape/shape/1', 'flatten/Shape', 'flatten/strided_slice', 'flatten/strided_slice/stack', 'flatten/strided_slice/stack_1', 'flatten/strided_slice/stack_2', 'input_1', 'loss/mul', 'loss/mul/x', 'loss/predictions_loss/Const_1', 'loss/predictions_loss/Const_2', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/values_0', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/values_0', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Cast/x', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Const', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel', 'predictions_target']
DEBUG fwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel']
DEBUG bwd_ops after call the gradient function: ['training/RMSprop/gradients/1641268416271758/gradients/Fill', 'training/RMSprop/gradients/1641268416271758/gradients/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block1_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block2_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block2_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block3_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block3_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block4_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block4_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641268416271758/gradients/block5_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/block5_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641268416271758/gradients/fc1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/fc1/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641268416271758/gradients/fc1/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641268416271758/gradients/fc1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/fc2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/fc2/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641268416271758/gradients/fc2/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641268416271758/gradients/fc2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641268416271758/gradients/flatten/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/flatten/Reshape_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/grad_ys_0', 'training/RMSprop/gradients/1641268416271758/gradients/loss/mul_grad/Mul', 'training/RMSprop/gradients/1641268416271758/gradients/loss/mul_grad/Mul_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_1_grad/Const', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_1_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_1_grad/Reshape/shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_1_grad/Tile', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_grad/Reshape/shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/Sum_grad/Tile', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims/dim', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/LogSoftmax', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/Neg', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Neg', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Reshape_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Shape_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Sum', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/Sum_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/div_no_nan', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/div_no_nan_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/div_no_nan_2', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/value_grad/mul', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape_1', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum', 'training/RMSprop/gradients/1641268416271758/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum_1', 'training/RMSprop/gradients/1641268416271758/gradients/predictions/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641268416271758/gradients/predictions/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641268416271758/gradients/predictions/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641268416271758/gradients/zeros_like']
DEBUG Using tensors ['block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Relu:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Relu:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Relu:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Relu:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Relu:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Relu:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Relu:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Relu:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/Relu:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc2/MatMul/ReadVariableOp:0', 'flatten/Reshape:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Number of checkpoints: 5:
DEBUG [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>]


DEBUG checkpoints_disconnected: {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>}
DEBUG Found 27 ops to copy within fwd_ops ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['loss/mul'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp']
DEBUG Processing list ['loss/mul:0']
DEBUG Copied_svg: SubGraphView (graphid=139660194491864):
** ops[27]:
  training/RMSprop/gradients/fc2/MatMul/ReadVariableOp
  training/RMSprop/gradients/fc2/MatMul
  training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/fc2/BiasAdd
  training/RMSprop/gradients/fc2/Relu
  training/RMSprop/gradients/predictions/MatMul/ReadVariableOp
  training/RMSprop/gradients/predictions/MatMul
  training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/predictions/BiasAdd
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul
  training/RMSprop/gradients/loss/predictions_loss/Sum
  training/RMSprop/gradients/loss/predictions_loss/num_elements
  training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast
  training/RMSprop/gradients/loss/predictions_loss/Sum_1
  training/RMSprop/gradients/loss/predictions_loss/value
  training/RMSprop/gradients/loss/mul
** inputs: empty
** outputs[2]:
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits:1
  training/RMSprop/gradients/loss/mul:0

DEBUG Copied ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'] to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul_1:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/loss/mul:0']
DEBUG with respect to boundary:[<tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(4096, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]
DEBUG Checkpoint gradients before loop {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: None, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: None, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: None, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: None}
DEBUG checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>], [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>], [<tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>], [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>], [<tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]]
DEBUG Processing list ['fc1/Relu:0']
DEBUG Found 15 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['fc1/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0']
DEBUG ops_to_copy = ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice']
DEBUG Copied ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice'] to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0'] restricted to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/fc1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0']
DEBUG Processing list ['block5_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block5_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu']
DEBUG Copied ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu'] to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block5_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block4_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block4_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu']
DEBUG Copied ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu'] to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block4_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block3_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block3_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu']
DEBUG Copied ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu'] to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block3_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block2_conv1/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block2_conv1/Relu'], stop_at ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu']
DEBUG Copied ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu'] to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block2_conv1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0']
  1/218 [..............................] - ETA: 1:27:32 - loss: 2.3458 - acc: 0.0783  2/218 [..............................] - ETA: 47:28 - loss: 42485653.1729 - acc: 0.0957  3/218 [..............................] - ETA: 34:05 - loss: 28323789.5328 - acc: 0.0957  4/218 [..............................] - ETA: 27:22 - loss: 21243678.7765 - acc: 0.0989  5/218 [..............................] - ETA: 23:21 - loss: 16994947.9974 - acc: 0.1009  6/218 [..............................] - ETA: 20:46 - loss: 14162457.2114 - acc: 0.1065  7/218 [..............................] - ETA: 18:54 - loss: 12139249.3838 - acc: 0.1081  8/218 [>.............................] - ETA: 17:31 - loss: 10621843.4985 - acc: 0.1103  9/218 [>.............................] - ETA: 16:27 - loss: 9441638.9456 - acc: 0.1077  10/218 [>.............................] - ETA: 15:35 - loss: 8497475.2810 - acc: 0.1074 11/218 [>.............................] - ETA: 14:56 - loss: 7724977.7374 - acc: 0.1087 12/218 [>.............................] - ETA: 14:24 - loss: 7081229.7837 - acc: 0.1094 13/218 [>.............................] - ETA: 13:57 - loss: 6536519.9796 - acc: 0.1080 14/218 [>.............................] - ETA: 13:44 - loss: 6069625.8593 - acc: 0.1056 15/218 [=>............................] - ETA: 13:32 - loss: 5664984.3122 - acc: 0.1070 16/218 [=>............................] - ETA: 13:16 - loss: 5310922.9365 - acc: 0.1079 17/218 [=>............................] - ETA: 13:02 - loss: 4998515.8400 - acc: 0.1061 18/218 [=>............................] - ETA: 12:49 - loss: 4720820.6421 - acc: 0.1060 19/218 [=>............................] - ETA: 12:37 - loss: 4472356.5201 - acc: 0.1046 20/218 [=>............................] - ETA: 12:25 - loss: 4248738.8254 - acc: 0.1063 21/218 [=>............................] - ETA: 12:15 - loss: 4046418.0390 - acc: 0.1068 22/218 [==>...........................] - ETA: 12:05 - loss: 3862490.0508 - acc: 0.1057 23/218 [==>...........................] - ETA: 11:57 - loss: 3694555.8008 - acc: 0.1062 24/218 [==>...........................] - ETA: 11:48 - loss: 3540616.0718 - acc: 0.1065 25/218 [==>...........................] - ETA: 11:40 - loss: 3398991.5206 - acc: 0.1056 26/218 [==>...........................] - ETA: 11:32 - loss: 3268261.1641 - acc: 0.1054 27/218 [==>...........................] - ETA: 11:22 - loss: 3147214.5397 - acc: 0.1048 28/218 [==>...........................] - ETA: 11:13 - loss: 3034814.1025 - acc: 0.1059 29/218 [==>...........................] - ETA: 11:05 - loss: 2930165.4289 - acc: 0.1052 30/218 [===>..........................] - ETA: 10:57 - loss: 2832493.3249 - acc: 0.1046 31/218 [===>..........................] - ETA: 10:49 - loss: 2741122.6467 - acc: 0.1053 32/218 [===>..........................] - ETA: 10:42 - loss: 2655462.6361 - acc: 0.1041 33/218 [===>..........................] - ETA: 10:35 - loss: 2574994.1407 - acc: 0.1046 34/218 [===>..........................] - ETA: 10:33 - loss: 2499259.0871 - acc: 0.1041 35/218 [===>..........................] - ETA: 10:30 - loss: 2427851.7503 - acc: 0.1043 36/218 [===>..........................] - ETA: 10:28 - loss: 2360411.4876 - acc: 0.1039 37/218 [====>.........................] - ETA: 10:25 - loss: 2296616.6444 - acc: 0.1029 38/218 [====>.........................] - ETA: 10:23 - loss: 2236179.4242 - acc: 0.1039 39/218 [====>.........................] - ETA: 10:20 - loss: 2178841.5496 - acc: 0.1041 40/218 [====>.........................] - ETA: 10:15 - loss: 2124370.5685 - acc: 0.1034 41/218 [====>.........................] - ETA: 10:11 - loss: 2072556.7114 - acc: 0.1036 42/218 [====>.........................] - ETA: 10:06 - loss: 2023210.1772 - acc: 0.1039 43/218 [====>.........................] - ETA: 10:01 - loss: 1976158.8311 - acc: 0.1042 44/218 [=====>........................] - ETA: 9:56 - loss: 1931246.1826 - acc: 0.1051  45/218 [=====>........................] - ETA: 9:50 - loss: 1888329.6518 - acc: 0.1046 46/218 [=====>........................] - ETA: 9:44 - loss: 1847279.0568 - acc: 0.1044 47/218 [=====>........................] - ETA: 9:39 - loss: 1807975.2953 - acc: 0.1054 48/218 [=====>........................] - ETA: 9:34 - loss: 1770309.1898 - acc: 0.1064 49/218 [=====>........................] - ETA: 9:29 - loss: 1734180.4985 - acc: 0.1058 50/218 [=====>........................] - ETA: 9:24 - loss: 1699496.9346 - acc: 0.1048 51/218 [======>.......................] - ETA: 9:22 - loss: 1666173.5105 - acc: 0.1049 52/218 [======>.......................] - ETA: 9:20 - loss: 1634131.7565 - acc: 0.1048 53/218 [======>.......................] - ETA: 9:18 - loss: 1603299.1253 - acc: 0.1048 54/218 [======>.......................] - ETA: 9:15 - loss: 1573608.4433 - acc: 0.1053 55/218 [======>.......................] - ETA: 9:12 - loss: 1544997.4225 - acc: 0.1055 56/218 [======>.......................] - ETA: 9:08 - loss: 1517408.2239 - acc: 0.1047 57/218 [======>.......................] - ETA: 9:04 - loss: 1490787.0672 - acc: 0.1048 58/218 [======>.......................] - ETA: 8:59 - loss: 1465083.8817 - acc: 0.1044 59/218 [=======>......................] - ETA: 8:55 - loss: 1440251.9905 - acc: 0.1041 60/218 [=======>......................] - ETA: 8:50 - loss: 1416247.8289 - acc: 0.1045 61/218 [=======>......................] - ETA: 8:45 - loss: 1393030.6971 - acc: 0.1037 62/218 [=======>......................] - ETA: 8:41 - loss: 1370562.4972 - acc: 0.1037 63/218 [=======>......................] - ETA: 8:36 - loss: 1348807.5731 - acc: 0.1037 64/218 [=======>......................] - ETA: 8:32 - loss: 1327732.5021 - acc: 0.1039 65/218 [=======>......................] - ETA: 8:28 - loss: 1307305.8836 - acc: 0.1043 66/218 [========>.....................] - ETA: 8:23 - loss: 1287498.2536 - acc: 0.1048 67/218 [========>.....................] - ETA: 8:19 - loss: 1268281.8961 - acc: 0.1050 68/218 [========>.....................] - ETA: 8:16 - loss: 1249630.7256 - acc: 0.1053 69/218 [========>.....................] - ETA: 8:12 - loss: 1231520.1687 - acc: 0.1051 70/218 [========>.....................] - ETA: 8:09 - loss: 1213927.0561 - acc: 0.1060 71/218 [========>.....................] - ETA: 8:06 - loss: 1196829.5359 - acc: 0.1055 72/218 [========>.....................] - ETA: 8:02 - loss: 1180206.9354 - acc: 0.1055 73/218 [=========>....................] - ETA: 7:59 - loss: 1164039.7489 - acc: 0.1058 74/218 [=========>....................] - ETA: 7:56 - loss: 1148309.5131 - acc: 0.1059 75/218 [=========>....................] - ETA: 7:52 - loss: 1132998.7503 - acc: 0.1056 76/218 [=========>....................] - ETA: 7:49 - loss: 1118090.9022 - acc: 0.1057 77/218 [=========>....................] - ETA: 7:46 - loss: 1103570.2710 - acc: 0.1063 78/218 [=========>....................] - ETA: 7:42 - loss: 1089421.9637 - acc: 0.1062 79/218 [=========>....................] - ETA: 7:38 - loss: 1075631.8413 - acc: 0.1058 80/218 [==========>...................] - ETA: 7:34 - loss: 1062186.4720 - acc: 0.1057 81/218 [==========>...................] - ETA: 7:30 - loss: 1049073.0865 - acc: 0.1056 82/218 [==========>...................] - ETA: 7:26 - loss: 1036279.5438 - acc: 0.1056 83/218 [==========>...................] - ETA: 7:22 - loss: 1023794.2758 - acc: 0.1054 84/218 [==========>...................] - ETA: 7:18 - loss: 1011606.2761 - acc: 0.1051 85/218 [==========>...................] - ETA: 7:15 - loss: 999705.0526 - acc: 0.1056  86/218 [==========>...................] - ETA: 7:11 - loss: 988080.6020 - acc: 0.1053 87/218 [==========>...................] - ETA: 7:08 - loss: 976723.3802 - acc: 0.1051 88/218 [===========>..................] - ETA: 7:05 - loss: 965624.2770 - acc: 0.1049 89/218 [===========>..................] - ETA: 7:01 - loss: 954774.5919 - acc: 0.1047 90/218 [===========>..................] - ETA: 6:58 - loss: 944166.0109 - acc: 0.1047 91/218 [===========>..................] - ETA: 6:55 - loss: 933790.5854 - acc: 0.1049 92/218 [===========>..................] - ETA: 6:51 - loss: 923640.7124 - acc: 0.1052 93/218 [===========>..................] - ETA: 6:48 - loss: 913709.1166 - acc: 0.1048 94/218 [===========>..................] - ETA: 6:45 - loss: 903988.8313 - acc: 0.1047 95/218 [============>.................] - ETA: 6:42 - loss: 894473.1836 - acc: 0.1047 96/218 [============>.................] - ETA: 6:38 - loss: 885155.7786 - acc: 0.1046 97/218 [============>.................] - ETA: 6:35 - loss: 876030.4852 - acc: 0.1045 98/218 [============>.................] - ETA: 6:32 - loss: 867091.4222 - acc: 0.1040 99/218 [============>.................] - ETA: 6:28 - loss: 858332.9461 - acc: 0.1043100/218 [============>.................] - ETA: 6:25 - loss: 849749.6396 - acc: 0.1044101/218 [============>.................] - ETA: 6:22 - loss: 841336.2997 - acc: 0.1045102/218 [=============>................] - ETA: 6:19 - loss: 833087.9271 - acc: 0.1051103/218 [=============>................] - ETA: 6:15 - loss: 824999.7169 - acc: 0.1052104/218 [=============>................] - ETA: 6:12 - loss: 817067.0484 - acc: 0.1056105/218 [=============>................] - ETA: 6:09 - loss: 809285.6070 - acc: 0.1055106/218 [=============>................] - ETA: 6:05 - loss: 801650.8588 - acc: 0.1056107/218 [=============>................] - ETA: 6:02 - loss: 794158.8162 - acc: 0.1055108/218 [=============>................] - ETA: 5:59 - loss: 786805.5152 - acc: 0.1055109/218 [==============>...............] - ETA: 5:56 - loss: 779587.1369 - acc: 0.1061110/218 [==============>...............] - ETA: 5:52 - loss: 772500.0020 - acc: 0.1060111/218 [==============>...............] - ETA: 5:49 - loss: 765540.5656 - acc: 0.1062112/218 [==============>...............] - ETA: 5:46 - loss: 758705.4026 - acc: 0.1061113/218 [==============>...............] - ETA: 5:43 - loss: 751991.2157 - acc: 0.1063114/218 [==============>...............] - ETA: 5:39 - loss: 745394.8224 - acc: 0.1063115/218 [==============>...............] - ETA: 5:36 - loss: 738913.1483 - acc: 0.1061116/218 [==============>...............] - ETA: 5:33 - loss: 732543.2272 - acc: 0.1061117/218 [===============>..............] - ETA: 5:29 - loss: 726282.1939 - acc: 0.1060118/218 [===============>..............] - ETA: 5:26 - loss: 720127.2796 - acc: 0.1058119/218 [===============>..............] - ETA: 5:22 - loss: 714075.8092 - acc: 0.1058120/218 [===============>..............] - ETA: 5:18 - loss: 708125.1967 - acc: 0.1056121/218 [===============>..............] - ETA: 5:15 - loss: 702272.9413 - acc: 0.1054122/218 [===============>..............] - ETA: 5:11 - loss: 696516.6246 - acc: 0.1057123/218 [===============>..............] - ETA: 5:08 - loss: 690853.9064 - acc: 0.1058124/218 [================>.............] - ETA: 5:04 - loss: 685282.5304 - acc: 0.1060125/218 [================>.............] - ETA: 5:01 - loss: 679800.2886 - acc: 0.1058126/218 [================>.............] - ETA: 4:58 - loss: 674405.0665 - acc: 0.1057127/218 [================>.............] - ETA: 4:55 - loss: 669094.8124 - acc: 0.1056128/218 [================>.............] - ETA: 4:52 - loss: 663867.5271 - acc: 0.1056129/218 [================>.............] - ETA: 4:48 - loss: 658721.2851 - acc: 0.1056130/218 [================>.............] - ETA: 4:45 - loss: 653654.2160 - acc: 0.1060131/218 [=================>............] - ETA: 4:42 - loss: 648664.5068 - acc: 0.1058132/218 [=================>............] - ETA: 4:39 - loss: 643750.3992 - acc: 0.1058133/218 [=================>............] - ETA: 4:36 - loss: 638910.1879 - acc: 0.1063134/218 [=================>............] - ETA: 4:32 - loss: 634142.2185 - acc: 0.1064135/218 [=================>............] - ETA: 4:29 - loss: 629444.9059 - acc: 0.1062136/218 [=================>............] - ETA: 4:26 - loss: 624816.6514 - acc: 0.1062137/218 [=================>............] - ETA: 4:23 - loss: 620255.9628 - acc: 0.1063138/218 [=================>............] - ETA: 4:19 - loss: 615761.3710 - acc: 0.1063139/218 [==================>...........] - ETA: 4:16 - loss: 611331.4636 - acc: 0.1061140/218 [==================>...........] - ETA: 4:13 - loss: 606964.8268 - acc: 0.1061141/218 [==================>...........] - ETA: 4:10 - loss: 602660.1280 - acc: 0.1060142/218 [==================>...........] - ETA: 4:07 - loss: 598416.0588 - acc: 0.1059143/218 [==================>...........] - ETA: 4:03 - loss: 594231.3472 - acc: 0.1058144/218 [==================>...........] - ETA: 4:00 - loss: 590104.7566 - acc: 0.1063145/218 [==================>...........] - ETA: 3:57 - loss: 586035.0844 - acc: 0.1064146/218 [===================>..........] - ETA: 3:54 - loss: 582021.1613 - acc: 0.1065147/218 [===================>..........] - ETA: 3:51 - loss: 578061.8494 - acc: 0.1062148/218 [===================>..........] - ETA: 3:47 - loss: 574156.0416 - acc: 0.1064149/218 [===================>..........] - ETA: 3:44 - loss: 570302.6610 - acc: 0.1061150/218 [===================>..........] - ETA: 3:41 - loss: 566500.6586 - acc: 0.1062151/218 [===================>..........] - ETA: 3:37 - loss: 562749.0138 - acc: 0.1064152/218 [===================>..........] - ETA: 3:34 - loss: 559046.7328 - acc: 0.1064153/218 [====================>.........] - ETA: 3:30 - loss: 555392.8477 - acc: 0.1063154/218 [====================>.........] - ETA: 3:27 - loss: 551786.4155 - acc: 0.1062155/218 [====================>.........] - ETA: 3:24 - loss: 548226.5180 - acc: 0.1061156/218 [====================>.........] - ETA: 3:21 - loss: 544712.2601 - acc: 0.1063157/218 [====================>.........] - ETA: 3:18 - loss: 541242.7700 - acc: 0.1063158/218 [====================>.........] - ETA: 3:14 - loss: 537817.1974 - acc: 0.1062159/218 [====================>.........] - ETA: 3:15 - loss: 534434.7137 - acc: 0.1062160/218 [=====================>........] - ETA: 3:12 - loss: 531094.5108 - acc: 0.1063161/218 [=====================>........] - ETA: 3:08 - loss: 527795.8786 - acc: 0.1062162/218 [=====================>........] - ETA: 3:05 - loss: 524537.8935 - acc: 0.1063163/218 [=====================>........] - ETA: 3:02 - loss: 521319.8855 - acc: 0.1067164/218 [=====================>........] - ETA: 2:58 - loss: 518141.1198 - acc: 0.1066165/218 [=====================>........] - ETA: 2:55 - loss: 515000.8845 - acc: 0.1067166/218 [=====================>........] - ETA: 2:52 - loss: 511898.4833 - acc: 0.1072167/218 [=====================>........] - ETA: 2:48 - loss: 508833.2707 - acc: 0.1072168/218 [======================>.......] - ETA: 2:45 - loss: 505804.5150 - acc: 0.1071169/218 [======================>.......] - ETA: 2:41 - loss: 502811.6025 - acc: 0.1071170/218 [======================>.......] - ETA: 2:38 - loss: 499853.9007 - acc: 0.1070171/218 [======================>.......] - ETA: 2:35 - loss: 496930.7919 - acc: 0.1070172/218 [======================>.......] - ETA: 2:31 - loss: 494041.6728 - acc: 0.1071173/218 [======================>.......] - ETA: 2:28 - loss: 491185.9539 - acc: 0.1072174/218 [======================>.......] - ETA: 2:25 - loss: 488363.0593 - acc: 0.1070175/218 [=======================>......] - ETA: 2:22 - loss: 485572.4264 - acc: 0.1071176/218 [=======================>......] - ETA: 2:18 - loss: 482813.5053 - acc: 0.1072177/218 [=======================>......] - ETA: 2:15 - loss: 480085.7583 - acc: 0.1074178/218 [=======================>......] - ETA: 2:11 - loss: 477388.6602 - acc: 0.1076179/218 [=======================>......] - ETA: 2:08 - loss: 474721.6981 - acc: 0.1075180/218 [=======================>......] - ETA: 2:05 - loss: 472084.3681 - acc: 0.1073181/218 [=======================>......] - ETA: 2:01 - loss: 469476.1799 - acc: 0.1073182/218 [========================>.....] - ETA: 1:58 - loss: 466896.6531 - acc: 0.1073183/218 [========================>.....] - ETA: 1:55 - loss: 464345.3178 - acc: 0.1072184/218 [========================>.....] - ETA: 1:51 - loss: 461821.7145 - acc: 0.1072185/218 [========================>.....] - ETA: 1:48 - loss: 459325.3933 - acc: 0.1074186/218 [========================>.....] - ETA: 1:45 - loss: 456855.9155 - acc: 0.1073187/218 [========================>.....] - ETA: 1:41 - loss: 454412.8481 - acc: 0.1071188/218 [========================>.....] - ETA: 1:38 - loss: 451995.7707 - acc: 0.1071189/218 [=========================>....] - ETA: 1:35 - loss: 449604.2709 - acc: 0.1072190/218 [=========================>....] - ETA: 1:32 - loss: 447237.9447 - acc: 0.1072191/218 [=========================>....] - ETA: 1:28 - loss: 444896.3968 - acc: 0.1073192/218 [=========================>....] - ETA: 1:25 - loss: 442579.2400 - acc: 0.1073193/218 [=========================>....] - ETA: 1:22 - loss: 440286.0952 - acc: 0.1074194/218 [=========================>....] - ETA: 1:19 - loss: 438016.5910 - acc: 0.1074195/218 [=========================>....] - ETA: 1:15 - loss: 435770.3715 - acc: 0.1073196/218 [=========================>....] - ETA: 1:12 - loss: 433547.0651 - acc: 0.1074197/218 [==========================>...] - ETA: 1:09 - loss: 431346.3303 - acc: 0.1076198/218 [==========================>...] - ETA: 1:05 - loss: 429167.8250 - acc: 0.1078199/218 [==========================>...] - ETA: 1:02 - loss: 427011.2143 - acc: 0.1077200/218 [==========================>...] - ETA: 59s - loss: 424876.1713 - acc: 0.1077 201/218 [==========================>...] - ETA: 55s - loss: 422762.3709 - acc: 0.1076202/218 [==========================>...] - ETA: 52s - loss: 420669.4993 - acc: 0.1076203/218 [==========================>...] - ETA: 49s - loss: 418597.2471 - acc: 0.1076204/218 [===========================>..] - ETA: 46s - loss: 416545.3111 - acc: 0.1074205/218 [===========================>..] - ETA: 42s - loss: 414513.3940 - acc: 0.1074206/218 [===========================>..] - ETA: 39s - loss: 412501.2047 - acc: 0.1073207/218 [===========================>..] - ETA: 36s - loss: 410508.4564 - acc: 0.1072208/218 [===========================>..] - ETA: 32s - loss: 408534.8691 - acc: 0.1073209/218 [===========================>..] - ETA: 29s - loss: 406580.1678 - acc: 0.1073210/218 [===========================>..] - ETA: 26s - loss: 404644.0825 - acc: 0.1073211/218 [============================>.] - ETA: 23s - loss: 402726.3528 - acc: 0.1075212/218 [============================>.] - ETA: 19s - loss: 400826.7110 - acc: 0.1074213/218 [============================>.] - ETA: 16s - loss: 398944.9064 - acc: 0.1073214/218 [============================>.] - ETA: 13s - loss: 397080.6886 - acc: 0.1073215/218 [============================>.] - ETA: 9s - loss: 395233.8123 - acc: 0.1074 216/218 [============================>.] - ETA: 6s - loss: 393404.0369 - acc: 0.1074217/218 [============================>.] - ETA: 3s - loss: 391591.1257 - acc: 0.1076  1/218 [..............................] - ETA: 3:51 - loss: 2.3927 - acc: 0.0913  2/218 [..............................] - ETA: 3:09 - loss: 2.3931 - acc: 0.1000  3/218 [..............................] - ETA: 2:49 - loss: 2.3812 - acc: 0.0986  4/218 [..............................] - ETA: 2:38 - loss: 2.3684 - acc: 0.1033  5/218 [..............................] - ETA: 2:34 - loss: 2.3659 - acc: 0.1043  6/218 [..............................] - ETA: 2:34 - loss: 2.3725 - acc: 0.1029  7/218 [..............................] - ETA: 2:31 - loss: 2.3659 - acc: 0.1025  8/218 [>.............................] - ETA: 2:27 - loss: 2.3679 - acc: 0.0984  9/218 [>.............................] - ETA: 2:26 - loss: 2.3637 - acc: 0.1000 10/218 [>.............................] - ETA: 2:27 - loss: 2.3688 - acc: 0.0996 11/218 [>.............................] - ETA: 2:27 - loss: 2.3715 - acc: 0.0972 12/218 [>.............................] - ETA: 2:28 - loss: 2.3689 - acc: 0.0967 13/218 [>.............................] - ETA: 2:28 - loss: 2.3674 - acc: 0.0983 14/218 [>.............................] - ETA: 2:28 - loss: 2.3726 - acc: 0.0978 15/218 [=>............................] - ETA: 2:29 - loss: 2.3709 - acc: 0.0980 16/218 [=>............................] - ETA: 2:29 - loss: 2.3693 - acc: 0.0989 17/218 [=>............................] - ETA: 2:29 - loss: 2.3705 - acc: 0.0982 18/218 [=>............................] - ETA: 2:28 - loss: 2.3708 - acc: 0.0966 19/218 [=>............................] - ETA: 2:28 - loss: 2.3720 - acc: 0.0961 20/218 [=>............................] - ETA: 2:28 - loss: 2.3719 - acc: 0.0980 21/218 [=>............................] - ETA: 2:28 - loss: 2.3689 - acc: 0.0988 22/218 [==>...........................] - ETA: 2:28 - loss: 2.3680 - acc: 0.0994 23/218 [==>...........................] - ETA: 2:27 - loss: 2.3681 - acc: 0.0992 24/218 [==>...........................] - ETA: 2:26 - loss: 2.3676 - acc: 0.0996 25/218 [==>...........................] - ETA: 2:27 - loss: 2.3646 - acc: 0.1002 26/218 [==>...........................] - ETA: 2:27 - loss: 2.3630 - acc: 0.0998 27/218 [==>...........................] - ETA: 2:27 - loss: 2.3630 - acc: 0.1008 28/218 [==>...........................] - ETA: 2:27 - loss: 2.3639 - acc: 0.1002 29/218 [==>...........................] - ETA: 2:27 - loss: 2.3639 - acc: 0.0988 30/218 [===>..........................] - ETA: 2:26 - loss: 2.3645 - acc: 0.0997 31/218 [===>..........................] - ETA: 2:25 - loss: 2.3644 - acc: 0.0994 32/218 [===>..........................] - ETA: 2:25 - loss: 2.3625 - acc: 0.0996 33/218 [===>..........................] - ETA: 2:24 - loss: 2.3627 - acc: 0.0999 34/218 [===>..........................] - ETA: 2:24 - loss: 2.3635 - acc: 0.0996 35/218 [===>..........................] - ETA: 2:23 - loss: 2.3649 - acc: 0.0998 36/218 [===>..........................] - ETA: 2:22 - loss: 2.3644 - acc: 0.1011 37/218 [====>.........................] - ETA: 2:21 - loss: 2.3640 - acc: 0.1015 38/218 [====>.........................] - ETA: 2:21 - loss: 2.3625 - acc: 0.1021 39/218 [====>.........................] - ETA: 2:20 - loss: 2.3631 - acc: 0.1012 40/218 [====>.........................] - ETA: 2:19 - loss: 2.3637 - acc: 0.1010 41/218 [====>.........................] - ETA: 2:18 - loss: 2.3644 - acc: 0.1010 42/218 [====>.........................] - ETA: 2:18 - loss: 2.3645 - acc: 0.1003 43/218 [====>.........................] - ETA: 2:17 - loss: 2.3654 - acc: 0.0997 44/218 [=====>........................] - ETA: 2:29 - loss: 2.3660 - acc: 0.0998218/218 [==============================] - 755s 3s/step - loss: 389799.8303 - acc: 0.1076 - val_loss: 2.3660 - val_acc: 0.0998
