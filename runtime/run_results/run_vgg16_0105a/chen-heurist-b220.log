WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/memory_saving_gradients.py:78: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 220), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'chen-heurist'), ('verbose', False)]
Shape of x_train: (50000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
Cannot find config for batch_size=220, use 256 instead
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/p32xlarge_VGG16_256_None/ilp_log/layer_names'}, {}]
[STR DEBUG] Solution is not configured, use Chen's heuristic to select checkpoints
[STR DEBUG] Pure recomputing strategy with Chen's greedy strategy
DEBUG bwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Reshape/shape/1', 'flatten/Shape', 'flatten/strided_slice', 'flatten/strided_slice/stack', 'flatten/strided_slice/stack_1', 'flatten/strided_slice/stack_2', 'input_1', 'loss/mul', 'loss/mul/x', 'loss/predictions_loss/Const_1', 'loss/predictions_loss/Const_2', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/values_0', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/values_0', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Cast/x', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Const', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel', 'predictions_target']
DEBUG fwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel']
DEBUG bwd_ops after call the gradient function: ['training/RMSprop/gradients/1641264931530161/gradients/Fill', 'training/RMSprop/gradients/1641264931530161/gradients/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block1_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block2_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block2_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block3_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block3_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block4_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block4_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641264931530161/gradients/block5_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/block5_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641264931530161/gradients/fc1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/fc1/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641264931530161/gradients/fc1/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641264931530161/gradients/fc1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/fc2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/fc2/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641264931530161/gradients/fc2/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641264931530161/gradients/fc2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641264931530161/gradients/flatten/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/flatten/Reshape_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/grad_ys_0', 'training/RMSprop/gradients/1641264931530161/gradients/loss/mul_grad/Mul', 'training/RMSprop/gradients/1641264931530161/gradients/loss/mul_grad/Mul_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_1_grad/Const', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_1_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_1_grad/Reshape/shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_1_grad/Tile', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_grad/Reshape/shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/Sum_grad/Tile', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims/dim', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/LogSoftmax', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/Neg', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Neg', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Reshape_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Shape_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Sum', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/Sum_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/div_no_nan', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/div_no_nan_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/div_no_nan_2', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/value_grad/mul', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape_1', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum', 'training/RMSprop/gradients/1641264931530161/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum_1', 'training/RMSprop/gradients/1641264931530161/gradients/predictions/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641264931530161/gradients/predictions/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641264931530161/gradients/predictions/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641264931530161/gradients/zeros_like']
DEBUG Using tensors ['block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Relu:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Relu:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Relu:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Relu:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Relu:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Relu:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Relu:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Relu:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/Relu:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc2/MatMul/ReadVariableOp:0', 'flatten/Reshape:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Number of checkpoints: 5:
DEBUG [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>]


DEBUG checkpoints_disconnected: {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>}
DEBUG Found 27 ops to copy within fwd_ops ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['loss/mul'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp']
DEBUG Processing list ['loss/mul:0']
DEBUG Copied_svg: SubGraphView (graphid=139692595899864):
** ops[27]:
  training/RMSprop/gradients/fc2/MatMul/ReadVariableOp
  training/RMSprop/gradients/fc2/MatMul
  training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/fc2/BiasAdd
  training/RMSprop/gradients/fc2/Relu
  training/RMSprop/gradients/predictions/MatMul/ReadVariableOp
  training/RMSprop/gradients/predictions/MatMul
  training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/predictions/BiasAdd
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul
  training/RMSprop/gradients/loss/predictions_loss/Sum
  training/RMSprop/gradients/loss/predictions_loss/num_elements
  training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast
  training/RMSprop/gradients/loss/predictions_loss/Sum_1
  training/RMSprop/gradients/loss/predictions_loss/value
  training/RMSprop/gradients/loss/mul
** inputs: empty
** outputs[2]:
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits:1
  training/RMSprop/gradients/loss/mul:0

DEBUG Copied ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'] to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul_1:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/loss/mul:0']
DEBUG with respect to boundary:[<tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(4096, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]
DEBUG Checkpoint gradients before loop {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: None, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: None, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: None, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: None}
DEBUG checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>], [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>], [<tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>], [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>], [<tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]]
DEBUG Processing list ['fc1/Relu:0']
DEBUG Found 15 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['fc1/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0']
DEBUG ops_to_copy = ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice']
DEBUG Copied ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice'] to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0'] restricted to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/fc1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0']
DEBUG Processing list ['block5_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block5_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu']
DEBUG Copied ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu'] to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block5_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block4_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block4_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu']
DEBUG Copied ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu'] to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block4_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block3_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block3_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu']
DEBUG Copied ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu'] to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block3_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block2_conv1/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block2_conv1/Relu'], stop_at ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu']
DEBUG Copied ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu'] to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block2_conv1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0']
  1/228 [..............................] - ETA: 1:28:03 - loss: 2.3380 - acc: 0.0818  2/228 [..............................] - ETA: 47:17 - loss: 10484034.1690 - acc: 0.0750  3/228 [..............................] - ETA: 33:49 - loss: 6989401.3806 - acc: 0.0939   4/228 [..............................] - ETA: 27:10 - loss: 5242092.8407 - acc: 0.0977  5/228 [..............................] - ETA: 23:10 - loss: 4193820.1995 - acc: 0.0927  6/228 [..............................] - ETA: 20:30 - loss: 3495145.2328 - acc: 0.1008  7/228 [..............................] - ETA: 18:38 - loss: 2995839.1311 - acc: 0.1006  8/228 [>.............................] - ETA: 17:13 - loss: 2621360.1217 - acc: 0.0977  9/228 [>.............................] - ETA: 16:08 - loss: 2330099.5631 - acc: 0.0965 10/228 [>.............................] - ETA: 15:18 - loss: 2097089.8526 - acc: 0.0950 11/228 [>.............................] - ETA: 14:38 - loss: 1906445.5318 - acc: 0.0967 12/228 [>.............................] - ETA: 14:03 - loss: 1747575.2631 - acc: 0.0981 13/228 [>.............................] - ETA: 13:33 - loss: 1613146.5738 - acc: 0.1028 14/228 [>.............................] - ETA: 13:08 - loss: 1497922.0147 - acc: 0.1003 15/228 [>.............................] - ETA: 12:46 - loss: 1398060.7007 - acc: 0.1021 16/228 [=>............................] - ETA: 12:28 - loss: 1310682.0507 - acc: 0.1023 17/228 [=>............................] - ETA: 12:10 - loss: 1233583.2417 - acc: 0.1024 18/228 [=>............................] - ETA: 12:00 - loss: 1165050.9672 - acc: 0.1030 19/228 [=>............................] - ETA: 11:52 - loss: 1103732.6161 - acc: 0.1012 20/228 [=>............................] - ETA: 11:42 - loss: 1048546.0997 - acc: 0.1027 21/228 [=>............................] - ETA: 11:31 - loss: 998615.4451 - acc: 0.1019  22/228 [=>............................] - ETA: 11:20 - loss: 953223.9385 - acc: 0.1041 23/228 [==>...........................] - ETA: 11:10 - loss: 911779.5194 - acc: 0.1026 24/228 [==>...........................] - ETA: 11:00 - loss: 873788.8020 - acc: 0.1006 25/228 [==>...........................] - ETA: 10:50 - loss: 838837.3419 - acc: 0.1020 26/228 [==>...........................] - ETA: 10:42 - loss: 806574.4559 - acc: 0.1017 27/228 [==>...........................] - ETA: 10:35 - loss: 776701.4130 - acc: 0.1005 28/228 [==>...........................] - ETA: 10:27 - loss: 748962.1587 - acc: 0.1016 29/228 [==>...........................] - ETA: 10:20 - loss: 723135.9567 - acc: 0.1013 30/228 [==>...........................] - ETA: 10:11 - loss: 699031.5016 - acc: 0.1005 31/228 [===>..........................] - ETA: 10:07 - loss: 676482.1721 - acc: 0.1000 32/228 [===>..........................] - ETA: 10:03 - loss: 655342.1795 - acc: 0.0999 33/228 [===>..........................] - ETA: 9:58 - loss: 635483.3953 - acc: 0.1000  34/228 [===>..........................] - ETA: 9:53 - loss: 616792.7747 - acc: 0.1005 35/228 [===>..........................] - ETA: 9:48 - loss: 599170.1897 - acc: 0.1005 36/228 [===>..........................] - ETA: 9:42 - loss: 582526.6372 - acc: 0.1004 37/228 [===>..........................] - ETA: 9:37 - loss: 566782.7360 - acc: 0.1006 38/228 [====>.........................] - ETA: 9:33 - loss: 551867.4614 - acc: 0.1002 39/228 [====>.........................] - ETA: 9:29 - loss: 537717.0727 - acc: 0.1003 40/228 [====>.........................] - ETA: 9:25 - loss: 524274.2032 - acc: 0.1008 41/228 [====>.........................] - ETA: 9:21 - loss: 511487.0837 - acc: 0.1003 42/228 [====>.........................] - ETA: 9:17 - loss: 499308.8744 - acc: 0.1005 43/228 [====>.........................] - ETA: 9:14 - loss: 487697.0934 - acc: 0.1008 44/228 [====>.........................] - ETA: 9:10 - loss: 476613.1196 - acc: 0.1020 45/228 [====>.........................] - ETA: 9:05 - loss: 466021.7679 - acc: 0.1028 46/228 [=====>........................] - ETA: 9:00 - loss: 455890.9101 - acc: 0.1024 47/228 [=====>........................] - ETA: 8:56 - loss: 446191.1640 - acc: 0.1033 48/228 [=====>........................] - ETA: 8:51 - loss: 436895.5628 - acc: 0.1034 49/228 [=====>........................] - ETA: 8:50 - loss: 427979.3739 - acc: 0.1035 50/228 [=====>........................] - ETA: 8:48 - loss: 419419.8324 - acc: 0.1036 51/228 [=====>........................] - ETA: 8:46 - loss: 411195.9592 - acc: 0.1042 52/228 [=====>........................] - ETA: 8:44 - loss: 403288.3890 - acc: 0.1044 53/228 [=====>........................] - ETA: 8:42 - loss: 395679.2175 - acc: 0.1052 54/228 [======>.......................] - ETA: 8:40 - loss: 388351.8673 - acc: 0.1041 55/228 [======>.......................] - ETA: 8:38 - loss: 381290.9665 - acc: 0.1053 56/228 [======>.......................] - ETA: 8:36 - loss: 374482.2402 - acc: 0.1054 57/228 [======>.......................] - ETA: 8:34 - loss: 367912.4166 - acc: 0.1057 58/228 [======>.......................] - ETA: 8:31 - loss: 361569.1387 - acc: 0.1059 59/228 [======>.......................] - ETA: 8:27 - loss: 355440.8886 - acc: 0.1054 60/228 [======>.......................] - ETA: 8:24 - loss: 349516.9123 - acc: 0.1052 61/228 [=======>......................] - ETA: 8:20 - loss: 343787.1647 - acc: 0.1054 62/228 [=======>......................] - ETA: 8:16 - loss: 338242.2474 - acc: 0.1059 63/228 [=======>......................] - ETA: 8:11 - loss: 332873.3592 - acc: 0.1058 64/228 [=======>......................] - ETA: 8:06 - loss: 327672.2492 - acc: 0.1051 65/228 [=======>......................] - ETA: 8:02 - loss: 322631.1731 - acc: 0.1047 66/228 [=======>......................] - ETA: 7:58 - loss: 317742.8567 - acc: 0.1054 67/228 [=======>......................] - ETA: 7:54 - loss: 313000.4602 - acc: 0.1060 68/228 [=======>......................] - ETA: 7:50 - loss: 308397.5461 - acc: 0.1064 69/228 [========>.....................] - ETA: 7:46 - loss: 303928.0498 - acc: 0.1063 70/228 [========>.....................] - ETA: 7:43 - loss: 299586.2534 - acc: 0.1063 71/228 [========>.....................] - ETA: 7:42 - loss: 295366.7608 - acc: 0.1072 72/228 [========>.....................] - ETA: 7:39 - loss: 291264.4769 - acc: 0.1076 73/228 [========>.....................] - ETA: 7:36 - loss: 287274.5841 - acc: 0.1076 74/228 [========>.....................] - ETA: 7:33 - loss: 283392.5265 - acc: 0.1073 75/228 [========>.....................] - ETA: 7:30 - loss: 279613.9903 - acc: 0.1068 76/228 [=========>....................] - ETA: 7:26 - loss: 275934.8891 - acc: 0.1068 77/228 [=========>....................] - ETA: 7:23 - loss: 272351.3490 - acc: 0.1071 78/228 [=========>....................] - ETA: 7:19 - loss: 268859.6945 - acc: 0.1073 79/228 [=========>....................] - ETA: 7:16 - loss: 265456.4364 - acc: 0.1072 80/228 [=========>....................] - ETA: 7:13 - loss: 262138.2596 - acc: 0.1071 81/228 [=========>....................] - ETA: 7:10 - loss: 258902.0132 - acc: 0.1075 82/228 [=========>....................] - ETA: 7:06 - loss: 255744.6996 - acc: 0.1070 83/228 [=========>....................] - ETA: 7:03 - loss: 252663.4656 - acc: 0.1068 84/228 [==========>...................] - ETA: 7:00 - loss: 249655.7352 - acc: 0.1066 85/228 [==========>...................] - ETA: 6:57 - loss: 246718.6372 - acc: 0.1060 86/228 [==========>...................] - ETA: 6:54 - loss: 243849.8446 - acc: 0.1062 87/228 [==========>...................] - ETA: 6:50 - loss: 241046.9992 - acc: 0.1066 88/228 [==========>...................] - ETA: 6:47 - loss: 238307.8625 - acc: 0.1066 89/228 [==========>...................] - ETA: 6:44 - loss: 235630.2719 - acc: 0.1066 90/228 [==========>...................] - ETA: 6:41 - loss: 233012.1832 - acc: 0.1069 91/228 [==========>...................] - ETA: 6:38 - loss: 230451.6347 - acc: 0.1076 92/228 [===========>..................] - ETA: 6:34 - loss: 227946.7507 - acc: 0.1080 93/228 [===========>..................] - ETA: 6:31 - loss: 225495.7349 - acc: 0.1080 94/228 [===========>..................] - ETA: 6:28 - loss: 223096.8769 - acc: 0.1078 95/228 [===========>..................] - ETA: 6:25 - loss: 220748.5130 - acc: 0.1077 96/228 [===========>..................] - ETA: 6:22 - loss: 218449.0733 - acc: 0.1076 97/228 [===========>..................] - ETA: 6:19 - loss: 216197.0884 - acc: 0.1079 98/228 [===========>..................] - ETA: 6:16 - loss: 213991.0192 - acc: 0.1076 99/228 [============>.................] - ETA: 6:13 - loss: 211829.5170 - acc: 0.1080100/228 [============>.................] - ETA: 6:10 - loss: 209711.2451 - acc: 0.1082101/228 [============>.................] - ETA: 6:07 - loss: 207634.9189 - acc: 0.1082102/228 [============>.................] - ETA: 6:04 - loss: 205599.3050 - acc: 0.1079103/228 [============>.................] - ETA: 6:01 - loss: 203603.2176 - acc: 0.1077104/228 [============>.................] - ETA: 5:58 - loss: 201645.5164 - acc: 0.1073105/228 [============>.................] - ETA: 5:55 - loss: 199725.1058 - acc: 0.1077106/228 [============>.................] - ETA: 5:52 - loss: 197840.9283 - acc: 0.1075107/228 [=============>................] - ETA: 5:49 - loss: 195991.9691 - acc: 0.1076108/228 [=============>................] - ETA: 5:46 - loss: 194177.2500 - acc: 0.1076109/228 [=============>................] - ETA: 5:44 - loss: 192395.8282 - acc: 0.1081110/228 [=============>................] - ETA: 5:41 - loss: 190646.8512 - acc: 0.1081111/228 [=============>................] - ETA: 5:38 - loss: 188929.3327 - acc: 0.1082112/228 [=============>................] - ETA: 5:35 - loss: 187242.4842 - acc: 0.1085113/228 [=============>................] - ETA: 5:32 - loss: 185585.4914 - acc: 0.1083114/228 [==============>...............] - ETA: 5:29 - loss: 183957.5684 - acc: 0.1087115/228 [==============>...............] - ETA: 5:27 - loss: 182357.9582 - acc: 0.1089116/228 [==============>...............] - ETA: 5:24 - loss: 180785.9267 - acc: 0.1088117/228 [==============>...............] - ETA: 5:21 - loss: 179240.7676 - acc: 0.1087118/228 [==============>...............] - ETA: 5:18 - loss: 177721.7976 - acc: 0.1084119/228 [==============>...............] - ETA: 5:15 - loss: 176228.3565 - acc: 0.1085120/228 [==============>...............] - ETA: 5:12 - loss: 174759.8056 - acc: 0.1087121/228 [==============>...............] - ETA: 5:09 - loss: 173315.5518 - acc: 0.1086122/228 [===============>..............] - ETA: 5:05 - loss: 171894.9514 - acc: 0.1089123/228 [===============>..............] - ETA: 5:02 - loss: 170497.4791 - acc: 0.1091124/228 [===============>..............] - ETA: 5:00 - loss: 169122.5180 - acc: 0.1093125/228 [===============>..............] - ETA: 4:57 - loss: 167769.5563 - acc: 0.1095126/228 [===============>..............] - ETA: 4:54 - loss: 166438.0702 - acc: 0.1091127/228 [===============>..............] - ETA: 4:51 - loss: 165127.5524 - acc: 0.1093128/228 [===============>..............] - ETA: 4:48 - loss: 163837.5114 - acc: 0.1094129/228 [===============>..............] - ETA: 4:45 - loss: 162567.4711 - acc: 0.1094130/228 [================>.............] - ETA: 4:42 - loss: 161316.9697 - acc: 0.1096131/228 [================>.............] - ETA: 4:40 - loss: 160085.5600 - acc: 0.1100132/228 [================>.............] - ETA: 4:37 - loss: 158872.8080 - acc: 0.1100133/228 [================>.............] - ETA: 4:34 - loss: 157678.2930 - acc: 0.1099134/228 [================>.............] - ETA: 4:31 - loss: 156501.6065 - acc: 0.1098135/228 [================>.............] - ETA: 4:28 - loss: 155342.3524 - acc: 0.1097136/228 [================>.............] - ETA: 4:25 - loss: 154200.1461 - acc: 0.1097137/228 [=================>............] - ETA: 4:23 - loss: 153074.6144 - acc: 0.1097138/228 [=================>............] - ETA: 4:20 - loss: 151965.3948 - acc: 0.1096139/228 [=================>............] - ETA: 4:17 - loss: 150872.1351 - acc: 0.1095140/228 [=================>............] - ETA: 4:14 - loss: 149794.4934 - acc: 0.1095141/228 [=================>............] - ETA: 4:11 - loss: 148732.1379 - acc: 0.1096142/228 [=================>............] - ETA: 4:07 - loss: 147684.7447 - acc: 0.1096143/228 [=================>............] - ETA: 4:04 - loss: 146652.0003 - acc: 0.1095144/228 [=================>............] - ETA: 4:01 - loss: 145633.5996 - acc: 0.1098145/228 [==================>...........] - ETA: 3:58 - loss: 144629.3103 - acc: 0.1096146/228 [==================>...........] - ETA: 3:56 - loss: 143638.7144 - acc: 0.1093147/228 [==================>...........] - ETA: 3:53 - loss: 142661.5961 - acc: 0.1092148/228 [==================>...........] - ETA: 3:50 - loss: 141697.6819 - acc: 0.1090149/228 [==================>...........] - ETA: 3:48 - loss: 140746.7062 - acc: 0.1089150/228 [==================>...........] - ETA: 3:45 - loss: 139808.4102 - acc: 0.1086151/228 [==================>...........] - ETA: 3:42 - loss: 138882.5419 - acc: 0.1087152/228 [===================>..........] - ETA: 3:39 - loss: 137968.8561 - acc: 0.1086153/228 [===================>..........] - ETA: 3:36 - loss: 137067.1142 - acc: 0.1085154/228 [===================>..........] - ETA: 3:33 - loss: 136177.0836 - acc: 0.1083155/228 [===================>..........] - ETA: 3:30 - loss: 135298.5366 - acc: 0.1084156/228 [===================>..........] - ETA: 3:27 - loss: 134431.2533 - acc: 0.1083157/228 [===================>..........] - ETA: 3:24 - loss: 133575.0179 - acc: 0.1084158/228 [===================>..........] - ETA: 3:21 - loss: 132729.6210 - acc: 0.1084159/228 [===================>..........] - ETA: 3:18 - loss: 131894.8579 - acc: 0.1085160/228 [====================>.........] - ETA: 3:15 - loss: 131070.5295 - acc: 0.1085161/228 [====================>.........] - ETA: 3:12 - loss: 130256.4410 - acc: 0.1086162/228 [====================>.........] - ETA: 3:09 - loss: 129452.4031 - acc: 0.1085163/228 [====================>.........] - ETA: 3:06 - loss: 128658.2307 - acc: 0.1085164/228 [====================>.........] - ETA: 3:04 - loss: 127873.7432 - acc: 0.1087165/228 [====================>.........] - ETA: 3:03 - loss: 127098.7692 - acc: 0.1087166/228 [====================>.........] - ETA: 3:00 - loss: 126333.1279 - acc: 0.1085167/228 [====================>.........] - ETA: 2:57 - loss: 125576.6559 - acc: 0.1086168/228 [=====================>........] - ETA: 2:54 - loss: 124829.1895 - acc: 0.1086169/228 [=====================>........] - ETA: 2:52 - loss: 124090.5688 - acc: 0.1086170/228 [=====================>........] - ETA: 2:49 - loss: 123360.6378 - acc: 0.1085171/228 [=====================>........] - ETA: 2:46 - loss: 122639.2440 - acc: 0.1087172/228 [=====================>........] - ETA: 2:43 - loss: 121926.2385 - acc: 0.1089173/228 [=====================>........] - ETA: 2:40 - loss: 121221.4759 - acc: 0.1087174/228 [=====================>........] - ETA: 2:37 - loss: 120524.8140 - acc: 0.1087175/228 [======================>.......] - ETA: 2:34 - loss: 119836.1146 - acc: 0.1089176/228 [======================>.......] - ETA: 2:31 - loss: 119155.2406 - acc: 0.1088177/228 [======================>.......] - ETA: 2:28 - loss: 118482.0601 - acc: 0.1087178/228 [======================>.......] - ETA: 2:25 - loss: 117816.4435 - acc: 0.1086179/228 [======================>.......] - ETA: 2:22 - loss: 117158.2639 - acc: 0.1087180/228 [======================>.......] - ETA: 2:19 - loss: 116507.3974 - acc: 0.1091181/228 [======================>.......] - ETA: 2:16 - loss: 115863.7229 - acc: 0.1089182/228 [======================>.......] - ETA: 2:13 - loss: 115227.1216 - acc: 0.1089183/228 [=======================>......] - ETA: 2:10 - loss: 114597.4786 - acc: 0.1089184/228 [=======================>......] - ETA: 2:07 - loss: 113974.6786 - acc: 0.1091185/228 [=======================>......] - ETA: 2:04 - loss: 113358.6116 - acc: 0.1092186/228 [=======================>......] - ETA: 2:01 - loss: 112749.1690 - acc: 0.1092187/228 [=======================>......] - ETA: 1:58 - loss: 112146.2446 - acc: 0.1095188/228 [=======================>......] - ETA: 1:55 - loss: 111549.7342 - acc: 0.1097189/228 [=======================>......] - ETA: 1:53 - loss: 110959.5366 - acc: 0.1097190/228 [========================>.....] - ETA: 1:50 - loss: 110375.5512 - acc: 0.1096191/228 [========================>.....] - ETA: 1:47 - loss: 109797.6808 - acc: 0.1097192/228 [========================>.....] - ETA: 1:44 - loss: 109225.8298 - acc: 0.1096193/228 [========================>.....] - ETA: 1:41 - loss: 108659.9046 - acc: 0.1097194/228 [========================>.....] - ETA: 1:38 - loss: 108099.8138 - acc: 0.1096195/228 [========================>.....] - ETA: 1:35 - loss: 107545.4676 - acc: 0.1097196/228 [========================>.....] - ETA: 1:32 - loss: 106996.7778 - acc: 0.1097197/228 [========================>.....] - ETA: 1:29 - loss: 106453.6587 - acc: 0.1095198/228 [=========================>....] - ETA: 1:26 - loss: 105916.0255 - acc: 0.1097199/228 [=========================>....] - ETA: 1:23 - loss: 105383.7957 - acc: 0.1097200/228 [=========================>....] - ETA: 1:20 - loss: 104856.8880 - acc: 0.1098201/228 [=========================>....] - ETA: 1:18 - loss: 104335.2234 - acc: 0.1098202/228 [=========================>....] - ETA: 1:15 - loss: 103818.7238 - acc: 0.1099203/228 [=========================>....] - ETA: 1:12 - loss: 103307.3127 - acc: 0.1104204/228 [=========================>....] - ETA: 1:09 - loss: 102800.9575 - acc: 0.1102205/228 [=========================>....] - ETA: 1:06 - loss: 102299.5007 - acc: 0.1099206/228 [==========================>...] - ETA: 1:03 - loss: 101802.9124 - acc: 0.1099207/228 [==========================>...] - ETA: 1:00 - loss: 101311.1219 - acc: 0.1101208/228 [==========================>...] - ETA: 57s - loss: 100824.0603 - acc: 0.1100 209/228 [==========================>...] - ETA: 54s - loss: 100341.6601 - acc: 0.1098210/228 [==========================>...] - ETA: 52s - loss: 99863.8536 - acc: 0.1097 211/228 [==========================>...] - ETA: 49s - loss: 99390.5761 - acc: 0.1096212/228 [==========================>...] - ETA: 46s - loss: 98921.7635 - acc: 0.1095213/228 [===========================>..] - ETA: 43s - loss: 98457.3528 - acc: 0.1095214/228 [===========================>..] - ETA: 40s - loss: 97997.2824 - acc: 0.1093215/228 [===========================>..] - ETA: 37s - loss: 97541.4918 - acc: 0.1094216/228 [===========================>..] - ETA: 34s - loss: 97089.9234 - acc: 0.1092217/228 [===========================>..] - ETA: 31s - loss: 96642.5151 - acc: 0.1093218/228 [===========================>..] - ETA: 28s - loss: 96199.2114 - acc: 0.1093219/228 [===========================>..] - ETA: 25s - loss: 95759.9560 - acc: 0.1092220/228 [===========================>..] - ETA: 23s - loss: 95324.6938 - acc: 0.1092221/228 [============================>.] - ETA: 20s - loss: 94893.7955 - acc: 0.1093222/228 [============================>.] - ETA: 17s - loss: 94466.3563 - acc: 0.1093223/228 [============================>.] - ETA: 14s - loss: 94042.7659 - acc: 0.1094224/228 [============================>.] - ETA: 11s - loss: 93622.9424 - acc: 0.1094225/228 [============================>.] - ETA: 8s - loss: 93206.8507 - acc: 0.1097 226/228 [============================>.] - ETA: 5s - loss: 92794.4411 - acc: 0.1099227/228 [============================>.] - ETA: 2s - loss: 92385.6652 - acc: 0.1098  1/228 [..............................] - ETA: 3:43 - loss: 2.3111 - acc: 0.1273  2/228 [..............................] - ETA: 3:03 - loss: 2.2985 - acc: 0.1409  3/228 [..............................] - ETA: 2:40 - loss: 2.2970 - acc: 0.1348  4/228 [..............................] - ETA: 2:42 - loss: 2.2976 - acc: 0.1330  5/228 [..............................] - ETA: 2:46 - loss: 2.2951 - acc: 0.1445  6/228 [..............................] - ETA: 2:48 - loss: 2.2977 - acc: 0.1447  7/228 [..............................] - ETA: 2:49 - loss: 2.2983 - acc: 0.1474  8/228 [>.............................] - ETA: 2:50 - loss: 2.2983 - acc: 0.1477  9/228 [>.............................] - ETA: 2:48 - loss: 2.2989 - acc: 0.1495 10/228 [>.............................] - ETA: 2:46 - loss: 2.2983 - acc: 0.1491 11/228 [>.............................] - ETA: 2:44 - loss: 2.2981 - acc: 0.1475 12/228 [>.............................] - ETA: 2:43 - loss: 2.2989 - acc: 0.1481 13/228 [>.............................] - ETA: 2:42 - loss: 2.2983 - acc: 0.1483 14/228 [>.............................] - ETA: 2:40 - loss: 2.2984 - acc: 0.1464 15/228 [>.............................] - ETA: 2:39 - loss: 2.2983 - acc: 0.1455 16/228 [=>............................] - ETA: 2:38 - loss: 2.2980 - acc: 0.1446 17/228 [=>............................] - ETA: 2:37 - loss: 2.2973 - acc: 0.1449 18/228 [=>............................] - ETA: 2:36 - loss: 2.2972 - acc: 0.1442 19/228 [=>............................] - ETA: 2:35 - loss: 2.2976 - acc: 0.1440 20/228 [=>............................] - ETA: 2:34 - loss: 2.2975 - acc: 0.1457 21/228 [=>............................] - ETA: 2:33 - loss: 2.2973 - acc: 0.1463 22/228 [=>............................] - ETA: 2:32 - loss: 2.2967 - acc: 0.1452 23/228 [==>...........................] - ETA: 2:31 - loss: 2.2963 - acc: 0.1472 24/228 [==>...........................] - ETA: 2:30 - loss: 2.2960 - acc: 0.1477 25/228 [==>...........................] - ETA: 2:30 - loss: 2.2956 - acc: 0.1471 26/228 [==>...........................] - ETA: 2:29 - loss: 2.2957 - acc: 0.1467 27/228 [==>...........................] - ETA: 2:28 - loss: 2.2958 - acc: 0.1466 28/228 [==>...........................] - ETA: 2:26 - loss: 2.2957 - acc: 0.1463 29/228 [==>...........................] - ETA: 2:25 - loss: 2.2956 - acc: 0.1464 30/228 [==>...........................] - ETA: 2:24 - loss: 2.2958 - acc: 0.1474 31/228 [===>..........................] - ETA: 2:22 - loss: 2.2959 - acc: 0.1474 32/228 [===>..........................] - ETA: 2:21 - loss: 2.2958 - acc: 0.1472 33/228 [===>..........................] - ETA: 2:21 - loss: 2.2958 - acc: 0.1464 34/228 [===>..........................] - ETA: 2:20 - loss: 2.2960 - acc: 0.1453 35/228 [===>..........................] - ETA: 2:19 - loss: 2.2958 - acc: 0.1448 36/228 [===>..........................] - ETA: 2:18 - loss: 2.2954 - acc: 0.1465 37/228 [===>..........................] - ETA: 2:18 - loss: 2.2954 - acc: 0.1464 38/228 [====>.........................] - ETA: 2:17 - loss: 2.2959 - acc: 0.1461 39/228 [====>.........................] - ETA: 2:16 - loss: 2.2959 - acc: 0.1456 40/228 [====>.........................] - ETA: 2:15 - loss: 2.2961 - acc: 0.1451 41/228 [====>.........................] - ETA: 2:13 - loss: 2.2960 - acc: 0.1457 42/228 [====>.........................] - ETA: 2:12 - loss: 2.2959 - acc: 0.1456 43/228 [====>.........................] - ETA: 2:10 - loss: 2.2960 - acc: 0.1449 44/228 [====>.........................] - ETA: 2:13 - loss: 2.2958 - acc: 0.1459 45/228 [====>.........................] - ETA: 2:12 - loss: 2.2957 - acc: 0.1463 46/228 [=====>........................] - ETA: 2:31 - loss: 2.2959 - acc: 0.1462228/228 [==============================] - 696s 3s/step - loss: 91981.7602 - acc: 0.1101 - val_loss: 2.2959 - val_acc: 0.1462
