WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:928: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
2022-01-04 14:47:10.200647: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.68GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-04 14:47:10.200753: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.68GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 260), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'dynprog'), ('verbose', False)]
Shape of x_train: (50000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
Cannot find config for batch_size=260, use 256 instead
[STR DEBUG] Parsing STR configuration: [{'strategy': 'swap', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/layer_names'}, {'p': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/P-dynprog', 'q': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/Q-dynprog'}]
[STR DEBUG] Use swap strategy of DYNPROG
[STR DEBUG] Processing layer 2's swapping, swap out at [3], swap in at [41]
[STR DEBUG] Find swapout ops: name: "block1_conv2/Relu"
op: "Relu"
input: "block1_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block1_conv2/Relu:0", shape=(?, 224, 224, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block1_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Add swap-in op at name: "training/RMSprop/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block1_conv2/Relu"
input: "block1_pool/MaxPool"
input: "training/RMSprop/gradients/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/RMSprop/gradients/gradients/block1_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 5's swapping, swap out at [6], swap in at [38]
[STR DEBUG] Find swapout ops: name: "block2_conv2/Relu"
op: "Relu"
input: "block2_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block2_conv2/Relu:0", shape=(?, 112, 112, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block2_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Add swap-in op at name: "training/RMSprop/gradients/gradients/block2_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block2_conv2/Relu"
input: "block2_pool/MaxPool"
input: "training/RMSprop/gradients/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/RMSprop/gradients/gradients/block2_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
  1/193 [..............................] - ETA: 1:38:32 - loss: 2.3061 - acc: 0.0654  2/193 [..............................] - ETA: 53:00 - loss: 36275385.1531 - acc: 0.06922022-01-04 14:47:20.133017: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
  3/193 [..............................] - ETA: 37:54 - loss: 24183596.2372 - acc: 0.0833  4/193 [..............................] - ETA: 30:14 - loss: 18137697.7859 - acc: 0.07602022-01-04 14:47:25.344913: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
  5/193 [..............................] - ETA: 25:47 - loss: 14510195.6441 - acc: 0.0762  6/193 [..............................] - ETA: 22:50 - loss: 12091877.8911 - acc: 0.08332022-01-04 14:47:31.038595: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
  7/193 [>.............................] - ETA: 20:46 - loss: 10364467.0928 - acc: 0.08632022-01-04 14:47:33.771705: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
  8/193 [>.............................] - ETA: 19:07 - loss: 9068908.9939 - acc: 0.0837 2022-01-04 14:47:36.594583: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-04 14:47:36.595395: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
  9/193 [>.............................] - ETA: 17:53 - loss: 8061252.6953 - acc: 0.0829 10/193 [>.............................] - ETA: 16:50 - loss: 7255127.6751 - acc: 0.0850 11/193 [>.............................] - ETA: 16:01 - loss: 6595570.8231 - acc: 0.0864 12/193 [>.............................] - ETA: 15:19 - loss: 6045940.1774 - acc: 0.0865 13/193 [=>............................] - ETA: 14:41 - loss: 5580868.0332 - acc: 0.0864 14/193 [=>............................] - ETA: 14:11 - loss: 5182234.7669 - acc: 0.09072022-01-04 14:47:53.502131: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
 15/193 [=>............................] - ETA: 13:43 - loss: 4836752.6025 - acc: 0.0923 16/193 [=>............................] - ETA: 13:19 - loss: 4534455.7096 - acc: 0.0899 17/193 [=>............................] - ETA: 13:00 - loss: 4267723.1563 - acc: 0.0905 18/193 [=>............................] - ETA: 12:41 - loss: 4030627.5531 - acc: 0.0934 19/193 [=>............................] - ETA: 12:24 - loss: 3818489.3825 - acc: 0.0927 20/193 [==>...........................] - ETA: 12:08 - loss: 3627565.0285 - acc: 0.0927 21/193 [==>...........................] - ETA: 11:55 - loss: 3454823.9463 - acc: 0.0932 22/193 [==>...........................] - ETA: 11:41 - loss: 3297786.5989 - acc: 0.09302022-01-04 14:48:17.401171: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
 23/193 [==>...........................] - ETA: 11:34 - loss: 3154404.6728 - acc: 0.0946 24/193 [==>...........................] - ETA: 11:23 - loss: 3022971.2392 - acc: 0.0966 25/193 [==>...........................] - ETA: 11:11 - loss: 2902053.5671 - acc: 0.0971 26/193 [===>..........................] - ETA: 11:09 - loss: 2790436.4829 - acc: 0.0982 27/193 [===>..........................] - ETA: 10:59 - loss: 2687087.0688 - acc: 0.0984 28/193 [===>..........................] - ETA: 10:48 - loss: 2591119.7558 - acc: 0.0986 29/193 [===>..........................] - ETA: 10:41 - loss: 2501770.8782 - acc: 0.0993 30/193 [===>..........................] - ETA: 10:31 - loss: 2418378.5922 - acc: 0.0991 31/193 [===>..........................] - ETA: 10:23 - loss: 2340366.4540 - acc: 0.0985 32/193 [===>..........................] - ETA: 10:15 - loss: 2267230.0743 - acc: 0.0977 33/193 [====>.........................] - ETA: 10:06 - loss: 2198526.2018 - acc: 0.0981 34/193 [====>.........................] - ETA: 10:00 - loss: 2133863.7342 - acc: 0.0986 35/193 [====>.........................] - ETA: 9:53 - loss: 2072896.2648 - acc: 0.0982  36/193 [====>.........................] - ETA: 9:47 - loss: 2015315.8769 - acc: 0.0982 37/193 [====>.........................] - ETA: 9:41 - loss: 1960847.9418 - acc: 0.0986 38/193 [====>.........................] - ETA: 9:35 - loss: 1909246.7396 - acc: 0.0992 39/193 [=====>........................] - ETA: 9:28 - loss: 1860291.7539 - acc: 0.1002 40/193 [=====>........................] - ETA: 9:22 - loss: 1813784.5172 - acc: 0.1019 41/193 [=====>........................] - ETA: 9:17 - loss: 1769545.9254 - acc: 0.1034 42/193 [=====>........................] - ETA: 9:10 - loss: 1727413.9331 - acc: 0.1038 43/193 [=====>........................] - ETA: 9:06 - loss: 1687241.5695 - acc: 0.1038 44/193 [=====>........................] - ETA: 9:00 - loss: 1648895.2210 - acc: 0.1040 45/193 [=====>........................] - ETA: 8:54 - loss: 1612253.1560 - acc: 0.1044 46/193 [======>.......................] - ETA: 8:49 - loss: 1577204.2240 - acc: 0.1042 47/193 [======>.......................] - ETA: 8:43 - loss: 1543646.7351 - acc: 0.1051 48/193 [======>.......................] - ETA: 8:37 - loss: 1511487.4757 - acc: 0.1056 49/193 [======>.......................] - ETA: 8:32 - loss: 1480640.8390 - acc: 0.1053 50/193 [======>.......................] - ETA: 8:26 - loss: 1451028.0666 - acc: 0.1053 51/193 [======>.......................] - ETA: 8:21 - loss: 1422576.5805 - acc: 0.1054 52/193 [=======>......................] - ETA: 8:16 - loss: 1395219.3815 - acc: 0.1062 53/193 [=======>......................] - ETA: 8:11 - loss: 1368894.5291 - acc: 0.1070 54/193 [=======>......................] - ETA: 8:07 - loss: 1343544.6711 - acc: 0.1080 55/193 [=======>......................] - ETA: 8:02 - loss: 1319116.6258 - acc: 0.1099 56/193 [=======>......................] - ETA: 7:57 - loss: 1295561.1493 - acc: 0.1095 57/193 [=======>......................] - ETA: 7:53 - loss: 1272832.0469 - acc: 0.1089 58/193 [========>.....................] - ETA: 7:48 - loss: 1250886.7064 - acc: 0.1088 59/193 [========>.....................] - ETA: 7:44 - loss: 1229685.2757 - acc: 0.1093 60/193 [========>.....................] - ETA: 7:39 - loss: 1209190.5593 - acc: 0.1088 61/193 [========>.....................] - ETA: 7:35 - loss: 1189367.8004 - acc: 0.1104 62/193 [========>.....................] - ETA: 7:31 - loss: 1170184.4861 - acc: 0.1106 63/193 [========>.....................] - ETA: 7:26 - loss: 1151610.1658 - acc: 0.1104 64/193 [========>.....................] - ETA: 7:22 - loss: 1133616.2930 - acc: 0.1101 65/193 [=========>....................] - ETA: 7:18 - loss: 1116176.0777 - acc: 0.1101 66/193 [=========>....................] - ETA: 7:14 - loss: 1099264.3538 - acc: 0.1099 67/193 [=========>....................] - ETA: 7:10 - loss: 1082857.4575 - acc: 0.1101 68/193 [=========>....................] - ETA: 7:06 - loss: 1066933.1168 - acc: 0.1101 69/193 [=========>....................] - ETA: 7:02 - loss: 1051470.3508 - acc: 0.1101 70/193 [=========>....................] - ETA: 6:58 - loss: 1036449.3820 - acc: 0.1105 71/193 [==========>...................] - ETA: 6:54 - loss: 1021851.5363 - acc: 0.1101 72/193 [==========>...................] - ETA: 6:49 - loss: 1007659.1857 - acc: 0.1103 73/193 [==========>...................] - ETA: 6:46 - loss: 993855.6668 - acc: 0.1102  74/193 [==========>...................] - ETA: 6:42 - loss: 980425.2160 - acc: 0.1099 75/193 [==========>...................] - ETA: 6:38 - loss: 967352.9104 - acc: 0.1101 76/193 [==========>...................] - ETA: 6:34 - loss: 954624.6128 - acc: 0.1102 77/193 [==========>...................] - ETA: 6:30 - loss: 942226.9204 - acc: 0.1098 78/193 [===========>..................] - ETA: 6:26 - loss: 930147.1176 - acc: 0.1100 79/193 [===========>..................] - ETA: 6:22 - loss: 918373.1325 - acc: 0.1099 80/193 [===========>..................] - ETA: 6:18 - loss: 906893.4968 - acc: 0.1099 81/193 [===========>..................] - ETA: 6:14 - loss: 895697.3492 - acc: 0.1094 82/193 [===========>..................] - ETA: 6:10 - loss: 884774.2388 - acc: 0.1098 83/193 [===========>..................] - ETA: 6:07 - loss: 874114.3359 - acc: 0.1099 84/193 [============>.................] - ETA: 6:03 - loss: 863708.2518 - acc: 0.1098 85/193 [============>.................] - ETA: 6:00 - loss: 853547.0053 - acc: 0.1096 86/193 [============>.................] - ETA: 5:56 - loss: 843622.0668 - acc: 0.1095 87/193 [============>.................] - ETA: 5:52 - loss: 833925.2876 - acc: 0.1103 88/193 [============>.................] - ETA: 5:49 - loss: 824448.8933 - acc: 0.1104 89/193 [============>.................] - ETA: 5:45 - loss: 815185.4486 - acc: 0.1106 90/193 [============>.................] - ETA: 5:42 - loss: 806127.8581 - acc: 0.1109 91/193 [=============>................] - ETA: 5:39 - loss: 797269.3354 - acc: 0.1109 92/193 [=============>................] - ETA: 5:36 - loss: 788603.3895 - acc: 0.1107 93/193 [=============>................] - ETA: 5:32 - loss: 780123.8079 - acc: 0.1108 94/193 [=============>................] - ETA: 5:28 - loss: 771824.6428 - acc: 0.1105 95/193 [=============>................] - ETA: 5:25 - loss: 763700.1965 - acc: 0.1109 96/193 [=============>................] - ETA: 5:21 - loss: 755745.0330 - acc: 0.1107 97/193 [==============>...............] - ETA: 5:18 - loss: 747953.8710 - acc: 0.1105 98/193 [==============>...............] - ETA: 5:14 - loss: 740321.7122 - acc: 0.11032022-01-04 14:52:23.494423: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.11GiB (rounded to 3339714560).  Current allocation summary follows.
2022-01-04 14:52:23.495409: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **************__**_____________***************______________________***_***************___**__******
2022-01-04 14:52:23.495465: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_grad_input_ops.cc:1063 : Resource exhausted: OOM when allocating tensor with shape[260,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File "../run_training.py", line 70, in <module>
    verbose=1)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py", line 603, in fit
    steps_name='steps_per_epoch')
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 1021, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3476, in __call__
    run_metadata=self.run_metadata)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1472, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[260,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training/RMSprop/gradients/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

