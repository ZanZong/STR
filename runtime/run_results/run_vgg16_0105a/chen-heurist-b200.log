nohup: ignoring input
WARNING:tensorflow:From ../run_training.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ../run_training.py:27: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/memory_saving_gradients.py:78: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 200), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'chen-heurist'), ('verbose', False)]
Shape of x_train: (50000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
Cannot find config for batch_size=200, use 256 instead
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'true', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/p32xlarge_VGG16_256_None/ilp_log/layer_names'}, {}]
[STR DEBUG] Solution is not configured, use Chen's heuristic to select checkpoints
[STR DEBUG] Pure recomputing strategy with Chen's greedy strategy
DEBUG bwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Reshape/shape/1', 'flatten/Shape', 'flatten/strided_slice', 'flatten/strided_slice/stack', 'flatten/strided_slice/stack_1', 'flatten/strided_slice/stack_2', 'input_1', 'loss/mul', 'loss/mul/x', 'loss/predictions_loss/Const_1', 'loss/predictions_loss/Const_2', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/values_0', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/values_0', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Cast/x', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Const', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel', 'predictions_target']
DEBUG fwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel']
DEBUG bwd_ops after call the gradient function: ['training/RMSprop/gradients/1641225227812706/gradients/Fill', 'training/RMSprop/gradients/1641225227812706/gradients/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block1_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block2_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block2_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block3_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block3_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block4_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block4_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641225227812706/gradients/block5_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/block5_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641225227812706/gradients/fc1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/fc1/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641225227812706/gradients/fc1/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641225227812706/gradients/fc1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/fc2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/fc2/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641225227812706/gradients/fc2/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641225227812706/gradients/fc2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641225227812706/gradients/flatten/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/flatten/Reshape_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/grad_ys_0', 'training/RMSprop/gradients/1641225227812706/gradients/loss/mul_grad/Mul', 'training/RMSprop/gradients/1641225227812706/gradients/loss/mul_grad/Mul_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_1_grad/Const', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_1_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_1_grad/Reshape/shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_1_grad/Tile', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_grad/Reshape/shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/Sum_grad/Tile', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims/dim', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/LogSoftmax', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/Neg', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Neg', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Reshape_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Shape_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Sum', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/Sum_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/div_no_nan', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/div_no_nan_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/div_no_nan_2', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/value_grad/mul', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape_1', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum', 'training/RMSprop/gradients/1641225227812706/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum_1', 'training/RMSprop/gradients/1641225227812706/gradients/predictions/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641225227812706/gradients/predictions/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641225227812706/gradients/predictions/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641225227812706/gradients/zeros_like']
DEBUG Using tensors ['block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Relu:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Relu:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Relu:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Relu:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Relu:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Relu:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Relu:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Relu:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/Relu:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc2/MatMul/ReadVariableOp:0', 'flatten/Reshape:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Number of checkpoints: 5:
DEBUG [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]


DEBUG checkpoints_disconnected: {<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>}
DEBUG Found 27 ops to copy within fwd_ops ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['loss/mul'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp']
DEBUG Processing list ['loss/mul:0']
DEBUG Copied_svg: SubGraphView (graphid=140173451410848):
** ops[27]:
  training/RMSprop/gradients/fc2/MatMul/ReadVariableOp
  training/RMSprop/gradients/fc2/MatMul
  training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/fc2/BiasAdd
  training/RMSprop/gradients/fc2/Relu
  training/RMSprop/gradients/predictions/MatMul/ReadVariableOp
  training/RMSprop/gradients/predictions/MatMul
  training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/predictions/BiasAdd
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul
  training/RMSprop/gradients/loss/predictions_loss/Sum
  training/RMSprop/gradients/loss/predictions_loss/num_elements
  training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast
  training/RMSprop/gradients/loss/predictions_loss/Sum_1
  training/RMSprop/gradients/loss/predictions_loss/value
  training/RMSprop/gradients/loss/mul
** inputs: empty
** outputs[2]:
  training/RMSprop/gradients/loss/mul:0
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits:1

DEBUG Copied ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'] to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul_1:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/loss/mul:0']
DEBUG with respect to boundary:[<tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(4096, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]
DEBUG Checkpoint gradients before loop {<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: None, <tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: None, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: None, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: None, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0' shape=(?, 4096) dtype=float32>}
DEBUG checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>], [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>], [<tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>], [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>], [<tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]]
DEBUG Processing list ['fc1/Relu:0']
DEBUG Found 15 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['fc1/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0']
DEBUG ops_to_copy = ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice']
DEBUG Copied ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice'] to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0'] restricted to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/fc1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0']
DEBUG Processing list ['block5_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block5_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu']
DEBUG Copied ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu'] to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block5_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block4_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block4_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu']
DEBUG Copied ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu'] to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block4_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block3_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block3_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu']
DEBUG Copied ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu'] to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block3_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block2_conv1/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block2_conv1/Relu'], stop_at ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu']
DEBUG Copied ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu'] to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block2_conv1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0']
  1/250 [..............................] - ETA: 1:33:25 - loss: 2.2860 - acc: 0.1200  2/250 [..............................] - ETA: 50:02 - loss: 205853265.1430 - acc: 0.1075  3/250 [..............................] - ETA: 35:30 - loss: 137235514.8841 - acc: 0.1033  4/250 [..............................] - ETA: 28:13 - loss: 102928453.1793 - acc: 0.1050  5/250 [..............................] - ETA: 23:50 - loss: 82342763.4849 - acc: 0.1020   6/250 [..............................] - ETA: 20:56 - loss: 68618973.8129 - acc: 0.1033  7/250 [..............................] - ETA: 18:50 - loss: 58816264.1694 - acc: 0.1007  8/250 [..............................] - ETA: 17:18 - loss: 51464231.4521 - acc: 0.0994  9/250 [>.............................] - ETA: 16:05 - loss: 45745983.7734 - acc: 0.1017 10/250 [>.............................] - ETA: 15:06 - loss: 41171385.6265 - acc: 0.1025 11/250 [>.............................] - ETA: 14:18 - loss: 37428532.5969 - acc: 0.1059 12/250 [>.............................] - ETA: 13:38 - loss: 34309488.4087 - acc: 0.1071 13/250 [>.............................] - ETA: 13:09 - loss: 31670297.1695 - acc: 0.1054 14/250 [>.............................] - ETA: 12:41 - loss: 29408133.2524 - acc: 0.1050 15/250 [>.............................] - ETA: 12:17 - loss: 27447591.1890 - acc: 0.1050 16/250 [>.............................] - ETA: 11:56 - loss: 25732116.8837 - acc: 0.1066 17/250 [=>............................] - ETA: 11:36 - loss: 24218463.0848 - acc: 0.1074 18/250 [=>............................] - ETA: 11:19 - loss: 22872993.0413 - acc: 0.1064 19/250 [=>............................] - ETA: 11:03 - loss: 21669151.4234 - acc: 0.1050 20/250 [=>............................] - ETA: 10:48 - loss: 20585693.9672 - acc: 0.1055 21/250 [=>............................] - ETA: 10:35 - loss: 19605422.9356 - acc: 0.1052 22/250 [=>............................] - ETA: 10:27 - loss: 18714267.4521 - acc: 0.1048 23/250 [=>............................] - ETA: 10:18 - loss: 17900603.7495 - acc: 0.1052 24/250 [=>............................] - ETA: 10:08 - loss: 17154745.3559 - acc: 0.1065 25/250 [==>...........................] - ETA: 9:59 - loss: 16468555.6338 - acc: 0.1064  26/250 [==>...........................] - ETA: 9:50 - loss: 15835149.7365 - acc: 0.1062 27/250 [==>...........................] - ETA: 9:41 - loss: 15248662.7945 - acc: 0.1061 28/250 [==>...........................] - ETA: 9:35 - loss: 14704067.7768 - acc: 0.1063 29/250 [==>...........................] - ETA: 9:30 - loss: 14197031.0358 - acc: 0.1055 30/250 [==>...........................] - ETA: 9:24 - loss: 13723796.7447 - acc: 0.1050 31/250 [==>...........................] - ETA: 9:17 - loss: 13281093.6981 - acc: 0.1048 32/250 [==>...........................] - ETA: 9:11 - loss: 12866059.5912 - acc: 0.1052 33/250 [==>...........................] - ETA: 9:05 - loss: 12476179.1444 - acc: 0.1058 34/250 [===>..........................] - ETA: 9:00 - loss: 12109232.9533 - acc: 0.1054 35/250 [===>..........................] - ETA: 8:55 - loss: 11763254.9359 - acc: 0.1054 36/250 [===>..........................] - ETA: 8:50 - loss: 11436497.9184 - acc: 0.1043 37/250 [===>..........................] - ETA: 8:46 - loss: 11127403.4425 - acc: 0.1043 38/250 [===>..........................] - ETA: 8:41 - loss: 10834577.0967 - acc: 0.1042 39/250 [===>..........................] - ETA: 8:36 - loss: 10556767.4864 - acc: 0.1051 40/250 [===>..........................] - ETA: 8:31 - loss: 10292848.3581 - acc: 0.1059 41/250 [===>..........................] - ETA: 8:26 - loss: 10041803.3324 - acc: 0.1056 42/250 [====>.........................] - ETA: 8:21 - loss: 9802712.8315 - acc: 0.1056  43/250 [====>.........................] - ETA: 8:16 - loss: 9574742.8349 - acc: 0.1052 44/250 [====>.........................] - ETA: 8:11 - loss: 9357135.0955 - acc: 0.1048 45/250 [====>.........................] - ETA: 8:07 - loss: 9149198.8111 - acc: 0.1044 46/250 [====>.........................] - ETA: 8:04 - loss: 8950303.2355 - acc: 0.1051 47/250 [====>.........................] - ETA: 7:59 - loss: 8759871.3008 - acc: 0.1051 48/250 [====>.........................] - ETA: 7:55 - loss: 8577374.0299 - acc: 0.1054 49/250 [====>.........................] - ETA: 7:51 - loss: 8402325.6273 - acc: 0.1055 50/250 [=====>........................] - ETA: 7:47 - loss: 8234279.1608 - acc: 0.1058 51/250 [=====>........................] - ETA: 7:43 - loss: 8072822.7517 - acc: 0.1068 52/250 [=====>........................] - ETA: 7:39 - loss: 7917576.2047 - acc: 0.1064 53/250 [=====>........................] - ETA: 7:35 - loss: 7768188.0177 - acc: 0.1073 54/250 [=====>........................] - ETA: 7:32 - loss: 7624332.7267 - acc: 0.1072 55/250 [=====>........................] - ETA: 7:28 - loss: 7485708.5369 - acc: 0.1082 56/250 [=====>........................] - ETA: 7:25 - loss: 7352035.2104 - acc: 0.1091 57/250 [=====>........................] - ETA: 7:21 - loss: 7223052.1829 - acc: 0.1093 58/250 [=====>........................] - ETA: 7:18 - loss: 7098516.8401 - acc: 0.1084 59/250 [======>.......................] - ETA: 7:16 - loss: 6978203.0342 - acc: 0.1088 60/250 [======>.......................] - ETA: 7:14 - loss: 6861899.6906 - acc: 0.1082 61/250 [======>.......................] - ETA: 7:11 - loss: 6749409.5695 - acc: 0.1080 62/250 [======>.......................] - ETA: 7:08 - loss: 6640548.1619 - acc: 0.1076 63/250 [======>.......................] - ETA: 7:05 - loss: 6535142.6719 - acc: 0.1077 64/250 [======>.......................] - ETA: 7:02 - loss: 6433031.1034 - acc: 0.1077 65/250 [======>.......................] - ETA: 6:58 - loss: 6334061.4295 - acc: 0.1078 66/250 [======>.......................] - ETA: 6:55 - loss: 6238090.8367 - acc: 0.1079 67/250 [=======>......................] - ETA: 6:52 - loss: 6144985.0377 - acc: 0.1081 68/250 [=======>......................] - ETA: 6:49 - loss: 6054617.6445 - acc: 0.1078 69/250 [=======>......................] - ETA: 6:46 - loss: 5966869.5961 - acc: 0.1076 70/250 [=======>......................] - ETA: 6:43 - loss: 5881628.6348 - acc: 0.1079 71/250 [=======>......................] - ETA: 6:40 - loss: 5798788.8273 - acc: 0.1069 72/250 [=======>......................] - ETA: 6:37 - loss: 5718250.1256 - acc: 0.1067 73/250 [=======>......................] - ETA: 6:34 - loss: 5639917.9635 - acc: 0.1064 74/250 [=======>......................] - ETA: 6:31 - loss: 5563702.8872 - acc: 0.1064 75/250 [========>.....................] - ETA: 6:29 - loss: 5489520.2127 - acc: 0.1057 76/250 [========>.....................] - ETA: 6:26 - loss: 5417289.7139 - acc: 0.1056 77/250 [========>.....................] - ETA: 6:23 - loss: 5346935.3317 - acc: 0.1062 78/250 [========>.....................] - ETA: 6:20 - loss: 5278384.9974 - acc: 0.1056 79/250 [========>.....................] - ETA: 6:17 - loss: 5211570.0266 - acc: 0.1054 80/250 [========>.....................] - ETA: 6:14 - loss: 5146425.4300 - acc: 0.1058 81/250 [========>.....................] - ETA: 6:12 - loss: 5082889.3420 - acc: 0.1060 82/250 [========>.....................] - ETA: 6:10 - loss: 5020902.9147 - acc: 0.1066 83/250 [========>.....................] - ETA: 6:07 - loss: 4960410.1363 - acc: 0.1064 84/250 [=========>....................] - ETA: 6:05 - loss: 4901357.6619 - acc: 0.1072 85/250 [=========>....................] - ETA: 6:02 - loss: 4843694.6605 - acc: 0.1070 86/250 [=========>....................] - ETA: 6:00 - loss: 4787372.6563 - acc: 0.1072 87/250 [=========>....................] - ETA: 5:57 - loss: 4732345.4111 - acc: 0.1071 88/250 [=========>....................] - ETA: 5:54 - loss: 4678568.7848 - acc: 0.1070 89/250 [=========>....................] - ETA: 5:51 - loss: 4626000.6221 - acc: 0.1070 90/250 [=========>....................] - ETA: 5:49 - loss: 4574600.6535 - acc: 0.1072 91/250 [=========>....................] - ETA: 5:46 - loss: 4524330.3419 - acc: 0.1073 92/250 [==========>...................] - ETA: 5:43 - loss: 4475152.8631 - acc: 0.1070 93/250 [==========>...................] - ETA: 5:40 - loss: 4427032.9810 - acc: 0.1071 94/250 [==========>...................] - ETA: 5:38 - loss: 4379936.9100 - acc: 0.1069 95/250 [==========>...................] - ETA: 5:35 - loss: 4333832.3351 - acc: 0.1070 96/250 [==========>...................] - ETA: 5:33 - loss: 4288688.2721 - acc: 0.1070 97/250 [==========>...................] - ETA: 5:31 - loss: 4244475.0147 - acc: 0.1071 98/250 [==========>...................] - ETA: 5:28 - loss: 4201164.0686 - acc: 0.1072 99/250 [==========>...................] - ETA: 5:26 - loss: 4158728.0910 - acc: 0.1072100/250 [===========>..................] - ETA: 5:24 - loss: 4117140.8337 - acc: 0.1075101/250 [===========>..................] - ETA: 5:21 - loss: 4076377.0859 - acc: 0.1071102/250 [===========>..................] - ETA: 5:19 - loss: 4036412.6272 - acc: 0.1072103/250 [===========>..................] - ETA: 5:16 - loss: 3997224.1775 - acc: 0.1071104/250 [===========>..................] - ETA: 5:14 - loss: 3958789.3516 - acc: 0.1068105/250 [===========>..................] - ETA: 5:11 - loss: 3921086.6668 - acc: 0.1066106/250 [===========>..................] - ETA: 5:09 - loss: 3884095.3048 - acc: 0.1067107/250 [===========>..................] - ETA: 5:06 - loss: 3847795.3705 - acc: 0.1068108/250 [===========>..................] - ETA: 5:04 - loss: 3812167.6569 - acc: 0.1067109/250 [============>.................] - ETA: 5:01 - loss: 3777193.6628 - acc: 0.1068110/250 [============>.................] - ETA: 4:59 - loss: 3742855.5595 - acc: 0.1066111/250 [============>.................] - ETA: 4:56 - loss: 3709136.1608 - acc: 0.1064112/250 [============>.................] - ETA: 4:54 - loss: 3676018.8943 - acc: 0.1062113/250 [============>.................] - ETA: 4:52 - loss: 3643487.7740 - acc: 0.1062114/250 [============>.................] - ETA: 4:49 - loss: 3611527.3750 - acc: 0.1066115/250 [============>.................] - ETA: 4:47 - loss: 3580122.8236 - acc: 0.1067116/250 [============>.................] - ETA: 4:45 - loss: 3549259.7156 - acc: 0.1071117/250 [=============>................] - ETA: 4:42 - loss: 3518924.1822 - acc: 0.1069118/250 [=============>................] - ETA: 4:40 - loss: 3489102.8103 - acc: 0.1070119/250 [=============>................] - ETA: 4:37 - loss: 3459782.6379 - acc: 0.1067120/250 [=============>................] - ETA: 4:35 - loss: 3430951.1352 - acc: 0.1074121/250 [=============>................] - ETA: 4:33 - loss: 3402596.1861 - acc: 0.1076122/250 [=============>................] - ETA: 4:31 - loss: 3374706.0723 - acc: 0.1072123/250 [=============>................] - ETA: 4:28 - loss: 3347269.4560 - acc: 0.1075124/250 [=============>................] - ETA: 4:26 - loss: 3320275.3663 - acc: 0.1076125/250 [==============>...............] - ETA: 4:24 - loss: 3293713.4169 - acc: 0.1074126/250 [==============>...............] - ETA: 4:21 - loss: 3267572.8525 - acc: 0.1078127/250 [==============>...............] - ETA: 4:19 - loss: 3241843.9505 - acc: 0.1080128/250 [==============>...............] - ETA: 4:17 - loss: 3216517.0627 - acc: 0.1080129/250 [==============>...............] - ETA: 4:14 - loss: 3191582.8397 - acc: 0.1081130/250 [==============>...............] - ETA: 4:12 - loss: 3167032.2202 - acc: 0.1083131/250 [==============>...............] - ETA: 4:10 - loss: 3142856.4193 - acc: 0.1081132/250 [==============>...............] - ETA: 4:07 - loss: 3119046.9185 - acc: 0.1080133/250 [==============>...............] - ETA: 4:05 - loss: 3095595.4552 - acc: 0.1077134/250 [===============>..............] - ETA: 4:03 - loss: 3072494.0138 - acc: 0.1078135/250 [===============>..............] - ETA: 4:01 - loss: 3049734.8159 - acc: 0.1079136/250 [===============>..............] - ETA: 3:58 - loss: 3027310.3121 - acc: 0.1078137/250 [===============>..............] - ETA: 3:56 - loss: 3005213.1734 - acc: 0.1077138/250 [===============>..............] - ETA: 3:54 - loss: 2983436.2830 - acc: 0.1073139/250 [===============>..............] - ETA: 3:52 - loss: 2961972.7291 - acc: 0.1074140/250 [===============>..............] - ETA: 3:49 - loss: 2940815.7975 - acc: 0.1071141/250 [===============>..............] - ETA: 3:47 - loss: 2919958.9642 - acc: 0.1072142/250 [================>.............] - ETA: 3:45 - loss: 2899395.8890 - acc: 0.1074143/250 [================>.............] - ETA: 3:43 - loss: 2879120.4354 - acc: 0.1074144/250 [================>.............] - ETA: 3:41 - loss: 2859126.5595 - acc: 0.1074145/250 [================>.............] - ETA: 3:38 - loss: 2839408.4611 - acc: 0.1074146/250 [================>.............] - ETA: 3:36 - loss: 2819960.4737 - acc: 0.1074147/250 [================>.............] - ETA: 3:34 - loss: 2800777.0848 - acc: 0.1076148/250 [================>.............] - ETA: 3:32 - loss: 2781852.9311 - acc: 0.1073149/250 [================>.............] - ETA: 3:30 - loss: 2763182.7926 - acc: 0.1074150/250 [=================>............] - ETA: 3:27 - loss: 2744761.5892 - acc: 0.1076151/250 [=================>............] - ETA: 3:25 - loss: 2726584.3752 - acc: 0.1080152/250 [=================>............] - ETA: 3:23 - loss: 2708646.3357 - acc: 0.1078153/250 [=================>............] - ETA: 3:21 - loss: 2690942.7892 - acc: 0.1077154/250 [=================>............] - ETA: 3:19 - loss: 2673469.1497 - acc: 0.1077155/250 [=================>............] - ETA: 3:16 - loss: 2656220.9778 - acc: 0.1079156/250 [=================>............] - ETA: 3:14 - loss: 2639193.9351 - acc: 0.1079157/250 [=================>............] - ETA: 3:12 - loss: 2622383.7972 - acc: 0.1081158/250 [=================>............] - ETA: 3:10 - loss: 2605786.4459 - acc: 0.1082159/250 [==================>...........] - ETA: 3:08 - loss: 2589397.8664 - acc: 0.1081160/250 [==================>...........] - ETA: 3:06 - loss: 2573214.1440 - acc: 0.1079161/250 [==================>...........] - ETA: 3:04 - loss: 2557231.4618 - acc: 0.1080162/250 [==================>...........] - ETA: 3:01 - loss: 2541446.0966 - acc: 0.1079163/250 [==================>...........] - ETA: 2:59 - loss: 2525854.4169 - acc: 0.1078164/250 [==================>...........] - ETA: 2:57 - loss: 2510452.8796 - acc: 0.1079165/250 [==================>...........] - ETA: 2:55 - loss: 2495238.0276 - acc: 0.1078166/250 [==================>...........] - ETA: 2:53 - loss: 2480206.4873 - acc: 0.1078167/250 [===================>..........] - ETA: 2:51 - loss: 2465354.9652 - acc: 0.1076168/250 [===================>..........] - ETA: 2:48 - loss: 2450680.2470 - acc: 0.1076169/250 [===================>..........] - ETA: 2:46 - loss: 2436179.1941 - acc: 0.1078170/250 [===================>..........] - ETA: 2:44 - loss: 2421848.7417 - acc: 0.1077171/250 [===================>..........] - ETA: 2:42 - loss: 2407685.8969 - acc: 0.1077172/250 [===================>..........] - ETA: 2:40 - loss: 2393687.7366 - acc: 0.1079173/250 [===================>..........] - ETA: 2:38 - loss: 2379851.4046 - acc: 0.1079174/250 [===================>..........] - ETA: 2:36 - loss: 2366174.1109 - acc: 0.1080175/250 [====================>.........] - ETA: 2:34 - loss: 2352653.1292 - acc: 0.1079176/250 [====================>.........] - ETA: 2:32 - loss: 2339285.7949 - acc: 0.1079177/250 [====================>.........] - ETA: 2:29 - loss: 2326069.5039 - acc: 0.1082178/250 [====================>.........] - ETA: 2:27 - loss: 2313001.7107 - acc: 0.1080179/250 [====================>.........] - ETA: 2:25 - loss: 2300079.9264 - acc: 0.1081180/250 [====================>.........] - ETA: 2:23 - loss: 2287301.7174 - acc: 0.1081181/250 [====================>.........] - ETA: 2:21 - loss: 2274664.7039 - acc: 0.1082182/250 [====================>.........] - ETA: 2:19 - loss: 2262166.5588 - acc: 0.1082183/250 [====================>.........] - ETA: 2:17 - loss: 2249805.0055 - acc: 0.1085184/250 [=====================>........] - ETA: 2:15 - loss: 2237577.8168 - acc: 0.1085185/250 [=====================>........] - ETA: 2:13 - loss: 2225482.8138 - acc: 0.1085186/250 [=====================>........] - ETA: 2:11 - loss: 2213517.8723 - acc: 0.1086187/250 [=====================>........] - ETA: 2:08 - loss: 2201680.8918 - acc: 0.1086188/250 [=====================>........] - ETA: 2:06 - loss: 2189969.8355 - acc: 0.1084189/250 [=====================>........] - ETA: 2:04 - loss: 2178382.7057 - acc: 0.1084190/250 [=====================>........] - ETA: 2:02 - loss: 2166917.5456 - acc: 0.1086191/250 [=====================>........] - ETA: 2:00 - loss: 2155572.4396 - acc: 0.1085192/250 [======================>.......] - ETA: 1:58 - loss: 2144345.5118 - acc: 0.1085193/250 [======================>.......] - ETA: 1:56 - loss: 2133234.9253 - acc: 0.1086194/250 [======================>.......] - ETA: 1:54 - loss: 2122238.8808 - acc: 0.1087195/250 [======================>.......] - ETA: 1:52 - loss: 2111355.6163 - acc: 0.1087196/250 [======================>.......] - ETA: 1:50 - loss: 2100583.4055 - acc: 0.1085197/250 [======================>.......] - ETA: 1:48 - loss: 2089920.5571 - acc: 0.1087198/250 [======================>.......] - ETA: 1:46 - loss: 2079365.4290 - acc: 0.1089199/250 [======================>.......] - ETA: 1:44 - loss: 2068916.4336 - acc: 0.1090200/250 [=======================>......] - ETA: 1:41 - loss: 2058571.8630 - acc: 0.1087201/250 [=======================>......] - ETA: 1:39 - loss: 2048330.2234 - acc: 0.1085202/250 [=======================>......] - ETA: 1:37 - loss: 2038189.9862 - acc: 0.1084203/250 [=======================>......] - ETA: 1:35 - loss: 2028149.6528 - acc: 0.1087204/250 [=======================>......] - ETA: 1:33 - loss: 2018207.7540 - acc: 0.1087205/250 [=======================>......] - ETA: 1:31 - loss: 2008362.8494 - acc: 0.1088206/250 [=======================>......] - ETA: 1:29 - loss: 1998613.5263 - acc: 0.1088207/250 [=======================>......] - ETA: 1:27 - loss: 1988958.3997 - acc: 0.1087208/250 [=======================>......] - ETA: 1:25 - loss: 1979396.1108 - acc: 0.1087209/250 [========================>.....] - ETA: 1:23 - loss: 1969925.3270 - acc: 0.1087210/250 [========================>.....] - ETA: 1:21 - loss: 1960544.7412 - acc: 0.1087211/250 [========================>.....] - ETA: 1:19 - loss: 1951253.0709 - acc: 0.1085212/250 [========================>.....] - ETA: 1:17 - loss: 1942049.0578 - acc: 0.1087213/250 [========================>.....] - ETA: 1:15 - loss: 1932931.4674 - acc: 0.1086214/250 [========================>.....] - ETA: 1:13 - loss: 1923899.0881 - acc: 0.1090215/250 [========================>.....] - ETA: 1:11 - loss: 1914950.7309 - acc: 0.1090216/250 [========================>.....] - ETA: 1:09 - loss: 1906085.2289 - acc: 0.1091217/250 [=========================>....] - ETA: 1:07 - loss: 1897301.4367 - acc: 0.1092218/250 [=========================>....] - ETA: 1:05 - loss: 1888598.2310 - acc: 0.1090219/250 [=========================>....] - ETA: 1:02 - loss: 1879974.5053 - acc: 0.1089220/250 [=========================>....] - ETA: 1:00 - loss: 1871429.1771 - acc: 0.1089221/250 [=========================>....] - ETA: 58s - loss: 1862961.1822 - acc: 0.1087 222/250 [=========================>....] - ETA: 56s - loss: 1854569.4756 - acc: 0.1087223/250 [=========================>....] - ETA: 54s - loss: 1846253.0308 - acc: 0.1087224/250 [=========================>....] - ETA: 52s - loss: 1838010.8400 - acc: 0.1086225/250 [==========================>...] - ETA: 50s - loss: 1829841.9130 - acc: 0.1087226/250 [==========================>...] - ETA: 48s - loss: 1821745.2776 - acc: 0.1085227/250 [==========================>...] - ETA: 46s - loss: 1813719.9782 - acc: 0.1083228/250 [==========================>...] - ETA: 44s - loss: 1805765.0761 - acc: 0.1088229/250 [==========================>...] - ETA: 42s - loss: 1797879.6494 - acc: 0.1087230/250 [==========================>...] - ETA: 40s - loss: 1790062.7914 - acc: 0.1087231/250 [==========================>...] - ETA: 38s - loss: 1782313.6118 - acc: 0.1085232/250 [==========================>...] - ETA: 36s - loss: 1774631.2354 - acc: 0.1085233/250 [==========================>...] - ETA: 34s - loss: 1767014.8023 - acc: 0.1083234/250 [===========================>..] - ETA: 32s - loss: 1759463.4668 - acc: 0.1084235/250 [===========================>..] - ETA: 30s - loss: 1751976.3980 - acc: 0.1082236/250 [===========================>..] - ETA: 28s - loss: 1744552.7791 - acc: 0.1081237/250 [===========================>..] - ETA: 26s - loss: 1737191.8066 - acc: 0.1081238/250 [===========================>..] - ETA: 24s - loss: 1729892.6910 - acc: 0.1079239/250 [===========================>..] - ETA: 22s - loss: 1722654.6559 - acc: 0.1078240/250 [===========================>..] - ETA: 20s - loss: 1715476.9378 - acc: 0.1078241/250 [===========================>..] - ETA: 18s - loss: 1708358.7858 - acc: 0.1079242/250 [============================>.] - ETA: 16s - loss: 1701299.4614 - acc: 0.1079243/250 [============================>.] - ETA: 14s - loss: 1694298.2383 - acc: 0.1080244/250 [============================>.] - ETA: 12s - loss: 1687354.4025 - acc: 0.1081245/250 [============================>.] - ETA: 10s - loss: 1680467.2511 - acc: 0.1080246/250 [============================>.] - ETA: 8s - loss: 1673636.0927 - acc: 0.1079 247/250 [============================>.] - ETA: 6s - loss: 1666860.2474 - acc: 0.1079248/250 [============================>.] - ETA: 4s - loss: 1660139.0461 - acc: 0.1079249/250 [============================>.] - ETA: 2s - loss: 1653471.8302 - acc: 0.1078  1/250 [..............................] - ETA: 3:44 - loss: 2.3044 - acc: 0.1300  2/250 [..............................] - ETA: 2:51 - loss: 2.3045 - acc: 0.1200  3/250 [..............................] - ETA: 2:31 - loss: 2.3038 - acc: 0.1167  4/250 [..............................] - ETA: 2:20 - loss: 2.3034 - acc: 0.1187  5/250 [..............................] - ETA: 2:14 - loss: 2.3034 - acc: 0.1120  6/250 [..............................] - ETA: 2:09 - loss: 2.3029 - acc: 0.1175  7/250 [..............................] - ETA: 2:05 - loss: 2.3034 - acc: 0.1121  8/250 [..............................] - ETA: 2:04 - loss: 2.3029 - acc: 0.1106  9/250 [>.............................] - ETA: 2:02 - loss: 2.3029 - acc: 0.1089 10/250 [>.............................] - ETA: 2:00 - loss: 2.3031 - acc: 0.1080 11/250 [>.............................] - ETA: 1:59 - loss: 2.3032 - acc: 0.1050 12/250 [>.............................] - ETA: 1:57 - loss: 2.3032 - acc: 0.1042 13/250 [>.............................] - ETA: 1:56 - loss: 2.3033 - acc: 0.1058 14/250 [>.............................] - ETA: 1:55 - loss: 2.3031 - acc: 0.1043 15/250 [>.............................] - ETA: 1:54 - loss: 2.3031 - acc: 0.1023 16/250 [>.............................] - ETA: 1:57 - loss: 2.3033 - acc: 0.1013 17/250 [=>............................] - ETA: 1:58 - loss: 2.3033 - acc: 0.0991 18/250 [=>............................] - ETA: 1:58 - loss: 2.3031 - acc: 0.1000 19/250 [=>............................] - ETA: 1:57 - loss: 2.3030 - acc: 0.0997 20/250 [=>............................] - ETA: 1:57 - loss: 2.3033 - acc: 0.0990 21/250 [=>............................] - ETA: 1:56 - loss: 2.3031 - acc: 0.0988 22/250 [=>............................] - ETA: 1:56 - loss: 2.3032 - acc: 0.0984 23/250 [=>............................] - ETA: 1:55 - loss: 2.3033 - acc: 0.0970 24/250 [=>............................] - ETA: 1:54 - loss: 2.3031 - acc: 0.0990 25/250 [==>...........................] - ETA: 1:54 - loss: 2.3031 - acc: 0.0982 26/250 [==>...........................] - ETA: 1:53 - loss: 2.3030 - acc: 0.0992 27/250 [==>...........................] - ETA: 1:53 - loss: 2.3030 - acc: 0.0981 28/250 [==>...........................] - ETA: 1:52 - loss: 2.3028 - acc: 0.1000 29/250 [==>...........................] - ETA: 1:51 - loss: 2.3026 - acc: 0.1003 30/250 [==>...........................] - ETA: 1:51 - loss: 2.3026 - acc: 0.1005 31/250 [==>...........................] - ETA: 1:50 - loss: 2.3026 - acc: 0.0994 32/250 [==>...........................] - ETA: 1:49 - loss: 2.3026 - acc: 0.0992 33/250 [==>...........................] - ETA: 1:49 - loss: 2.3026 - acc: 0.0995 34/250 [===>..........................] - ETA: 1:48 - loss: 2.3026 - acc: 0.0990 35/250 [===>..........................] - ETA: 1:48 - loss: 2.3026 - acc: 0.0997 36/250 [===>..........................] - ETA: 1:47 - loss: 2.3026 - acc: 0.0996 37/250 [===>..........................] - ETA: 1:47 - loss: 2.3024 - acc: 0.0991 38/250 [===>..........................] - ETA: 1:47 - loss: 2.3025 - acc: 0.0988 39/250 [===>..........................] - ETA: 1:47 - loss: 2.3026 - acc: 0.0986 40/250 [===>..........................] - ETA: 1:47 - loss: 2.3026 - acc: 0.0986 41/250 [===>..........................] - ETA: 1:47 - loss: 2.3027 - acc: 0.0988 42/250 [====>.........................] - ETA: 1:47 - loss: 2.3026 - acc: 0.0988 43/250 [====>.........................] - ETA: 1:46 - loss: 2.3027 - acc: 0.0995 44/250 [====>.........................] - ETA: 1:46 - loss: 2.3026 - acc: 0.1002 45/250 [====>.........................] - ETA: 1:45 - loss: 2.3026 - acc: 0.1010 46/250 [====>.........................] - ETA: 1:44 - loss: 2.3027 - acc: 0.1004 47/250 [====>.........................] - ETA: 1:44 - loss: 2.3028 - acc: 0.1000 48/250 [====>.........................] - ETA: 1:43 - loss: 2.3028 - acc: 0.1005 49/250 [====>.........................] - ETA: 1:43 - loss: 2.3028 - acc: 0.1008 50/250 [=====>........................] - ETA: 1:42 - loss: 2.3028 - acc: 0.1000250/250 [==============================] - 531s 2s/step - loss: 1646857.9521 - acc: 0.1078 - val_loss: 2.3028 - val_acc: 0.1000
