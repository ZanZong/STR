WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 50), ('epochs', 1), ('model_name', 'vgg_unet'), ('strategy', 'str'), ('verbose', False)]
Cannot find config for batch_size=50, use 40 instead
There are 367 and 367 images downloaded for train and test
Verifying train dataset
  0%|          | 0/367 [00:00<?, ?it/s]  2%|▏         | 8/367 [00:00<00:04, 73.63it/s]  5%|▌         | 20/367 [00:00<00:03, 97.94it/s]  9%|▉         | 33/367 [00:00<00:02, 111.51it/s] 13%|█▎        | 47/367 [00:00<00:02, 119.87it/s] 16%|█▋        | 60/367 [00:00<00:02, 123.06it/s] 20%|█▉        | 73/367 [00:00<00:02, 124.69it/s] 23%|██▎       | 86/367 [00:00<00:02, 126.23it/s] 27%|██▋       | 100/367 [00:00<00:02, 126.54it/s] 32%|███▏      | 117/367 [00:00<00:01, 137.51it/s] 37%|███▋      | 134/367 [00:01<00:01, 146.71it/s] 41%|████▏     | 152/367 [00:01<00:01, 153.48it/s] 46%|████▋     | 170/367 [00:01<00:01, 159.29it/s] 51%|█████     | 188/367 [00:01<00:01, 163.61it/s] 56%|█████▌    | 205/367 [00:01<00:00, 164.46it/s] 61%|██████    | 223/367 [00:01<00:00, 166.67it/s] 65%|██████▌   | 240/367 [00:01<00:00, 166.77it/s] 70%|███████   | 257/367 [00:01<00:00, 167.50it/s] 75%|███████▍  | 274/367 [00:01<00:00, 167.45it/s] 80%|███████▉  | 292/367 [00:01<00:00, 169.84it/s] 84%|████████▍ | 309/367 [00:02<00:00, 169.09it/s] 89%|████████▉ | 327/367 [00:02<00:00, 171.51it/s] 94%|█████████▍| 345/367 [00:02<00:00, 171.01it/s] 99%|█████████▉| 363/367 [00:02<00:00, 169.68it/s]100%|██████████| 367/367 [00:02<00:00, 152.48it/s]
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:928: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
Dataset verified! 
Starting Epoch  0
[STR DEBUG] Parsing STR configuration: [{'strategy': 'hybrid', 'verbose': 'false', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/layer_names'}, {'r': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/R', 'p': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/P', 'q': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/PrunedQ'}]
[STR DEBUG] Processing layer 0's swapping, swap out at [1], swap in at [69]
[STR DEBUG] Find swapout ops: name: "input_1"
op: "Placeholder"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: -1
      }
      dim {
        size: 320
      }
      dim {
        size: 640
      }
      dim {
        size: 3
      }
    }
  }
}
, 
	choose swap tensor Tensor("input_1:0", shape=(?, 320, 640, 3), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block1_conv1/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block1_conv1/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput"
input: "block1_conv1/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>]
[STR DEBUG] Processing layer 1's swapping, swap out at [2], swap in at [68]
[STR DEBUG] Find swapout ops: name: "block1_conv1/Relu"
op: "Relu"
input: "block1_conv1/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block1_conv1/Relu:0", shape=(?, 320, 640, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block1_conv2/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block1_conv2/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad"
input: "block1_conv2/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block1_conv1/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 2's swapping, swap out at [3], swap in at [27, 63]
[STR DEBUG] Find swapout ops: name: "block1_conv2/Relu"
op: "Relu"
input: "block1_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block1_conv2/Relu:0", shape=(?, 320, 640, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block1_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 27, use the last op name: "batch_normalization_2/moving_mean"
op: "VarHandleOp"
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_2/moving_mean"
    }
  }
}
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 128
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: "batch_normalization_2/moving_mean"
  }
}

[STR DEBUG] Add swap-in op at name: "batch_normalization_2/moving_mean"
op: "VarHandleOp"
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_2/moving_mean"
    }
  }
}
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 128
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: "batch_normalization_2/moving_mean"
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block1_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block3_conv1/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput"
input: "block3_conv1/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block1_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 3's swapping, swap out at [4], swap in at [66]
[STR DEBUG] Find swapout ops: name: "block1_pool/MaxPool"
op: "MaxPool"
input: "block1_conv2/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
, 
	choose swap tensor Tensor("block1_pool/MaxPool:0", shape=(?, 160, 320, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block2_conv1/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block2_conv1/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput"
input: "block2_conv1/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block1_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>]
[STR DEBUG] Processing layer 4's swapping, swap out at [5], swap in at [64]
[STR DEBUG] Find swapout ops: name: "block2_conv1/Relu"
op: "Relu"
input: "block2_conv1/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block2_conv1/Relu:0", shape=(?, 160, 320, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block2_conv2/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block2_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block2_conv2/Relu"
input: "block2_pool/MaxPool"
input: "training/Adadelta/gradients/gradients/AddN_16"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block2_conv1/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 5's swapping, swap out at [6], swap in at [22, 57]
[STR DEBUG] Find swapout ops: name: "block2_conv2/Relu"
op: "Relu"
input: "block2_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block2_conv2/Relu:0", shape=(?, 160, 320, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block2_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 22, use the last op name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block4_conv3/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block4_pool/MaxPool_grad/MaxPoolGrad"
input: "block4_conv3/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block2_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block2_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 6's swapping, swap out at [7], swap in at [60]
[STR DEBUG] Find swapout ops: name: "block2_pool/MaxPool"
op: "MaxPool"
input: "block2_conv2/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
, 
	choose swap tensor Tensor("block2_pool/MaxPool:0", shape=(?, 80, 160, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block3_conv1/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block3_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block3_conv3/Relu"
input: "block3_pool/MaxPool"
input: "training/Adadelta/gradients/gradients/AddN_15"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block2_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>]
[STR DEBUG] Processing layer 7's swapping, swap out at [8], swap in at [62]
[STR DEBUG] Find swapout ops: name: "block3_conv1/Relu"
op: "Relu"
input: "block3_conv1/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block3_conv1/Relu:0", shape=(?, 80, 160, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block3_conv2/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block3_conv2/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput"
input: "block3_conv2/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block3_conv1/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 8's swapping, swap out at [9], swap in at [55]
[STR DEBUG] Find swapout ops: name: "block3_conv2/Relu"
op: "Relu"
input: "block3_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block3_conv2/Relu:0", shape=(?, 80, 160, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block3_conv3/Relu' type=Relu>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 55, use the last op name: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Reshape"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Shape"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Reshape"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Shape"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block3_conv2/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 9's swapping, swap out at [10], swap in at [17, 56]
[STR DEBUG] Find swapout ops: name: "block3_conv3/Relu"
op: "Relu"
input: "block3_conv3/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block3_conv3/Relu:0", shape=(?, 80, 160, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block3_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 17, use the last op name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block4_pool/MaxPool_grad/MaxPoolGrad"
op: "MaxPoolGrad"
input: "block4_conv3/Relu"
input: "block4_pool/MaxPool"
input: "training/Adadelta/gradients/gradients/zero_padding2d/Pad_grad/Slice_1"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block3_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block3_conv3/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 10's swapping, swap out at [11], swap in at [53]
[STR DEBUG] Find swapout ops: name: "block3_pool/MaxPool"
op: "MaxPool"
input: "block3_conv3/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
, 
	choose swap tensor Tensor("block3_pool/MaxPool:0", shape=(?, 40, 80, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block4_conv1/Relu' type=Relu>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 53, use the last op name: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/ReadVariableOp_3/Switch_grad/cond_grad"
op: "Merge"
input: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/FusedBatchNormV3_1_grad/FusedBatchNormGradV3:2"
input: "training/Adadelta/gradients/gradients/zeros_15"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 11's swapping, swap out at [12], swap in at [58]
[STR DEBUG] Find swapout ops: name: "block4_conv1/Relu"
op: "Relu"
input: "block4_conv1/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block4_conv1/Relu:0", shape=(?, 40, 80, 512), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block4_conv2/Relu' type=Relu>]
[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/block4_conv2/Relu_grad/ReluGrad"
op: "ReluGrad"
input: "training/Adadelta/gradients/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput"
input: "block4_conv2/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'training/Adadelta/gradients/gradients/block4_conv1/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 12's swapping, swap out at [13], swap in at [54]
[STR DEBUG] Find swapout ops: name: "block4_conv2/Relu"
op: "Relu"
input: "block4_conv2/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block4_conv2/Relu:0", shape=(?, 40, 80, 512), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block4_conv3/Relu' type=Relu>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 54, use the last op name: "training/Adadelta/gradients/gradients/conv2d_1/BiasAdd_grad/BiasAddGrad"
op: "BiasAddGrad"
input: "training/Adadelta/gradients/gradients/AddN_9"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}

[STR DEBUG] Processing layer 13's swapping, swap out at [14], swap in at [33]
[STR DEBUG] Find swapout ops: name: "block4_conv3/Relu"
op: "Relu"
input: "block4_conv3/BiasAdd"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("block4_conv3/Relu:0", shape=(?, 40, 80, 512), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'block4_pool/MaxPool' type=MaxPool>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 33, use the last op name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Add swap-in op at name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block4_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>, <tf.Operation 'training/Adadelta/gradients/gradients/block4_conv3/Relu_grad/ReluGrad' type=ReluGrad>]
[STR DEBUG] Processing layer 14's swapping, swap out at [15], swap in at [35]
[STR DEBUG] Cannot find swap-out control nodes for layer 14, use the first op name: "zero_padding2d_2/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "block4_pool/MaxPool"
op: "MaxPool"
input: "block4_conv3/Relu"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "ksize"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 2
      i: 2
      i: 1
    }
  }
}
, 
	choose swap tensor Tensor("block4_pool/MaxPool:0", shape=(?, 20, 40, 512), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_2/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 35, use the last op name: "loss/activation_loss/truediv"
op: "RealDiv"
input: "activation/truediv"
input: "loss/activation_loss/Sum"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Add swap-in op at name: "loss/activation_loss/truediv"
op: "RealDiv"
input: "activation/truediv"
input: "loss/activation_loss/Sum"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/block4_pool/MaxPool_grad/MaxPoolGrad' type=MaxPoolGrad>]
[STR DEBUG] Processing layer 15's swapping, swap out at [16], swap in at [32]
[STR DEBUG] Cannot find swap-out activation nodes for layer 15, among [<tf.Operation 'zero_padding2d_2/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>, <tf.Operation 'zero_padding2d_1/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>, <tf.Operation 'zero_padding2d_3/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>, <tf.Operation 'zero_padding2d/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d/Pad' type=Pad>]
[STR DEBUG] Choose op that have outputs: name: "zero_padding2d/Pad"
op: "Pad"
input: "block4_pool/MaxPool"
input: "zero_padding2d/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 15, use the first op name: "conv2d_3/BiasAdd"
op: "BiasAdd"
input: "conv2d_3/Conv2D"
input: "conv2d_3/BiasAdd/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}

[STR DEBUG] Find swapout ops: name: "zero_padding2d/Pad"
op: "Pad"
input: "block4_pool/MaxPool"
input: "zero_padding2d/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("zero_padding2d/Pad:0", shape=(?, 22, 42, 512), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 32, use the last op name: "batch_normalization_3/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Processing layer 16's swapping, swap out at [17], swap in at [34]
[STR DEBUG] Cannot find swap-out activation nodes for layer 16, among [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d/dilation_rate' type=Const>, <tf.Operation 'conv2d_3/dilation_rate' type=Const>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_2/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_2/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_2/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_2/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_2/bias' type=VarHandleOp>, <tf.Operation 'conv2d_2/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_2/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_4/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_4/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_1/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_1/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_1/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_1/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_1/bias' type=VarHandleOp>, <tf.Operation 'conv2d_1/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_1/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/dilation_rate' type=Const>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d/kernel' type=VarHandleOp>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d/bias' type=VarHandleOp>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_3/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_3/bias' type=VarHandleOp>, <tf.Operation 'conv2d_3/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_1/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_4/bias' type=VarHandleOp>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_1/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/dilation_rate' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d/Conv2D' type=Conv2D>, <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/dilation_rate' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform' type=Add>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_1/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_1/kernel/Initializer/random_uniform/mul"
input: "conv2d_1/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_1/kernel"
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 16, use the first op name: "batch_normalization_1/AssignMovingAvg_1/sub_1"
op: "Sub"
input: "batch_normalization_1/AssignMovingAvg_1/ReadVariableOp"
input: "batch_normalization_1/cond/Merge_2"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_1/moving_variance"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_1/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_1/kernel/Initializer/random_uniform/mul"
input: "conv2d_1/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_1/kernel"
    }
  }
}
, 
	choose swap tensor Tensor("conv2d_1/kernel/Initializer/random_uniform:0", shape=(3, 3, 768, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub_1' type=Sub>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 34, use the last op name: "reshape/Reshape/shape/2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 50
    }
  }
}

[STR DEBUG] Processing layer 17's swapping, swap out at [18], swap in at [52]
[STR DEBUG] Cannot find swap-out activation nodes for layer 17, among [<tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_3/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_3/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond_1/pred_id' type=Identity>, <tf.Operation 'batch_normalization/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_2/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_2/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond_1/pred_id' type=Identity>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_3/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_3/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_3/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_2/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_3/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/Const' type=Const>, <tf.Operation 'batch_normalization_3/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_2/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_3/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_3/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization/cond/Const' type=Const>, <tf.Operation 'batch_normalization/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_1/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_1/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_1/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_2/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_1/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_3/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_3/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_3/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_3/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_3/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_2/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_2/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_2/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_2/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_1/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_1/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_2/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_1/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/cond/Const' type=Const>, <tf.Operation 'batch_normalization_2/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/Const' type=Const>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_1/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_3/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_2/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_1/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_1/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_3/cond_1/pred_id' type=Identity>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond_1/pred_id' type=Identity>]
[STR DEBUG] Choose op that have outputs: name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 17, use the first op name: "up_sampling2d_1/Shape"
op: "Shape"
input: "batch_normalization_1/cond/Merge"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "out_type"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Find swapout ops: name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}
, 
	choose swap tensor Tensor("batch_normalization_1/cond_1/pred_id:0", shape=(), dtype=bool), 
	finish at the end of ops: [<tf.Operation 'up_sampling2d_1/Shape' type=Shape>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 52, use the last op name: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 18's swapping, swap out at [19], swap in at [51]
[STR DEBUG] Cannot find swap-out activation nodes for layer 18, among [<tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_1/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_1/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_1/Const' type=Const>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d/mul' type=Mul>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/strided_slice/stack_2' type=Const>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_2/Const' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_1/strided_slice/stack_2' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d/Const' type=Const>, <tf.Operation 'up_sampling2d/Shape' type=Shape>, <tf.Operation 'up_sampling2d/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_2' type=Const>]
[STR DEBUG] Choose op that have outputs: name: "up_sampling2d_2/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 18, use the first op name: "concatenate_1/concat/axis"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 3
    }
  }
}

[STR DEBUG] Find swapout ops: name: "up_sampling2d_2/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}
, 
	choose swap tensor Tensor("up_sampling2d_2/strided_slice/stack_2:0", shape=(1,), dtype=int32), 
	finish at the end of ops: [<tf.Operation 'concatenate_1/concat/axis' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 51, use the last op name: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/ShapeN"
op: "ShapeN"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "out_type"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Processing layer 19's swapping, swap out at [20], swap in at [50]
[STR DEBUG] Cannot find swap-out activation nodes for layer 19, among [<tf.Operation 'concatenate_1/concat/axis' type=Const>, <tf.Operation 'concatenate/concat/axis' type=Const>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>, <tf.Operation 'concatenate/concat' type=ConcatV2>, <tf.Operation 'concatenate_2/concat/axis' type=Const>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>]
[STR DEBUG] Choose op that have outputs: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 19, use the first op name: "zero_padding2d_1/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("concatenate_2/concat:0", shape=(?, 160, 320, 192), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_1/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 50, use the last op name: "training/Adadelta/gradients/gradients/zero_padding2d_1/Pad_grad/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/gradients/zero_padding2d_1/Pad_grad/Slice"
input: "training/Adadelta/gradients/gradients/zero_padding2d_1/Pad_grad/Reshape/shape"
attr {
  key: "T"
  value {
    type: DT_INT32
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Processing layer 20's swapping, swap out at [21], swap in at [49]
[STR DEBUG] Cannot find swap-out activation nodes for layer 20, among [<tf.Operation 'zero_padding2d_1/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_1/Pad' type=Pad>]
[STR DEBUG] Choose op that have outputs: name: "zero_padding2d_1/Pad"
op: "Pad"
input: "concatenate/concat"
input: "zero_padding2d_1/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 20, use the first op name: "conv2d_1/kernel/Initializer/random_uniform/sub"
op: "Sub"
input: "conv2d_1/kernel/Initializer/random_uniform/max"
input: "conv2d_1/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_1/kernel"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "zero_padding2d_1/Pad"
op: "Pad"
input: "concatenate/concat"
input: "zero_padding2d_1/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("zero_padding2d_1/Pad:0", shape=(?, 42, 82, 768), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/sub' type=Sub>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 49, use the last op name: "training/Adadelta/gradients/gradients/conv2d_1/BiasAdd_grad/BiasAddGrad"
op: "BiasAddGrad"
input: "training/Adadelta/gradients/gradients/AddN_9"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}

[STR DEBUG] Processing layer 21's swapping, swap out at [22], swap in at [48]
[STR DEBUG] Cannot find swap-out activation nodes for layer 21, among [<tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_1/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_1/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_1/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_1/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_1/bias' type=VarHandleOp>, <tf.Operation 'conv2d_1/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_1/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_1/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_1/dilation_rate' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_1/kernel/Initializer/random_uniform' type=Add>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_1/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_1/kernel/Initializer/random_uniform/mul"
input: "conv2d_1/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_1/kernel"
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 21, use the first op name: "batch_normalization_1/AssignMovingAvg_1/sub_1"
op: "Sub"
input: "batch_normalization_1/AssignMovingAvg_1/ReadVariableOp"
input: "batch_normalization_1/cond/Merge_2"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_1/moving_variance"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_1/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_1/kernel/Initializer/random_uniform/mul"
input: "conv2d_1/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_1/kernel"
    }
  }
}
, 
	choose swap tensor Tensor("conv2d_1/kernel/Initializer/random_uniform:0", shape=(3, 3, 768, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub_1' type=Sub>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 48, use the last op name: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/ReadVariableOp_3/Switch_grad/cond_grad"
op: "Merge"
input: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/FusedBatchNormV3_1_grad/FusedBatchNormGradV3:2"
input: "training/Adadelta/gradients/gradients/zeros_15"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 22's swapping, swap out at [23], swap in at [47]
[STR DEBUG] Cannot find swap-out activation nodes for layer 22, among [<tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_1/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_1/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_1/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_1/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_1/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_1/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_1/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_1/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_1/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_1/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_1/cond/Const' type=Const>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_1/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_1/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_1/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_1/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization_1/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_1/cond_1/pred_id' type=Identity>]
[STR DEBUG] Choose op that have outputs: name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 22, use the first op name: "up_sampling2d_1/Shape"
op: "Shape"
input: "batch_normalization_1/cond/Merge"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "out_type"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Find swapout ops: name: "batch_normalization_1/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}
, 
	choose swap tensor Tensor("batch_normalization_1/cond_1/pred_id:0", shape=(), dtype=bool), 
	finish at the end of ops: [<tf.Operation 'up_sampling2d_1/Shape' type=Shape>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 47, use the last op name: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_1/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 23's swapping, swap out at [24], swap in at [46, 61]
[STR DEBUG] Cannot find swap-out activation nodes for layer 23, among [<tf.Operation 'up_sampling2d_1/Shape' type=Shape>, <tf.Operation 'up_sampling2d_1/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_1/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_1/Const' type=Const>, <tf.Operation 'up_sampling2d_1/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_1/mul' type=Mul>, <tf.Operation 'up_sampling2d_1/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_1/strided_slice/stack_2' type=Const>]
[STR DEBUG] Choose op that have outputs: name: "up_sampling2d_1/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 23, use the first op name: "concatenate_1/concat/axis"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 3
    }
  }
}

[STR DEBUG] Find swapout ops: name: "up_sampling2d_1/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}
, 
	choose swap tensor Tensor("up_sampling2d_1/strided_slice/stack_2:0", shape=(1,), dtype=int32), 
	finish at the end of ops: [<tf.Operation 'concatenate_1/concat/axis' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 46, use the last op name: "training/Adadelta/gradients/gradients/concatenate_1/concat_grad/Rank"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 4
    }
  }
}

[STR DEBUG] Processing layer 24's swapping, swap out at [25], swap in at [45]
[STR DEBUG] Cannot find swap-out activation nodes for layer 24, among [<tf.Operation 'concatenate_1/concat/axis' type=Const>, <tf.Operation 'concatenate_1/concat' type=ConcatV2>]
[STR DEBUG] Choose op that have outputs: name: "concatenate_1/concat"
op: "ConcatV2"
input: "up_sampling2d_1/resize/ResizeNearestNeighbor"
input: "block2_pool/MaxPool"
input: "concatenate_1/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 24, use the first op name: "zero_padding2d_2/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "concatenate_1/concat"
op: "ConcatV2"
input: "up_sampling2d_1/resize/ResizeNearestNeighbor"
input: "block2_pool/MaxPool"
input: "concatenate_1/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("concatenate_1/concat:0", shape=(?, 80, 160, 384), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_2/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 45, use the last op name: "training/Adadelta/gradients/gradients/zero_padding2d_2/Pad_grad/stack/1"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 1
    }
  }
}

[STR DEBUG] Processing layer 25's swapping, swap out at [26], swap in at [44]
[STR DEBUG] Cannot find swap-out activation nodes for layer 25, among [<tf.Operation 'zero_padding2d_2/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_2/Pad' type=Pad>]
[STR DEBUG] Choose op that have outputs: name: "zero_padding2d_2/Pad"
op: "Pad"
input: "concatenate_1/concat"
input: "zero_padding2d_2/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 25, use the first op name: "conv2d_2/kernel/Initializer/random_uniform/mul"
op: "Mul"
input: "conv2d_2/kernel/Initializer/random_uniform/RandomUniform"
input: "conv2d_2/kernel/Initializer/random_uniform/sub"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_2/kernel"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "zero_padding2d_2/Pad"
op: "Pad"
input: "concatenate_1/concat"
input: "zero_padding2d_2/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("zero_padding2d_2/Pad:0", shape=(?, 82, 162, 384), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/mul' type=Mul>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 44, use the last op name: "training/Adadelta/gradients/gradients/conv2d_2/Conv2D_grad/Conv2DBackpropFilter"
op: "Conv2DBackpropFilter"
input: "zero_padding2d_2/Pad"
input: "training/Adadelta/gradients/gradients/conv2d_2/Conv2D_grad/ShapeN:1"
input: "training/Adadelta/gradients/gradients/AddN_6"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 26's swapping, swap out at [27], swap in at [43]
[STR DEBUG] Cannot find swap-out activation nodes for layer 26, among [<tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_2/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_2/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_2/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_2/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_2/bias' type=VarHandleOp>, <tf.Operation 'conv2d_2/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_2/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_2/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_2/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_2/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_2/dilation_rate' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_2/kernel/Initializer/random_uniform' type=Add>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_2/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_2/kernel/Initializer/random_uniform/mul"
input: "conv2d_2/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_2/kernel"
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 26, use the first op name: "batch_normalization_2/AssignMovingAvg_1/sub"
op: "Sub"
input: "batch_normalization_2/AssignMovingAvg_1/sub/x"
input: "batch_normalization_2/cond_1/Merge"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_2/moving_variance"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_2/kernel/Initializer/random_uniform"
op: "Add"
input: "conv2d_2/kernel/Initializer/random_uniform/mul"
input: "conv2d_2/kernel/Initializer/random_uniform/min"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_2/kernel"
    }
  }
}
, 
	choose swap tensor Tensor("conv2d_2/kernel/Initializer/random_uniform:0", shape=(3, 3, 384, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub' type=Sub>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 43, use the last op name: "training/Adadelta/gradients/gradients/batch_normalization_2/cond/Merge_grad/cond_grad"
op: "Switch"
input: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
input: "batch_normalization_2/cond/pred_id"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
    }
  }
}

[STR DEBUG] Processing layer 27's swapping, swap out at [28], swap in at [42]
[STR DEBUG] Cannot find swap-out activation nodes for layer 27, among [<tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_2/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_2/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond_1/pred_id' type=Identity>, <tf.Operation 'batch_normalization_2/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_2/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_2/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_2/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_2/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_2/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_2/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_2/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_2/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_2/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_2/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_2/cond/Const' type=Const>, <tf.Operation 'batch_normalization_2/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_2/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_2/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_2/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_2/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_2/moving_mean' type=VarHandleOp>]
[STR DEBUG] Choose op that have outputs: name: "batch_normalization_2/moving_mean"
op: "VarHandleOp"
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_2/moving_mean"
    }
  }
}
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 128
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: "batch_normalization_2/moving_mean"
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 27, use the first op name: "up_sampling2d_2/Shape"
op: "Shape"
input: "batch_normalization_2/cond/Merge"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "out_type"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Find swapout ops: name: "batch_normalization_2/moving_mean"
op: "VarHandleOp"
attr {
  key: "_class"
  value {
    list {
      s: "loc:@batch_normalization_2/moving_mean"
    }
  }
}
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 128
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: "batch_normalization_2/moving_mean"
  }
}
, 
	choose swap tensor Tensor("batch_normalization_2/moving_mean:0", shape=(), dtype=resource), 
	finish at the end of ops: [<tf.Operation 'up_sampling2d_2/Shape' type=Shape>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 42, use the last op name: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 28's swapping, swap out at [29], swap in at [41, 65]
[STR DEBUG] Cannot find swap-out activation nodes for layer 28, among [<tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_2/Const' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_2' type=Const>]
[STR DEBUG] Choose op that have outputs: name: "up_sampling2d_2/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 28, use the first op name: "concatenate_2/concat/axis"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
      }
      int_val: 3
    }
  }
}

[STR DEBUG] Find swapout ops: name: "up_sampling2d_2/strided_slice/stack_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 1
    }
  }
}
, 
	choose swap tensor Tensor("up_sampling2d_2/strided_slice/stack_2:0", shape=(1,), dtype=int32), 
	finish at the end of ops: [<tf.Operation 'concatenate_2/concat/axis' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 41, use the last op name: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/ShapeN"
op: "ShapeN"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "out_type"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Processing layer 29's swapping, swap out at [30], swap in at [40]
[STR DEBUG] Cannot find swap-out activation nodes for layer 29, among [<tf.Operation 'concatenate_2/concat/axis' type=Const>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>]
[STR DEBUG] Choose op that have outputs: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 29, use the first op name: "zero_padding2d_3/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("concatenate_2/concat:0", shape=(?, 160, 320, 192), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_3/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 40, use the last op name: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Reshape"
input: "training/Adadelta/gradients/gradients/zero_padding2d_3/Pad_grad/Shape"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 30's swapping, swap out at [31], swap in at [39]
[STR DEBUG] Cannot find swap-out activation nodes for layer 30, among [<tf.Operation 'zero_padding2d_3/Pad/paddings' type=Const>, <tf.Operation 'zero_padding2d_3/Pad' type=Pad>]
[STR DEBUG] Choose op that have outputs: name: "zero_padding2d_3/Pad"
op: "Pad"
input: "concatenate_2/concat"
input: "zero_padding2d_3/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 30, use the first op name: "conv2d_3/BiasAdd"
op: "BiasAdd"
input: "conv2d_3/Conv2D"
input: "conv2d_3/BiasAdd/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}

[STR DEBUG] Find swapout ops: name: "zero_padding2d_3/Pad"
op: "Pad"
input: "concatenate_2/concat"
input: "zero_padding2d_3/Pad/paddings"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tpaddings"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("zero_padding2d_3/Pad:0", shape=(?, 162, 322, 192), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 39, use the last op name: "training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropFilter"
op: "Conv2DBackpropFilter"
input: "zero_padding2d_3/Pad"
input: "training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/ShapeN:1"
input: "training/Adadelta/gradients/gradients/AddN_3"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 31's swapping, swap out at [32], swap in at [38]
[STR DEBUG] Cannot find swap-out activation nodes for layer 31, among [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/dilation_rate' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_3/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_3/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_3/bias' type=VarHandleOp>, <tf.Operation 'conv2d_3/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_3/Conv2D"
op: "Conv2D"
input: "zero_padding2d_3/Pad"
input: "conv2d_3/Conv2D/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 31, use the first op name: "batch_normalization_3/cond_1/Const_1"
op: "Const"
input: "^batch_normalization_3/cond_1/switch_f"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
      }
      float_val: 1.0
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_3/Conv2D"
op: "Conv2D"
input: "zero_padding2d_3/Pad"
input: "conv2d_3/Conv2D/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}
, 
	choose swap tensor Tensor("conv2d_3/Conv2D:0", shape=(?, 160, 320, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'batch_normalization_3/cond_1/Const_1' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 38, use the last op name: "training/Adadelta/gradients/gradients/batch_normalization_3/cond/ReadVariableOp_1/Switch_grad/cond_grad"
op: "Merge"
input: "training/Adadelta/gradients/gradients/zeros_5"
input: "training/Adadelta/gradients/gradients/batch_normalization_3/cond/FusedBatchNormV3_grad/FusedBatchNormGradV3:2"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 32's swapping, swap out at [33], swap in at [37]
[STR DEBUG] Cannot find swap-out activation nodes for layer 32, among [<tf.Operation 'batch_normalization_3/cond_1/Const_1' type=Const>, <tf.Operation 'batch_normalization_3/gamma/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_3/gamma' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub_1' type=Sub>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub' type=Sub>, <tf.Operation 'batch_normalization_3/gamma/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub/x' type=Const>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/gamma/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/gamma/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/beta/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub' type=Sub>, <tf.Operation 'batch_normalization_3/beta' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/sub_1' type=Sub>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_2' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/beta/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/Const' type=Const>, <tf.Operation 'batch_normalization_3/beta/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/switch_t' type=Identity>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/mul' type=Mul>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_3' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/beta/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/moving_mean/Initializer/zeros' type=Const>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_3/cond/Const_1' type=Const>, <tf.Operation 'batch_normalization_3/AssignMovingAvg/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/moving_mean' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_2/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/moving_mean/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/sub/x' type=Const>, <tf.Operation 'batch_normalization_3/moving_mean/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/switch_f' type=Identity>, <tf.Operation 'batch_normalization_3/moving_mean/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/moving_variance/Initializer/ones' type=Const>, <tf.Operation 'batch_normalization_3/moving_variance' type=VarHandleOp>, <tf.Operation 'batch_normalization_3/moving_variance/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'batch_normalization_3/cond/pred_id' type=Identity>, <tf.Operation 'batch_normalization_3/moving_variance/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/moving_variance/Assign' type=AssignVariableOp>, <tf.Operation 'batch_normalization_3/cond_1/switch_t' type=Identity>, <tf.Operation 'batch_normalization_3/cond_1/Const' type=Const>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3' type=FusedBatchNormV3>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/mul' type=Mul>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'batch_normalization_3/AssignMovingAvg_1/ReadVariableOp_1' type=ReadVariableOp>, <tf.Operation 'batch_normalization_3/cond/ReadVariableOp_3/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/Merge' type=Merge>, <tf.Operation 'batch_normalization_3/cond/Merge_1' type=Merge>, <tf.Operation 'batch_normalization_3/cond_1/switch_f' type=Identity>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/ReadVariableOp_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/FusedBatchNormV3_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond/Merge_2' type=Merge>, <tf.Operation 'batch_normalization_3/cond_1/Switch' type=Switch>, <tf.Operation 'batch_normalization_3/cond_1/pred_id' type=Identity>]
[STR DEBUG] Choose op that have outputs: name: "batch_normalization_3/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 32, use the first op name: "conv2d_4/kernel/Initializer/random_uniform/shape"
op: "Const"
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_4/kernel"
    }
  }
}
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
      }
      tensor_content: "\003\000\000\000\003\000\000\000@\000\000\0002\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "batch_normalization_3/cond_1/pred_id"
op: "Identity"
input: "keras_learning_phase"
attr {
  key: "T"
  value {
    type: DT_BOOL
  }
}
, 
	choose swap tensor Tensor("batch_normalization_3/cond_1/pred_id:0", shape=(), dtype=bool), 
	finish at the end of ops: [<tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/shape' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 37, use the last op name: "training/Adadelta/gradients/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropFilter"
op: "Conv2DBackpropFilter"
input: "batch_normalization_3/cond/Merge"
input: "training/Adadelta/gradients/gradients/conv2d_4/Conv2D_grad/ShapeN:1"
input: "training/Adadelta/gradients/gradients/reshape/Reshape_grad/Reshape"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "SAME"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}

[STR DEBUG] Processing layer 33's swapping, swap out at [34], swap in at [36]
[STR DEBUG] Cannot find swap-out activation nodes for layer 33, among [<tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_4/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_4/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/dilation_rate' type=Const>, <tf.Operation 'conv2d_4/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_4/bias' type=VarHandleOp>, <tf.Operation 'conv2d_4/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/Conv2D/ReadVariableOp' type=ReadVariableOp>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 33, use the first op name: "reshape/Reshape/shape"
op: "Pack"
input: "reshape/strided_slice"
input: "reshape/Reshape/shape/1"
input: "reshape/Reshape/shape/2"
attr {
  key: "N"
  value {
    i: 3
  }
}
attr {
  key: "T"
  value {
    type: DT_INT32
  }
}
attr {
  key: "axis"
  value {
    i: 0
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("conv2d_4/Conv2D/ReadVariableOp:0", shape=(3, 3, 64, 50), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'reshape/Reshape/shape' type=Pack>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 36, use the last op name: "training/Adadelta/gradients/gradients/reshape/Reshape_grad/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/gradients/AddN_2"
input: "training/Adadelta/gradients/gradients/reshape/Reshape_grad/Shape"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/reshape/Reshape_grad/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/gradients/AddN_2"
input: "training/Adadelta/gradients/gradients/reshape/Reshape_grad/Shape"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>]
[STR DEBUG] Processing layer 42's swapping, swap out at [43], swap in at [67]
[STR DEBUG] Cannot find swap-out activation nodes for layer 42, among [<tf.Operation 'training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size' type=Const>, <tf.Operation 'training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad' type=ResizeNearestNeighborGrad>]
[STR DEBUG] Choose op that have outputs: name: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 42, use the first op name: "training/Adadelta/gradients/gradients/batch_normalization_2/cond/ReadVariableOp_1/Switch_grad/cond_grad"
op: "Merge"
input: "training/Adadelta/gradients/gradients/zeros_11"
input: "training/Adadelta/gradients/gradients/batch_normalization_2/cond/FusedBatchNormV3_grad/FusedBatchNormGradV3:2"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Find swapout ops: name: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_2/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}
, 
	choose swap tensor Tensor("training/Adadelta/gradients/gradients/up_sampling2d_2/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad:0", shape=(?, 80, 160, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'training/Adadelta/gradients/gradients/batch_normalization_2/cond/ReadVariableOp_1/Switch_grad/cond_grad' type=Merge>]
[STR DEBUG] Processing layer 47's swapping, swap out at [48], swap in at [59]
[STR DEBUG] Cannot find swap-out activation nodes for layer 47, among [<tf.Operation 'training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size' type=Const>, <tf.Operation 'training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad' type=ResizeNearestNeighborGrad>]
[STR DEBUG] Choose op that have outputs: name: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_1/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 47, use the first op name: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/FusedBatchNormV3_grad/FusedBatchNormGradV3"
op: "FusedBatchNormGradV3"
input: "training/Adadelta/gradients/gradients/batch_normalization_1/cond/Merge_grad/cond_grad:1"
input: "batch_normalization_1/cond/FusedBatchNormV3/Switch:1"
input: "batch_normalization_1/cond/ReadVariableOp"
input: "batch_normalization_1/cond/FusedBatchNormV3:3"
input: "batch_normalization_1/cond/FusedBatchNormV3:4"
input: "batch_normalization_1/cond/FusedBatchNormV3:5"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "U"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "epsilon"
  value {
    f: 0.0010000000474974513
  }
}
attr {
  key: "is_training"
  value {
    b: true
  }
}
2022-01-07 22:16:23.821523: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:23.821617: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:24.164420: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:24.164489: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:24.341259: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:24.341308: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-01-07 22:16:34.341890: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.87GiB (rounded to 2003097600).  Current allocation summary follows.
2022-01-07 22:16:34.342910: W tensorflow/core/common_runtime/bfc_allocator.cc:424] *********____***_______**************************************************************************x_*
2022-01-07 22:16:34.342976: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_grad_input_ops.cc:1063 : Resource exhausted: OOM when allocating tensor with shape[50,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc

[STR DEBUG] Find swapout ops: name: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad"
op: "ResizeNearestNeighborGrad"
input: "training/Adadelta/gradients/gradients/concatenate_1/concat_grad/Slice"
input: "training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad/size"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}
, 
	choose swap tensor Tensor("training/Adadelta/gradients/gradients/up_sampling2d_1/resize/ResizeNearestNeighbor_grad/ResizeNearestNeighborGrad:0", shape=(?, 40, 80, 256), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'training/Adadelta/gradients/gradients/batch_normalization_1/cond/FusedBatchNormV3_grad/FusedBatchNormGradV3' type=FusedBatchNormGradV3>]
Traceback (most recent call last):
  File "../run_training.py", line 68, in <module>
    epochs=1)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/keras_segmentation-0.2.0remat-py3.6.egg/keras_segmentation/train.py", line 106, in train
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 1301, in fit_generator
    steps_name='steps_per_epoch')
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 1021, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3476, in __call__
    run_metadata=self.run_metadata)
  File "/home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1472, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted: OOM when allocating tensor with shape[50,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[training/Adadelta/gradients/gradients/block1_conv1/Relu_grad/ReluGrad/_444]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: OOM when allocating tensor with shape[50,192,162,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training/Adadelta/gradients/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.
