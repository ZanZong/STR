WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 35), ('epochs', 1), ('model_name', 'vgg_unet'), ('strategy', 'capuchin'), ('verbose', False)]
Cannot find config for batch_size=35, use 40 instead
There are 367 and 367 images downloaded for train and test
Verifying train dataset
  0%|          | 0/367 [00:00<?, ?it/s]  4%|▎         | 13/367 [00:00<00:02, 125.68it/s]  7%|▋         | 26/367 [00:00<00:02, 126.66it/s] 11%|█         | 39/367 [00:00<00:02, 127.89it/s] 14%|█▍        | 53/367 [00:00<00:02, 129.90it/s] 18%|█▊        | 66/367 [00:00<00:02, 129.02it/s] 23%|██▎       | 83/367 [00:00<00:02, 141.70it/s] 28%|██▊       | 101/367 [00:00<00:01, 152.17it/s] 32%|███▏      | 119/367 [00:00<00:01, 158.31it/s] 37%|███▋      | 137/367 [00:00<00:01, 161.99it/s] 42%|████▏     | 154/367 [00:01<00:01, 163.91it/s] 47%|████▋     | 172/367 [00:01<00:01, 165.99it/s] 52%|█████▏    | 190/367 [00:01<00:01, 168.78it/s] 56%|█████▋    | 207/367 [00:01<00:00, 169.07it/s] 61%|██████▏   | 225/367 [00:01<00:00, 169.59it/s] 66%|██████▌   | 243/367 [00:01<00:00, 170.20it/s] 71%|███████   | 261/367 [00:01<00:00, 171.99it/s] 76%|███████▌  | 279/367 [00:01<00:00, 171.78it/s] 81%|████████  | 297/367 [00:01<00:00, 172.71it/s] 86%|████████▌ | 315/367 [00:01<00:00, 172.73it/s] 91%|█████████ | 333/367 [00:02<00:00, 172.54it/s] 96%|█████████▌| 351/367 [00:02<00:00, 171.45it/s]100%|██████████| 367/367 [00:02<00:00, 161.69it/s]
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/str_strategy.py:122: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:928: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

Dataset verified! 
Starting Epoch  0
[STR DEBUG] Parsing STR configuration: [{'strategy': 'hybrid', 'verbose': 'false', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/layer_names'}, {'r': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/R-capuchin', 'p': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/P-capuchin', 'q': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/Q-capuchin'}]
[STR DEBUG] Processing layer 28's swapping, swap out at [30], swap in at [41]
[STR DEBUG] Cannot find swap-out activation nodes for layer 28, among [<tf.Operation 'up_sampling2d_2/Const' type=Const>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_2' type=Const>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>, <tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>]
[STR DEBUG] Choose op that have outputs: name: "up_sampling2d_2/strided_slice"
op: "StridedSlice"
input: "up_sampling2d_2/Shape"
input: "up_sampling2d_2/strided_slice/stack"
input: "up_sampling2d_2/strided_slice/stack_1"
input: "up_sampling2d_2/strided_slice/stack_2"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_INT32
  }
}
attr {
  key: "begin_mask"
  value {
    i: 0
  }
}
attr {
  key: "ellipsis_mask"
  value {
    i: 0
  }
}
attr {
  key: "end_mask"
  value {
    i: 0
  }
}
attr {
  key: "new_axis_mask"
  value {
    i: 0
  }
}
attr {
  key: "shrink_axis_mask"
  value {
    i: 0
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 28, use the first op name: "zero_padding2d_3/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "up_sampling2d_2/strided_slice"
op: "StridedSlice"
input: "up_sampling2d_2/Shape"
input: "up_sampling2d_2/strided_slice/stack"
input: "up_sampling2d_2/strided_slice/stack_1"
input: "up_sampling2d_2/strided_slice/stack_2"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_INT32
  }
}
attr {
  key: "begin_mask"
  value {
    i: 0
  }
}
attr {
  key: "ellipsis_mask"
  value {
    i: 0
  }
}
attr {
  key: "end_mask"
  value {
    i: 0
  }
}
attr {
  key: "new_axis_mask"
  value {
    i: 0
  }
}
attr {
  key: "shrink_axis_mask"
  value {
    i: 0
  }
}
, 
	choose swap tensor Tensor("up_sampling2d_2/strided_slice:0", shape=(2,), dtype=int32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_3/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 41, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/ConcatOffset"
op: "ConcatOffset"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/mod"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/ShapeN"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/ShapeN:1"
attr {
  key: "N"
  value {
    i: 2
  }
}

[STR DEBUG] Processing layer 29's swapping, swap out at [31], swap in at [40]
[STR DEBUG] Cannot find swap-out activation nodes for layer 29, among [<tf.Operation 'concatenate_2/concat/axis' type=Const>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>]
[STR DEBUG] Choose op that have outputs: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 29, use the first op name: "conv2d_3/dilation_rate"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 2
        }
      }
      tensor_content: "\001\000\000\000\001\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("concatenate_2/concat:0", shape=(?, 160, 320, 192), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_3/dilation_rate' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 40, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Reshape"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Shape"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 31's swapping, swap out at [34], swap in at [38]
[STR DEBUG] Cannot find swap-out activation nodes for layer 31, among [<tf.Operation 'conv2d_3/dilation_rate' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_3/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_3/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_3/bias' type=VarHandleOp>, <tf.Operation 'conv2d_3/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/Conv2D/ReadVariableOp' type=ReadVariableOp>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_3/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_3/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 31, use the first op name: "reshape/strided_slice/stack"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 0
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_3/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_3/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("conv2d_3/Conv2D/ReadVariableOp:0", shape=(3, 3, 192, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'reshape/strided_slice/stack' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 38, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Merge"
op: "Merge"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Switch"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Switch_1:1"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Merge"
op: "Merge"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Switch"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch_grad/Switch_1:1"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>]
[STR DEBUG] Processing layer 33's swapping, swap out at [35], swap in at [36]
[STR DEBUG] Cannot find swap-out activation nodes for layer 33, among [<tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_4/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_4/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_4/bias' type=VarHandleOp>, <tf.Operation 'conv2d_4/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/dilation_rate' type=Const>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_4/dilation_rate"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 2
        }
      }
      tensor_content: "\001\000\000\000\001\000\000\000"
    }
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 33, use the first op name: "activation/Max"
op: "Max"
input: "reshape/Reshape"
input: "activation/Max/reduction_indices"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
attr {
  key: "keep_dims"
  value {
    b: true
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_4/dilation_rate"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 2
        }
      }
      tensor_content: "\001\000\000\000\001\000\000\000"
    }
  }
}
, 
	choose swap tensor Tensor("conv2d_4/dilation_rate:0", shape=(2,), dtype=int32), 
	finish at the end of ops: [<tf.Operation 'activation/Max' type=Max>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 36, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/reshape/Reshape_grad/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/gradients/AddN_2"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/reshape/Reshape_grad/Shape"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}

 1/64 [..............................] - ETA: 23:11 - loss: 4.4757 - acc: 0.0096 2/64 [..............................] - ETA: 12:46 - loss: 4.4517 - acc: 0.0102 3/64 [>.............................] - ETA: 9:15 - loss: 4.4454 - acc: 0.0105  4/64 [>.............................] - ETA: 7:28 - loss: 4.4402 - acc: 0.0107 5/64 [=>............................] - ETA: 6:22 - loss: 4.4407 - acc: 0.0105 6/64 [=>............................] - ETA: 5:38 - loss: 4.4432 - acc: 0.0106 7/64 [==>...........................] - ETA: 5:05 - loss: 4.4486 - acc: 0.0104 8/64 [==>...........................] - ETA: 4:40 - loss: 4.4507 - acc: 0.0104 9/64 [===>..........................] - ETA: 4:20 - loss: 4.4468 - acc: 0.010410/64 [===>..........................] - ETA: 4:03 - loss: 4.4424 - acc: 0.010411/64 [====>.........................] - ETA: 3:51 - loss: 4.4442 - acc: 0.010412/64 [====>.........................] - ETA: 3:39 - loss: 4.4422 - acc: 0.010413/64 [=====>........................] - ETA: 3:28 - loss: 4.4398 - acc: 0.010514/64 [=====>........................] - ETA: 3:18 - loss: 4.4365 - acc: 0.010615/64 [======>.......................] - ETA: 3:09 - loss: 4.4357 - acc: 0.010616/64 [======>.......................] - ETA: 3:04 - loss: 4.4353 - acc: 0.010617/64 [======>.......................] - ETA: 2:57 - loss: 4.4359 - acc: 0.010618/64 [=======>......................] - ETA: 2:50 - loss: 4.4378 - acc: 0.010619/64 [=======>......................] - ETA: 2:44 - loss: 4.4377 - acc: 0.010620/64 [========>.....................] - ETA: 2:38 - loss: 4.4342 - acc: 0.010621/64 [========>.....................] - ETA: 2:33 - loss: 4.4332 - acc: 0.010622/64 [=========>....................] - ETA: 2:28 - loss: 4.4336 - acc: 0.010623/64 [=========>....................] - ETA: 2:23 - loss: 4.4314 - acc: 0.010624/64 [==========>...................] - ETA: 2:19 - loss: 4.4298 - acc: 0.010725/64 [==========>...................] - ETA: 2:14 - loss: 4.4282 - acc: 0.010726/64 [===========>..................] - ETA: 2:09 - loss: 4.4274 - acc: 0.010727/64 [===========>..................] - ETA: 2:04 - loss: 4.4271 - acc: 0.010828/64 [============>.................] - ETA: 2:00 - loss: 4.4278 - acc: 0.010729/64 [============>.................] - ETA: 1:56 - loss: 4.4275 - acc: 0.010730/64 [=============>................] - ETA: 1:52 - loss: 4.4258 - acc: 0.010731/64 [=============>................] - ETA: 1:48 - loss: 4.4239 - acc: 0.010832/64 [==============>...............] - ETA: 1:44 - loss: 4.4239 - acc: 0.010833/64 [==============>...............] - ETA: 1:40 - loss: 4.4228 - acc: 0.010834/64 [==============>...............] - ETA: 1:36 - loss: 4.4212 - acc: 0.010835/64 [===============>..............] - ETA: 1:33 - loss: 4.4195 - acc: 0.010936/64 [===============>..............] - ETA: 1:29 - loss: 4.4185 - acc: 0.010937/64 [================>.............] - ETA: 1:25 - loss: 4.4178 - acc: 0.010938/64 [================>.............] - ETA: 1:22 - loss: 4.4176 - acc: 0.010939/64 [=================>............] - ETA: 1:18 - loss: 4.4181 - acc: 0.010940/64 [=================>............] - ETA: 1:15 - loss: 4.4173 - acc: 0.010941/64 [==================>...........] - ETA: 1:12 - loss: 4.4151 - acc: 0.010942/64 [==================>...........] - ETA: 1:08 - loss: 4.4143 - acc: 0.010943/64 [===================>..........] - ETA: 1:05 - loss: 4.4141 - acc: 0.010944/64 [===================>..........] - ETA: 1:02 - loss: 4.4125 - acc: 0.011045/64 [====================>.........] - ETA: 58s - loss: 4.4111 - acc: 0.0110 46/64 [====================>.........] - ETA: 55s - loss: 4.4099 - acc: 0.011047/64 [=====================>........] - ETA: 52s - loss: 4.4088 - acc: 0.011048/64 [=====================>........] - ETA: 48s - loss: 4.4084 - acc: 0.011149/64 [=====================>........] - ETA: 45s - loss: 4.4083 - acc: 0.011150/64 [======================>.......] - ETA: 42s - loss: 4.4076 - acc: 0.011151/64 [======================>.......] - ETA: 39s - loss: 4.4065 - acc: 0.011152/64 [=======================>......] - ETA: 36s - loss: 4.4049 - acc: 0.011153/64 [=======================>......] - ETA: 33s - loss: 4.4046 - acc: 0.011154/64 [========================>.....] - ETA: 30s - loss: 4.4034 - acc: 0.011155/64 [========================>.....] - ETA: 27s - loss: 4.4022 - acc: 0.011256/64 [=========================>....] - ETA: 24s - loss: 4.4009 - acc: 0.011257/64 [=========================>....] - ETA: 21s - loss: 4.3998 - acc: 0.011258/64 [==========================>...] - ETA: 17s - loss: 4.3988 - acc: 0.011259/64 [==========================>...] - ETA: 14s - loss: 4.3986 - acc: 0.011260/64 [===========================>..] - ETA: 11s - loss: 4.3986 - acc: 0.011261/64 [===========================>..] - ETA: 8s - loss: 4.3977 - acc: 0.0112 62/64 [============================>.] - ETA: 5s - loss: 4.3960 - acc: 0.011363/64 [============================>.] - ETA: 2s - loss: 4.3951 - acc: 0.011364/64 [==============================] - 191s 3s/step - loss: 4.3945 - acc: 0.0113
Finished Epoch 0
