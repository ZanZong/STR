WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 30), ('epochs', 1), ('model_name', 'vgg_unet'), ('strategy', 'capuchin'), ('verbose', False)]
Cannot find config for batch_size=30, use 40 instead
There are 367 and 367 images downloaded for train and test
Verifying train dataset
  0%|          | 0/367 [00:00<?, ?it/s]  4%|▎         | 13/367 [00:00<00:02, 124.39it/s]  7%|▋         | 26/367 [00:00<00:02, 126.18it/s] 11%|█         | 39/367 [00:00<00:02, 127.37it/s] 14%|█▍        | 53/367 [00:00<00:02, 130.50it/s] 19%|█▉        | 71/367 [00:00<00:02, 145.45it/s] 24%|██▍       | 89/367 [00:00<00:01, 155.37it/s] 29%|██▉       | 107/367 [00:00<00:01, 162.23it/s] 34%|███▍      | 124/367 [00:00<00:01, 163.98it/s] 38%|███▊      | 141/367 [00:00<00:01, 165.51it/s] 43%|████▎     | 159/367 [00:01<00:01, 168.90it/s] 48%|████▊     | 177/367 [00:01<00:01, 170.37it/s] 53%|█████▎    | 195/367 [00:01<00:01, 171.54it/s] 58%|█████▊    | 213/367 [00:01<00:00, 171.56it/s] 63%|██████▎   | 231/367 [00:01<00:00, 171.71it/s] 68%|██████▊   | 249/367 [00:01<00:00, 172.07it/s] 73%|███████▎  | 267/367 [00:01<00:00, 173.33it/s] 78%|███████▊  | 285/367 [00:01<00:00, 173.31it/s] 83%|████████▎ | 303/367 [00:01<00:00, 173.09it/s] 87%|████████▋ | 321/367 [00:01<00:00, 173.00it/s] 92%|█████████▏| 339/367 [00:02<00:00, 173.09it/s] 97%|█████████▋| 357/367 [00:02<00:00, 172.54it/s]100%|██████████| 367/367 [00:02<00:00, 164.75it/s]
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/str_strategy.py:122: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:928: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

Dataset verified! 
Starting Epoch  0
[STR DEBUG] Parsing STR configuration: [{'strategy': 'hybrid', 'verbose': 'false', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/layer_names'}, {'r': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/R-capuchin', 'p': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/P-capuchin', 'q': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/vgg_unet_40/Q-capuchin'}]
[STR DEBUG] Processing layer 28's swapping, swap out at [30], swap in at [41]
[STR DEBUG] Cannot find swap-out activation nodes for layer 28, among [<tf.Operation 'up_sampling2d_2/strided_slice' type=StridedSlice>, <tf.Operation 'up_sampling2d_2/Const' type=Const>, <tf.Operation 'up_sampling2d_2/Shape' type=Shape>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_1' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack' type=Const>, <tf.Operation 'up_sampling2d_2/strided_slice/stack_2' type=Const>, <tf.Operation 'up_sampling2d_2/mul' type=Mul>, <tf.Operation 'up_sampling2d_2/resize/ResizeNearestNeighbor' type=ResizeNearestNeighbor>]
[STR DEBUG] Choose op that have outputs: name: "up_sampling2d_2/resize/ResizeNearestNeighbor"
op: "ResizeNearestNeighbor"
input: "batch_normalization_2/cond/Merge"
input: "up_sampling2d_2/mul"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 28, use the first op name: "zero_padding2d_3/Pad/paddings"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 4
        }
        dim {
          size: 2
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\001\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

[STR DEBUG] Find swapout ops: name: "up_sampling2d_2/resize/ResizeNearestNeighbor"
op: "ResizeNearestNeighbor"
input: "batch_normalization_2/cond/Merge"
input: "up_sampling2d_2/mul"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "align_corners"
  value {
    b: false
  }
}
attr {
  key: "half_pixel_centers"
  value {
    b: true
  }
}
, 
	choose swap tensor Tensor("up_sampling2d_2/resize/ResizeNearestNeighbor:0", shape=(?, 160, 320, 128), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'zero_padding2d_3/Pad/paddings' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 41, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Slice_1"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/ConcatOffset:1"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/concatenate_2/concat_grad/ShapeN:1"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 29's swapping, swap out at [31], swap in at [40]
[STR DEBUG] Cannot find swap-out activation nodes for layer 29, among [<tf.Operation 'concatenate_2/concat/axis' type=Const>, <tf.Operation 'concatenate_2/concat' type=ConcatV2>]
[STR DEBUG] Choose op that have outputs: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 29, use the first op name: "conv2d_3/BiasAdd"
op: "BiasAdd"
input: "conv2d_3/Conv2D"
input: "conv2d_3/BiasAdd/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}

[STR DEBUG] Find swapout ops: name: "concatenate_2/concat"
op: "ConcatV2"
input: "up_sampling2d_2/resize/ResizeNearestNeighbor"
input: "block1_pool/MaxPool"
input: "concatenate_2/concat/axis"
attr {
  key: "N"
  value {
    i: 2
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
, 
	choose swap tensor Tensor("concatenate_2/concat:0", shape=(?, 160, 320, 192), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 40, use the last op name: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Slice_1"
op: "Slice"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_3/Conv2D_grad/Conv2DBackpropInput"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Reshape"
input: "training/Adadelta/gradients/gradients/training/Adadelta/gradients/zero_padding2d_3/Pad_grad/Shape"
attr {
  key: "Index"
  value {
    type: DT_INT32
  }
}
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Processing layer 31's swapping, swap out at [34], swap in at [38]
[STR DEBUG] Cannot find swap-out activation nodes for layer 31, among [<tf.Operation 'conv2d_3/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_3/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/Conv2D/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/dilation_rate' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_3/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_3/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_3/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_3/bias' type=VarHandleOp>, <tf.Operation 'conv2d_3/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_3/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_3/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_3/Conv2D' type=Conv2D>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_3/Conv2D"
op: "Conv2D"
input: "zero_padding2d_3/Pad"
input: "conv2d_3/Conv2D/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 31, use the first op name: "reshape/strided_slice/stack"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_INT32
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_INT32
      tensor_shape {
        dim {
          size: 1
        }
      }
      int_val: 0
    }
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_3/Conv2D"
op: "Conv2D"
input: "zero_padding2d_3/Pad"
input: "conv2d_3/Conv2D/ReadVariableOp"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "data_format"
  value {
    s: "NHWC"
  }
}
attr {
  key: "dilations"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "explicit_paddings"
  value {
    list {
    }
  }
}
attr {
  key: "padding"
  value {
    s: "VALID"
  }
}
attr {
  key: "strides"
  value {
    list {
      i: 1
      i: 1
      i: 1
      i: 1
    }
  }
}
attr {
  key: "use_cudnn_on_gpu"
  value {
    b: true
  }
}
, 
	choose swap tensor Tensor("conv2d_3/Conv2D:0", shape=(?, 160, 320, 64), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'reshape/strided_slice/stack' type=Const>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 38, use the last op name: "training/Adadelta/gradients/batch_normalization_3/cond/FusedBatchNormV3/Switch"
op: "Switch"
input: "training/Adadelta/gradients/conv2d_3/BiasAdd"
input: "batch_normalization_3/cond/pred_id"
input: "^loss/mul"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@conv2d_3/BiasAdd"
    }
  }
}

[STR DEBUG] Processing layer 33's swapping, swap out at [35], swap in at [36]
[STR DEBUG] Cannot find swap-out activation nodes for layer 33, among [<tf.Operation 'conv2d_4/dilation_rate' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'conv2d_4/kernel' type=VarHandleOp>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'conv2d_4/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'conv2d_4/kernel/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/kernel/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/kernel/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/bias/Initializer/zeros' type=Const>, <tf.Operation 'conv2d_4/bias' type=VarHandleOp>, <tf.Operation 'conv2d_4/bias/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>, <tf.Operation 'conv2d_4/bias/Read/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/bias/Assign' type=AssignVariableOp>, <tf.Operation 'conv2d_4/Conv2D' type=Conv2D>, <tf.Operation 'conv2d_4/BiasAdd' type=BiasAdd>, <tf.Operation 'conv2d_4/BiasAdd/ReadVariableOp' type=ReadVariableOp>, <tf.Operation 'conv2d_4/Conv2D/ReadVariableOp' type=ReadVariableOp>]
[STR DEBUG] Choose op that have outputs: name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}

[STR DEBUG] Cannot find swap-out control nodes for layer 33, use the first op name: "activation/Max"
op: "Max"
input: "reshape/Reshape"
input: "activation/Max/reduction_indices"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tidx"
  value {
    type: DT_INT32
  }
}
attr {
  key: "keep_dims"
  value {
    b: true
  }
}

[STR DEBUG] Find swapout ops: name: "conv2d_4/Conv2D/ReadVariableOp"
op: "ReadVariableOp"
input: "conv2d_4/kernel"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
, 
	choose swap tensor Tensor("conv2d_4/Conv2D/ReadVariableOp:0", shape=(3, 3, 64, 50), dtype=float32), 
	finish at the end of ops: [<tf.Operation 'activation/Max' type=Max>]
[STR DEBUG] Cannot find swap-in control nodes for ref. layer 36, use the last op name: "training/Adadelta/gradients/reshape/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/conv2d_4/BiasAdd"
input: "training/Adadelta/gradients/reshape/Reshape/shape"
input: "^loss/mul"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}

[STR DEBUG] Add swap-in op at name: "training/Adadelta/gradients/reshape/Reshape"
op: "Reshape"
input: "training/Adadelta/gradients/conv2d_4/BiasAdd"
input: "training/Adadelta/gradients/reshape/Reshape/shape"
input: "^loss/mul"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "Tshape"
  value {
    type: DT_INT32
  }
}
 for consumer [<tf.Operation 'training/Adadelta/gradients/gradients/training/Adadelta/gradients/conv2d_4/Conv2D_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>]
 1/64 [..............................] - ETA: 21:20 - loss: 4.5471 - acc: 0.0111 2/64 [..............................] - ETA: 11:59 - loss: 4.5481 - acc: 0.0128 3/64 [>.............................] - ETA: 8:36 - loss: 4.5506 - acc: 0.0129  4/64 [>.............................] - ETA: 7:08 - loss: 4.5549 - acc: 0.0127 5/64 [=>............................] - ETA: 6:13 - loss: 4.5535 - acc: 0.0125 6/64 [=>............................] - ETA: 5:35 - loss: 4.5483 - acc: 0.0125 7/64 [==>...........................] - ETA: 5:06 - loss: 4.5479 - acc: 0.0121 8/64 [==>...........................] - ETA: 4:44 - loss: 4.5452 - acc: 0.0122 9/64 [===>..........................] - ETA: 4:23 - loss: 4.5384 - acc: 0.012310/64 [===>..........................] - ETA: 4:04 - loss: 4.5374 - acc: 0.012211/64 [====>.........................] - ETA: 3:48 - loss: 4.5380 - acc: 0.012412/64 [====>.........................] - ETA: 3:36 - loss: 4.5378 - acc: 0.012313/64 [=====>........................] - ETA: 3:24 - loss: 4.5365 - acc: 0.012314/64 [=====>........................] - ETA: 3:14 - loss: 4.5354 - acc: 0.012415/64 [======>.......................] - ETA: 3:05 - loss: 4.5366 - acc: 0.012516/64 [======>.......................] - ETA: 2:56 - loss: 4.5364 - acc: 0.012517/64 [======>.......................] - ETA: 2:51 - loss: 4.5359 - acc: 0.012518/64 [=======>......................] - ETA: 2:44 - loss: 4.5348 - acc: 0.012519/64 [=======>......................] - ETA: 2:39 - loss: 4.5341 - acc: 0.012420/64 [========>.....................] - ETA: 2:32 - loss: 4.5320 - acc: 0.012421/64 [========>.....................] - ETA: 2:27 - loss: 4.5298 - acc: 0.012422/64 [=========>....................] - ETA: 2:23 - loss: 4.5283 - acc: 0.012423/64 [=========>....................] - ETA: 2:17 - loss: 4.5276 - acc: 0.012524/64 [==========>...................] - ETA: 2:12 - loss: 4.5274 - acc: 0.012525/64 [==========>...................] - ETA: 2:07 - loss: 4.5257 - acc: 0.012526/64 [===========>..................] - ETA: 2:02 - loss: 4.5254 - acc: 0.012527/64 [===========>..................] - ETA: 1:58 - loss: 4.5249 - acc: 0.012628/64 [============>.................] - ETA: 1:54 - loss: 4.5248 - acc: 0.012629/64 [============>.................] - ETA: 1:49 - loss: 4.5240 - acc: 0.012630/64 [=============>................] - ETA: 1:45 - loss: 4.5234 - acc: 0.012631/64 [=============>................] - ETA: 1:41 - loss: 4.5223 - acc: 0.012632/64 [==============>...............] - ETA: 1:37 - loss: 4.5212 - acc: 0.012533/64 [==============>...............] - ETA: 1:34 - loss: 4.5192 - acc: 0.012634/64 [==============>...............] - ETA: 1:30 - loss: 4.5183 - acc: 0.012535/64 [===============>..............] - ETA: 1:27 - loss: 4.5171 - acc: 0.012636/64 [===============>..............] - ETA: 1:23 - loss: 4.5166 - acc: 0.012637/64 [================>.............] - ETA: 1:20 - loss: 4.5157 - acc: 0.012638/64 [================>.............] - ETA: 1:17 - loss: 4.5148 - acc: 0.012639/64 [=================>............] - ETA: 1:13 - loss: 4.5142 - acc: 0.012740/64 [=================>............] - ETA: 1:10 - loss: 4.5138 - acc: 0.012741/64 [==================>...........] - ETA: 1:07 - loss: 4.5130 - acc: 0.012742/64 [==================>...........] - ETA: 1:03 - loss: 4.5123 - acc: 0.012743/64 [===================>..........] - ETA: 1:00 - loss: 4.5114 - acc: 0.012744/64 [===================>..........] - ETA: 57s - loss: 4.5103 - acc: 0.0127 45/64 [====================>.........] - ETA: 54s - loss: 4.5089 - acc: 0.012746/64 [====================>.........] - ETA: 51s - loss: 4.5075 - acc: 0.012747/64 [=====================>........] - ETA: 48s - loss: 4.5063 - acc: 0.012848/64 [=====================>........] - ETA: 45s - loss: 4.5059 - acc: 0.012849/64 [=====================>........] - ETA: 42s - loss: 4.5050 - acc: 0.012850/64 [======================>.......] - ETA: 39s - loss: 4.5041 - acc: 0.012851/64 [======================>.......] - ETA: 36s - loss: 4.5033 - acc: 0.012852/64 [=======================>......] - ETA: 33s - loss: 4.5027 - acc: 0.012953/64 [=======================>......] - ETA: 30s - loss: 4.5023 - acc: 0.012954/64 [========================>.....] - ETA: 27s - loss: 4.5015 - acc: 0.012955/64 [========================>.....] - ETA: 25s - loss: 4.5003 - acc: 0.012956/64 [=========================>....] - ETA: 22s - loss: 4.4995 - acc: 0.012957/64 [=========================>....] - ETA: 19s - loss: 4.4984 - acc: 0.012958/64 [==========================>...] - ETA: 16s - loss: 4.4969 - acc: 0.012959/64 [==========================>...] - ETA: 13s - loss: 4.4958 - acc: 0.012960/64 [===========================>..] - ETA: 11s - loss: 4.4953 - acc: 0.012961/64 [===========================>..] - ETA: 8s - loss: 4.4944 - acc: 0.0129 62/64 [============================>.] - ETA: 5s - loss: 4.4934 - acc: 0.012963/64 [============================>.] - ETA: 2s - loss: 4.4925 - acc: 0.013064/64 [==============================] - 174s 3s/step - loss: 4.4920 - acc: 0.0130
Finished Epoch 0
