WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/lms.py:970: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/zongzan/.conda/envs/STR36/lib/python3.6/site-packages/tensorflow_core/python/ops/stropt/memory_saving_gradients.py:78: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.
Instructions for updating:
Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.
1 Physical GPUs, 1 Logical GPUs
Parsing arguments: [('batch_size', 250), ('epochs', 1), ('model_name', 'VGG16'), ('strategy', 'chen-heurist'), ('verbose', False)]
Shape of x_train: (40000, 224, 224, 3), shape of x_test: (10000, 224, 224, 3)
[STR DEBUG] Parsing STR configuration: [{'strategy': 'recompute', 'verbose': 'false', 'tags': '/home/zongzan/dist_dnn_training/STR/optimizer/logs/VGG16_250/layer_names'}, {}]
DEBUG bwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Reshape/shape/1', 'flatten/Shape', 'flatten/strided_slice', 'flatten/strided_slice/stack', 'flatten/strided_slice/stack_1', 'flatten/strided_slice/stack_2', 'input_1', 'loss/mul', 'loss/mul/x', 'loss/predictions_loss/Const_1', 'loss/predictions_loss/Const_2', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Rank_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_1/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/begin', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2/size', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_1/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Sub_2/y', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat/values_0', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/axis', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat_1/values_0', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Cast/x', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Const', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel', 'predictions_target']
DEBUG fwd_ops: ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv1/bias', 'block1_conv1/kernel', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_conv2/bias', 'block1_conv2/kernel', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv1/bias', 'block2_conv1/kernel', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_conv2/bias', 'block2_conv2/kernel', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv1/bias', 'block3_conv1/kernel', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv2/bias', 'block3_conv2/kernel', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_conv3/bias', 'block3_conv3/kernel', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv1/bias', 'block4_conv1/kernel', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv2/bias', 'block4_conv2/kernel', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_conv3/bias', 'block4_conv3/kernel', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv1/bias', 'block5_conv1/kernel', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv2/bias', 'block5_conv2/kernel', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_conv3/bias', 'block5_conv3/kernel', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc1/bias', 'fc1/kernel', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'fc2/bias', 'fc2/kernel', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp', 'predictions/bias', 'predictions/kernel']
DEBUG bwd_ops after call the gradient function: ['training/RMSprop/gradients/1641632389601667/gradients/Fill', 'training/RMSprop/gradients/1641632389601667/gradients/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block1_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block2_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block2_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block3_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block3_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block4_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block4_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv1/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv2/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv3/Conv2D_grad/ShapeN', 'training/RMSprop/gradients/1641632389601667/gradients/block5_conv3/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/block5_pool/MaxPool_grad/MaxPoolGrad', 'training/RMSprop/gradients/1641632389601667/gradients/fc1/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/fc1/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641632389601667/gradients/fc1/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641632389601667/gradients/fc1/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/fc2/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/fc2/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641632389601667/gradients/fc2/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641632389601667/gradients/fc2/Relu_grad/ReluGrad', 'training/RMSprop/gradients/1641632389601667/gradients/flatten/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/flatten/Reshape_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/grad_ys_0', 'training/RMSprop/gradients/1641632389601667/gradients/loss/mul_grad/Mul', 'training/RMSprop/gradients/1641632389601667/gradients/loss/mul_grad/Mul_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_1_grad/Const', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_1_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_1_grad/Reshape/shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_1_grad/Tile', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_grad/Reshape/shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/Sum_grad/Tile', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims/dim', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/LogSoftmax', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/Neg', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits_grad/mul_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Neg', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Reshape_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Shape_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Sum', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/Sum_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/div_no_nan', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/div_no_nan_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/div_no_nan_2', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/value_grad/mul', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/BroadcastGradientArgs', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Mul_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Reshape_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Shape_1', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum', 'training/RMSprop/gradients/1641632389601667/gradients/loss/predictions_loss/weighted_loss/Mul_grad/Sum_1', 'training/RMSprop/gradients/1641632389601667/gradients/predictions/BiasAdd_grad/BiasAddGrad', 'training/RMSprop/gradients/1641632389601667/gradients/predictions/MatMul_grad/MatMul', 'training/RMSprop/gradients/1641632389601667/gradients/predictions/MatMul_grad/MatMul_1', 'training/RMSprop/gradients/1641632389601667/gradients/zeros_like']
DEBUG Using tensors ['block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Relu:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Relu:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Relu:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Relu:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Relu:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Relu:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Relu:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Relu:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/Relu:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'flatten/Reshape:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/MatMul/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc2/MatMul/ReadVariableOp:0', 'flatten/Reshape:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv1/Relu:0', 'block2_conv2/BiasAdd:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'block2_conv2/Conv2D:0', 'block2_conv2/Relu:0', 'block2_pool/MaxPool:0', 'block3_conv1/BiasAdd:0', 'block3_conv1/Conv2D/ReadVariableOp:0', 'block3_conv1/Conv2D:0', 'block3_conv1/Relu:0', 'block3_conv2/BiasAdd:0', 'block3_conv2/Conv2D/ReadVariableOp:0', 'block3_conv2/Conv2D:0', 'block3_conv2/Relu:0', 'block3_conv3/BiasAdd:0', 'block3_conv3/Conv2D/ReadVariableOp:0', 'block3_conv3/Conv2D:0', 'block3_conv3/Relu:0', 'block3_pool/MaxPool:0', 'block4_conv1/BiasAdd:0', 'block4_conv1/Conv2D/ReadVariableOp:0', 'block4_conv1/Conv2D:0', 'block4_conv1/Relu:0', 'block4_conv2/BiasAdd:0', 'block4_conv2/Conv2D/ReadVariableOp:0', 'block4_conv2/Conv2D:0', 'block4_conv2/Relu:0', 'block4_conv3/BiasAdd:0', 'block4_conv3/Conv2D/ReadVariableOp:0', 'block4_conv3/Conv2D:0', 'block4_conv3/Relu:0', 'block4_pool/MaxPool:0', 'block5_conv1/BiasAdd:0', 'block5_conv1/Conv2D/ReadVariableOp:0', 'block5_conv1/Conv2D:0', 'block5_conv1/Relu:0', 'block5_conv2/BiasAdd:0', 'block5_conv2/Conv2D/ReadVariableOp:0', 'block5_conv2/Conv2D:0', 'block5_conv2/Relu:0', 'block5_conv3/BiasAdd:0', 'block5_conv3/Conv2D/ReadVariableOp:0', 'block5_conv3/Conv2D:0', 'block5_conv3/Relu:0', 'block5_pool/MaxPool:0', 'fc1/BiasAdd/ReadVariableOp:0', 'fc1/BiasAdd:0', 'fc1/MatMul/ReadVariableOp:0', 'fc1/MatMul:0', 'fc1/Relu:0', 'fc2/BiasAdd/ReadVariableOp:0', 'fc2/BiasAdd:0', 'fc2/MatMul/ReadVariableOp:0', 'fc2/MatMul:0', 'fc2/Relu:0', 'flatten/Reshape:0', 'input_1:0', 'input_1:0', 'predictions/MatMul/ReadVariableOp:0']
DEBUG Rejected bottleneck candidate and ops ['block1_conv1/BiasAdd:0', 'block1_conv1/Conv2D/ReadVariableOp:0', 'block1_conv1/Conv2D:0', 'block1_conv1/Relu:0', 'block1_conv2/BiasAdd:0', 'block1_conv2/Conv2D/ReadVariableOp:0', 'block1_conv2/Conv2D:0', 'block1_conv2/Relu:0', 'block1_pool/MaxPool:0', 'block2_conv1/BiasAdd:0', 'block2_conv1/Conv2D/ReadVariableOp:0', 'block2_conv1/Conv2D:0', 'block2_conv2/Conv2D/ReadVariableOp:0', 'input_1:0']
DEBUG Number of checkpoints: 5:
DEBUG [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>]


DEBUG checkpoints_disconnected: {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>}
DEBUG Found 27 ops to copy within fwd_ops ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['loss/mul'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp']
DEBUG Processing list ['loss/mul:0']
DEBUG Copied_svg: SubGraphView (graphid=139916212100512):
** ops[27]:
  training/RMSprop/gradients/fc2/MatMul/ReadVariableOp
  training/RMSprop/gradients/fc2/MatMul
  training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/fc2/BiasAdd
  training/RMSprop/gradients/fc2/Relu
  training/RMSprop/gradients/predictions/MatMul/ReadVariableOp
  training/RMSprop/gradients/predictions/MatMul
  training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp
  training/RMSprop/gradients/predictions/BiasAdd
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights
  training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul
  training/RMSprop/gradients/loss/predictions_loss/Sum
  training/RMSprop/gradients/loss/predictions_loss/num_elements
  training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast
  training/RMSprop/gradients/loss/predictions_loss/Sum_1
  training/RMSprop/gradients/loss/predictions_loss/value
  training/RMSprop/gradients/loss/mul
** inputs: empty
** outputs[2]:
  training/RMSprop/gradients/loss/mul:0
  training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits:1

DEBUG Copied ['fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'] to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/fc2/BiasAdd', 'training/RMSprop/gradients/fc2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc2/MatMul', 'training/RMSprop/gradients/fc2/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc2/Relu', 'training/RMSprop/gradients/loss/mul', 'training/RMSprop/gradients/loss/predictions_loss/Sum', 'training/RMSprop/gradients/loss/predictions_loss/Sum_1', 'training/RMSprop/gradients/loss/predictions_loss/num_elements', 'training/RMSprop/gradients/loss/predictions_loss/num_elements/Cast', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'training/RMSprop/gradients/loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'training/RMSprop/gradients/loss/predictions_loss/value', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/Mul', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'training/RMSprop/gradients/loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'training/RMSprop/gradients/predictions/BiasAdd', 'training/RMSprop/gradients/predictions/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/predictions/MatMul', 'training/RMSprop/gradients/predictions/MatMul/ReadVariableOp']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul_1:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/predictions/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/loss/mul:0']
DEBUG with respect to boundary:[<tf.Tensor 'training/RMSprop/gradients/block5_conv2/Relu_sg:0' shape=(?, 14, 14, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block3_conv2/Relu_sg:0' shape=(?, 56, 56, 256) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/fc1/Relu_sg:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block4_conv2/Relu_sg:0' shape=(?, 28, 28, 512) dtype=float32>, <tf.Tensor 'training/RMSprop/gradients/block2_conv1/Relu_sg:0' shape=(?, 112, 112, 128) dtype=float32>], xs:[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(4096, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]
DEBUG Checkpoint gradients before loop {<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>: None, <tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>: None, <tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>: <tf.Tensor 'training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0' shape=(?, 4096) dtype=float32>, <tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>: None, <tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>: None}
DEBUG checkpoints_sorted_lists: [[<tf.Tensor 'block2_conv1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>], [<tf.Tensor 'block3_conv2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>], [<tf.Tensor 'block4_conv2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>], [<tf.Tensor 'block5_conv2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>], [<tf.Tensor 'fc1/Relu:0' shape=(?, 4096) dtype=float32>]]
DEBUG Processing list ['fc1/Relu:0']
DEBUG Found 15 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['fc1/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0']
DEBUG ops_to_copy = ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice']
DEBUG Copied ['block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice'] to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0'] restricted to ['training/RMSprop/gradients/block5_conv3/BiasAdd', 'training/RMSprop/gradients/block5_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Conv2D', 'training/RMSprop/gradients/block5_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv3/Relu', 'training/RMSprop/gradients/block5_pool/MaxPool', 'training/RMSprop/gradients/fc1/BiasAdd', 'training/RMSprop/gradients/fc1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/fc1/MatMul', 'training/RMSprop/gradients/fc1/MatMul/ReadVariableOp', 'training/RMSprop/gradients/fc1/Relu', 'training/RMSprop/gradients/flatten/Reshape', 'training/RMSprop/gradients/flatten/Reshape/shape', 'training/RMSprop/gradients/flatten/Shape', 'training/RMSprop/gradients/flatten/strided_slice']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/fc1/MatMul_grad/MatMul_1:0']
DEBUG for ['training/RMSprop/gradients/fc1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients/training/RMSprop/gradients/fc2/MatMul_grad/MatMul:0']
DEBUG Processing list ['block5_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block5_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu']
DEBUG Copied ['block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu'] to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block4_conv3/BiasAdd', 'training/RMSprop/gradients/block4_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Conv2D', 'training/RMSprop/gradients/block4_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv3/Relu', 'training/RMSprop/gradients/block4_pool/MaxPool', 'training/RMSprop/gradients/block5_conv1/BiasAdd', 'training/RMSprop/gradients/block5_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Conv2D', 'training/RMSprop/gradients/block5_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv1/Relu', 'training/RMSprop/gradients/block5_conv2/BiasAdd', 'training/RMSprop/gradients/block5_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Conv2D', 'training/RMSprop/gradients/block5_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block5_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block5_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block5_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_1/training/RMSprop/gradients/block5_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block4_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block4_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu']
DEBUG Copied ['block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu'] to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block3_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block3_conv3/BiasAdd', 'training/RMSprop/gradients/block3_conv3/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Conv2D', 'training/RMSprop/gradients/block3_conv3/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv3/Relu', 'training/RMSprop/gradients/block3_pool/MaxPool', 'training/RMSprop/gradients/block4_conv1/BiasAdd', 'training/RMSprop/gradients/block4_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Conv2D', 'training/RMSprop/gradients/block4_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv1/Relu', 'training/RMSprop/gradients/block4_conv2/BiasAdd', 'training/RMSprop/gradients/block4_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Conv2D', 'training/RMSprop/gradients/block4_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block4_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block4_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block4_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_2/training/RMSprop/gradients/block4_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block3_conv2/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block3_conv2/Relu'], stop_at ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu']
DEBUG Copied ['block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu'] to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block2_conv1/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block2_conv2/BiasAdd', 'training/RMSprop/gradients/block2_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Conv2D', 'training/RMSprop/gradients/block2_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv2/Relu', 'training/RMSprop/gradients/block2_pool/MaxPool', 'training/RMSprop/gradients/block3_conv1/BiasAdd', 'training/RMSprop/gradients/block3_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Conv2D', 'training/RMSprop/gradients/block3_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv1/Relu', 'training/RMSprop/gradients/block3_conv2/BiasAdd', 'training/RMSprop/gradients/block3_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Conv2D', 'training/RMSprop/gradients/block3_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block3_conv2/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block3_conv2/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block3_conv2/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block2_conv1/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_3/training/RMSprop/gradients/block3_conv3/Conv2D_grad/Conv2DBackpropInput:0']
DEBUG Processing list ['block2_conv1/Relu:0']
DEBUG Found 16 ops to copy within ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu', 'block2_conv2/BiasAdd', 'block2_conv2/BiasAdd/ReadVariableOp', 'block2_conv2/Conv2D', 'block2_conv2/Conv2D/ReadVariableOp', 'block2_conv2/Relu', 'block2_pool/MaxPool', 'block3_conv1/BiasAdd', 'block3_conv1/BiasAdd/ReadVariableOp', 'block3_conv1/Conv2D', 'block3_conv1/Conv2D/ReadVariableOp', 'block3_conv1/Relu', 'block3_conv2/BiasAdd', 'block3_conv2/BiasAdd/ReadVariableOp', 'block3_conv2/Conv2D', 'block3_conv2/Conv2D/ReadVariableOp', 'block3_conv2/Relu', 'block3_conv3/BiasAdd', 'block3_conv3/BiasAdd/ReadVariableOp', 'block3_conv3/Conv2D', 'block3_conv3/Conv2D/ReadVariableOp', 'block3_conv3/Relu', 'block3_pool/MaxPool', 'block4_conv1/BiasAdd', 'block4_conv1/BiasAdd/ReadVariableOp', 'block4_conv1/Conv2D', 'block4_conv1/Conv2D/ReadVariableOp', 'block4_conv1/Relu', 'block4_conv2/BiasAdd', 'block4_conv2/BiasAdd/ReadVariableOp', 'block4_conv2/Conv2D', 'block4_conv2/Conv2D/ReadVariableOp', 'block4_conv2/Relu', 'block4_conv3/BiasAdd', 'block4_conv3/BiasAdd/ReadVariableOp', 'block4_conv3/Conv2D', 'block4_conv3/Conv2D/ReadVariableOp', 'block4_conv3/Relu', 'block4_pool/MaxPool', 'block5_conv1/BiasAdd', 'block5_conv1/BiasAdd/ReadVariableOp', 'block5_conv1/Conv2D', 'block5_conv1/Conv2D/ReadVariableOp', 'block5_conv1/Relu', 'block5_conv2/BiasAdd', 'block5_conv2/BiasAdd/ReadVariableOp', 'block5_conv2/Conv2D', 'block5_conv2/Conv2D/ReadVariableOp', 'block5_conv2/Relu', 'block5_conv3/BiasAdd', 'block5_conv3/BiasAdd/ReadVariableOp', 'block5_conv3/Conv2D', 'block5_conv3/Conv2D/ReadVariableOp', 'block5_conv3/Relu', 'block5_pool/MaxPool', 'fc1/BiasAdd', 'fc1/BiasAdd/ReadVariableOp', 'fc1/MatMul', 'fc1/MatMul/ReadVariableOp', 'fc1/Relu', 'fc2/BiasAdd', 'fc2/BiasAdd/ReadVariableOp', 'fc2/MatMul', 'fc2/MatMul/ReadVariableOp', 'fc2/Relu', 'flatten/Reshape', 'flatten/Reshape/shape', 'flatten/Shape', 'flatten/strided_slice', 'loss/mul', 'loss/predictions_loss/Sum', 'loss/predictions_loss/Sum_1', 'loss/predictions_loss/num_elements', 'loss/predictions_loss/num_elements/Cast', 'loss/predictions_loss/softmax_cross_entropy_with_logits', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Reshape_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Shape_1', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice', 'loss/predictions_loss/softmax_cross_entropy_with_logits/Slice_2', 'loss/predictions_loss/softmax_cross_entropy_with_logits/concat', 'loss/predictions_loss/value', 'loss/predictions_loss/weighted_loss/Mul', 'loss/predictions_loss/weighted_loss/broadcast_weights', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like', 'loss/predictions_loss/weighted_loss/broadcast_weights/ones_like/Shape', 'predictions/BiasAdd', 'predictions/BiasAdd/ReadVariableOp', 'predictions/MatMul', 'predictions/MatMul/ReadVariableOp'], seed ['block2_conv1/Relu'], stop_at ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0']
DEBUG ops_to_copy = ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu']
DEBUG Copied ['block1_conv1/BiasAdd', 'block1_conv1/BiasAdd/ReadVariableOp', 'block1_conv1/Conv2D', 'block1_conv1/Conv2D/ReadVariableOp', 'block1_conv1/Relu', 'block1_conv2/BiasAdd', 'block1_conv2/BiasAdd/ReadVariableOp', 'block1_conv2/Conv2D', 'block1_conv2/Conv2D/ReadVariableOp', 'block1_conv2/Relu', 'block1_pool/MaxPool', 'block2_conv1/BiasAdd', 'block2_conv1/BiasAdd/ReadVariableOp', 'block2_conv1/Conv2D', 'block2_conv1/Conv2D/ReadVariableOp', 'block2_conv1/Relu'] to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Rewired ['training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0'] in place of ['block3_conv2/Relu:0', 'block4_conv2/Relu:0', 'block5_conv2/Relu:0', 'fc1/Relu:0'] restricted to ['training/RMSprop/gradients/block1_conv1/BiasAdd', 'training/RMSprop/gradients/block1_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Conv2D', 'training/RMSprop/gradients/block1_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv1/Relu', 'training/RMSprop/gradients/block1_conv2/BiasAdd', 'training/RMSprop/gradients/block1_conv2/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Conv2D', 'training/RMSprop/gradients/block1_conv2/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block1_conv2/Relu', 'training/RMSprop/gradients/block1_pool/MaxPool', 'training/RMSprop/gradients/block2_conv1/BiasAdd', 'training/RMSprop/gradients/block2_conv1/BiasAdd/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Conv2D', 'training/RMSprop/gradients/block2_conv1/Conv2D/ReadVariableOp', 'training/RMSprop/gradients/block2_conv1/Relu']
DEBUG Got gradients ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv1/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block1_conv2/Conv2D_grad/Conv2DBackpropFilter:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/BiasAdd_grad/BiasAddGrad:0', 'training/RMSprop/gradients/gradients_5/training/RMSprop/gradients/block2_conv1/Conv2D_grad/Conv2DBackpropFilter:0']
DEBUG for ['training/RMSprop/gradients/block2_conv1/Relu:0']
DEBUG with respect to ['block1_conv1/bias:0', 'block1_conv1/kernel:0', 'block1_conv2/bias:0', 'block1_conv2/kernel:0', 'block2_conv1/bias:0', 'block2_conv1/kernel:0', 'block2_conv2/bias:0', 'block2_conv2/kernel:0', 'block3_conv1/bias:0', 'block3_conv1/kernel:0', 'block3_conv2/bias:0', 'block3_conv2/kernel:0', 'block3_conv3/bias:0', 'block3_conv3/kernel:0', 'block4_conv1/bias:0', 'block4_conv1/kernel:0', 'block4_conv2/bias:0', 'block4_conv2/kernel:0', 'block4_conv3/bias:0', 'block4_conv3/kernel:0', 'block5_conv1/bias:0', 'block5_conv1/kernel:0', 'block5_conv2/bias:0', 'block5_conv2/kernel:0', 'block5_conv3/bias:0', 'block5_conv3/kernel:0', 'fc1/bias:0', 'fc1/kernel:0', 'fc2/bias:0', 'fc2/kernel:0', 'predictions/bias:0', 'predictions/kernel:0', 'training/RMSprop/gradients/block3_conv2/Relu_sg:0', 'training/RMSprop/gradients/block4_conv2/Relu_sg:0', 'training/RMSprop/gradients/block5_conv2/Relu_sg:0', 'training/RMSprop/gradients/fc1/Relu_sg:0']
DEBUG with boundary backprop substitutions ['training/RMSprop/gradients/gradients_4/training/RMSprop/gradients/block2_conv2/Conv2D_grad/Conv2DBackpropInput:0']
  1/160 [..............................] - ETA: 1:20:05 - loss: 2.3468 - acc: 0.0600  2/160 [..............................] - ETA: 43:08 - loss: 6038924.6734 - acc: 0.0720  3/160 [..............................] - ETA: 30:39 - loss: 4026063.2594 - acc: 0.0773  4/160 [..............................] - ETA: 24:38 - loss: 3019617.6934 - acc: 0.0840  5/160 [..............................] - ETA: 21:12 - loss: 2415703.6755 - acc: 0.0880  6/160 [>.............................] - ETA: 18:45 - loss: 2013205.0906 - acc: 0.0867  7/160 [>.............................] - ETA: 17:02 - loss: 1725604.7177 - acc: 0.0857  8/160 [>.............................] - ETA: 15:43 - loss: 1509904.4530 - acc: 0.0850  9/160 [>.............................] - ETA: 14:41 - loss: 1342137.5714 - acc: 0.0898 10/160 [>.............................] - ETA: 13:51 - loss: 1207924.0522 - acc: 0.0904 11/160 [=>............................] - ETA: 13:09 - loss: 1098112.9847 - acc: 0.0938 12/160 [=>............................] - ETA: 12:39 - loss: 1006603.7613 - acc: 0.0937 13/160 [=>............................] - ETA: 12:13 - loss: 929172.8798 - acc: 0.0935  14/160 [=>............................] - ETA: 11:50 - loss: 862803.5531 - acc: 0.0974 15/160 [=>............................] - ETA: 11:29 - loss: 805283.4700 - acc: 0.0992 16/160 [==>...........................] - ETA: 11:10 - loss: 754953.3973 - acc: 0.0978 17/160 [==>...........................] - ETA: 10:54 - loss: 710544.5093 - acc: 0.0974 18/160 [==>...........................] - ETA: 10:42 - loss: 671069.9437 - acc: 0.0969 19/160 [==>...........................] - ETA: 10:31 - loss: 635750.5941 - acc: 0.0975 20/160 [==>...........................] - ETA: 10:20 - loss: 603963.1792 - acc: 0.0976 21/160 [==>...........................] - ETA: 10:10 - loss: 575203.1371 - acc: 0.0994 22/160 [===>..........................] - ETA: 10:00 - loss: 549057.6443 - acc: 0.1011 23/160 [===>..........................] - ETA: 9:47 - loss: 525185.6724 - acc: 0.1028  24/160 [===>..........................] - ETA: 9:37 - loss: 503303.0321 - acc: 0.1018 25/160 [===>..........................] - ETA: 9:31 - loss: 483171.0028 - acc: 0.1013 26/160 [===>..........................] - ETA: 9:24 - loss: 464587.5906 - acc: 0.1031 27/160 [====>.........................] - ETA: 9:18 - loss: 447380.7271 - acc: 0.1028 28/160 [====>.........................] - ETA: 9:12 - loss: 431402.9263 - acc: 0.1030 29/160 [====>.........................] - ETA: 9:06 - loss: 416527.0428 - acc: 0.1033 30/160 [====>.........................] - ETA: 9:00 - loss: 402642.8846 - acc: 0.1035 31/160 [====>.........................] - ETA: 8:54 - loss: 389654.4787 - acc: 0.1028 32/160 [=====>........................] - ETA: 8:48 - loss: 377477.8475 - acc: 0.1060 33/160 [=====>........................] - ETA: 8:43 - loss: 366039.1951 - acc: 0.1062 34/160 [=====>........................] - ETA: 8:37 - loss: 355273.4042 - acc: 0.1052 35/160 [=====>........................] - ETA: 8:32 - loss: 345122.8013 - acc: 0.1051 36/160 [=====>........................] - ETA: 8:27 - loss: 335536.1669 - acc: 0.1043 37/160 [=====>........................] - ETA: 8:21 - loss: 326467.6841 - acc: 0.1039 38/160 [======>.......................] - ETA: 8:16 - loss: 317876.4897 - acc: 0.1038 39/160 [======>.......................] - ETA: 8:11 - loss: 309725.8701 - acc: 0.1033 40/160 [======>.......................] - ETA: 8:06 - loss: 301982.7810 - acc: 0.1037 41/160 [======>.......................] - ETA: 8:01 - loss: 294617.4034 - acc: 0.1040 42/160 [======>.......................] - ETA: 7:56 - loss: 287602.7583 - acc: 0.1032 43/160 [=======>......................] - ETA: 7:51 - loss: 280914.3756 - acc: 0.1037 44/160 [=======>......................] - ETA: 7:46 - loss: 274530.0104 - acc: 0.1038 45/160 [=======>......................] - ETA: 7:42 - loss: 268429.3947 - acc: 0.1029 46/160 [=======>......................] - ETA: 7:37 - loss: 262594.0231 - acc: 0.1035 47/160 [=======>......................] - ETA: 7:32 - loss: 257006.9651 - acc: 0.1030 48/160 [========>.....................] - ETA: 7:28 - loss: 251652.7011 - acc: 0.1034 49/160 [========>.....................] - ETA: 7:23 - loss: 246516.9837 - acc: 0.1033 50/160 [========>.....................] - ETA: 7:19 - loss: 241586.6900 - acc: 0.1038 51/160 [========>.....................] - ETA: 7:14 - loss: 236849.7411 - acc: 0.1038 52/160 [========>.....................] - ETA: 7:10 - loss: 232294.9825 - acc: 0.1041 53/160 [========>.....................] - ETA: 7:05 - loss: 227912.1023 - acc: 0.1038 54/160 [=========>....................] - ETA: 7:01 - loss: 223691.5504 - acc: 0.1041 55/160 [=========>....................] - ETA: 6:56 - loss: 219624.4738 - acc: 0.1037 56/160 [=========>....................] - ETA: 6:52 - loss: 215702.6493 - acc: 0.1039 57/160 [=========>....................] - ETA: 6:48 - loss: 211918.4326 - acc: 0.1040 58/160 [=========>....................] - ETA: 6:43 - loss: 208264.7060 - acc: 0.1045 59/160 [==========>...................] - ETA: 6:39 - loss: 204734.8386 - acc: 0.1047 60/160 [==========>...................] - ETA: 6:35 - loss: 201322.6299 - acc: 0.1042 61/160 [==========>...................] - ETA: 6:31 - loss: 198022.2968 - acc: 0.1039 62/160 [==========>...................] - ETA: 6:26 - loss: 194828.4259 - acc: 0.1038 63/160 [==========>...................] - ETA: 6:22 - loss: 191735.9478 - acc: 0.1042 64/160 [===========>..................] - ETA: 6:18 - loss: 188740.1096 - acc: 0.1042 65/160 [===========>..................] - ETA: 6:14 - loss: 185836.4510 - acc: 0.1044 66/160 [===========>..................] - ETA: 6:09 - loss: 183020.7820 - acc: 0.1045 67/160 [===========>..................] - ETA: 6:06 - loss: 180289.1627 - acc: 0.1052 68/160 [===========>..................] - ETA: 6:02 - loss: 177637.8844 - acc: 0.1055 69/160 [===========>..................] - ETA: 5:58 - loss: 175063.4592 - acc: 0.1059 70/160 [============>.................] - ETA: 5:54 - loss: 172562.5867 - acc: 0.1056 71/160 [============>.................] - ETA: 5:50 - loss: 170132.1705 - acc: 0.1053 72/160 [============>.................] - ETA: 5:46 - loss: 167769.2557 - acc: 0.1051 73/160 [============>.................] - ETA: 5:42 - loss: 165471.0783 - acc: 0.1053 74/160 [============>.................] - ETA: 5:38 - loss: 163235.0137 - acc: 0.1051 75/160 [=============>................] - ETA: 5:34 - loss: 161058.5778 - acc: 0.1050 76/160 [=============>................] - ETA: 5:30 - loss: 158939.4162 - acc: 0.1048 77/160 [=============>................] - ETA: 5:26 - loss: 156875.2974 - acc: 0.1051 78/160 [=============>................] - ETA: 5:22 - loss: 154864.1227 - acc: 0.1049 79/160 [=============>................] - ETA: 5:18 - loss: 152903.8466 - acc: 0.1047 80/160 [==============>...............] - ETA: 5:15 - loss: 150992.5773 - acc: 0.1049 81/160 [==============>...............] - ETA: 5:10 - loss: 149128.4998 - acc: 0.1048 82/160 [==============>...............] - ETA: 5:06 - loss: 147309.8876 - acc: 0.1047 83/160 [==============>...............] - ETA: 5:01 - loss: 145535.0974 - acc: 0.1049 84/160 [==============>...............] - ETA: 4:57 - loss: 143802.5642 - acc: 0.1050 85/160 [==============>...............] - ETA: 4:55 - loss: 142110.7964 - acc: 0.1046 86/160 [===============>..............] - ETA: 4:50 - loss: 140458.3720 - acc: 0.1044 87/160 [===============>..............] - ETA: 4:46 - loss: 138843.9344 - acc: 0.1048 88/160 [===============>..............] - ETA: 4:42 - loss: 137266.1885 - acc: 0.1049 89/160 [===============>..............] - ETA: 4:39 - loss: 135723.8977 - acc: 0.1050 90/160 [===============>..............] - ETA: 4:35 - loss: 134215.8798 - acc: 0.1056 91/160 [================>.............] - ETA: 4:31 - loss: 132741.0051 - acc: 0.1058 92/160 [================>.............] - ETA: 4:27 - loss: 131298.1931 - acc: 0.1061 93/160 [================>.............] - ETA: 4:23 - loss: 129886.4096 - acc: 0.1057 94/160 [================>.............] - ETA: 4:19 - loss: 128504.6638 - acc: 0.1056 95/160 [================>.............] - ETA: 4:15 - loss: 127152.0074 - acc: 0.1050 96/160 [=================>............] - ETA: 4:11 - loss: 125827.5383 - acc: 0.1047 97/160 [=================>............] - ETA: 4:07 - loss: 124530.3709 - acc: 0.1047 98/160 [=================>............] - ETA: 4:02 - loss: 123259.6763 - acc: 0.1046 99/160 [=================>............] - ETA: 3:58 - loss: 122014.6523 - acc: 0.1048100/160 [=================>............] - ETA: 3:54 - loss: 120794.5288 - acc: 0.1046101/160 [=================>............] - ETA: 3:51 - loss: 119598.5662 - acc: 0.1043102/160 [==================>...........] - ETA: 3:47 - loss: 118426.0539 - acc: 0.1045103/160 [==================>...........] - ETA: 3:43 - loss: 117276.3088 - acc: 0.1043104/160 [==================>...........] - ETA: 3:39 - loss: 116148.6741 - acc: 0.1043105/160 [==================>...........] - ETA: 3:34 - loss: 115042.5181 - acc: 0.1045106/160 [==================>...........] - ETA: 3:30 - loss: 113957.2336 - acc: 0.1046107/160 [===================>..........] - ETA: 3:26 - loss: 112892.2342 - acc: 0.1044108/160 [===================>..........] - ETA: 3:22 - loss: 111846.9570 - acc: 0.1047109/160 [===================>..........] - ETA: 3:18 - loss: 110820.8606 - acc: 0.1048110/160 [===================>..........] - ETA: 3:14 - loss: 109813.4228 - acc: 0.1049111/160 [===================>..........] - ETA: 3:10 - loss: 108824.1334 - acc: 0.1048112/160 [====================>.........] - ETA: 3:06 - loss: 107852.5100 - acc: 0.1046113/160 [====================>.........] - ETA: 3:02 - loss: 106898.0833 - acc: 0.1048114/160 [====================>.........] - ETA: 2:58 - loss: 105960.4010 - acc: 0.1052115/160 [====================>.........] - ETA: 2:55 - loss: 105039.0263 - acc: 0.1050116/160 [====================>.........] - ETA: 2:51 - loss: 104133.5433 - acc: 0.1048117/160 [====================>.........] - ETA: 2:47 - loss: 103243.5327 - acc: 0.1046118/160 [=====================>........] - ETA: 2:43 - loss: 102368.6070 - acc: 0.1051119/160 [=====================>........] - ETA: 2:39 - loss: 101508.3970 - acc: 0.1051120/160 [=====================>........] - ETA: 2:35 - loss: 100662.5129 - acc: 0.1052121/160 [=====================>........] - ETA: 2:31 - loss: 99830.6103 - acc: 0.1047 122/160 [=====================>........] - ETA: 2:27 - loss: 99012.3455 - acc: 0.1047123/160 [======================>.......] - ETA: 2:23 - loss: 98207.3858 - acc: 0.1049124/160 [======================>.......] - ETA: 2:20 - loss: 97415.4093 - acc: 0.1048125/160 [======================>.......] - ETA: 2:16 - loss: 96636.1043 - acc: 0.1053126/160 [======================>.......] - ETA: 2:12 - loss: 95869.1693 - acc: 0.1056127/160 [======================>.......] - ETA: 2:08 - loss: 95114.3426 - acc: 0.1055128/160 [=======================>......] - ETA: 2:04 - loss: 94371.2798 - acc: 0.1055129/160 [=======================>......] - ETA: 2:00 - loss: 93639.7374 - acc: 0.1053130/160 [=======================>......] - ETA: 1:56 - loss: 92919.4494 - acc: 0.1054131/160 [=======================>......] - ETA: 1:52 - loss: 92210.1582 - acc: 0.1053132/160 [=======================>......] - ETA: 1:48 - loss: 91511.6138 - acc: 0.1055133/160 [=======================>......] - ETA: 1:44 - loss: 90823.5825 - acc: 0.1052134/160 [========================>.....] - ETA: 1:40 - loss: 90145.8117 - acc: 0.1057135/160 [========================>.....] - ETA: 1:36 - loss: 89478.0859 - acc: 0.1057136/160 [========================>.....] - ETA: 1:32 - loss: 88820.1758 - acc: 0.1059137/160 [========================>.....] - ETA: 1:29 - loss: 88171.8701 - acc: 0.1058138/160 [========================>.....] - ETA: 1:25 - loss: 87532.9602 - acc: 0.1057139/160 [=========================>....] - ETA: 1:21 - loss: 86903.2433 - acc: 0.1056140/160 [=========================>....] - ETA: 1:17 - loss: 86282.5222 - acc: 0.1057141/160 [=========================>....] - ETA: 1:13 - loss: 85670.6058 - acc: 0.1058142/160 [=========================>....] - ETA: 1:10 - loss: 85067.3079 - acc: 0.1056143/160 [=========================>....] - ETA: 1:06 - loss: 84472.4477 - acc: 0.1057144/160 [==========================>...] - ETA: 1:02 - loss: 83885.8495 - acc: 0.1057145/160 [==========================>...] - ETA: 58s - loss: 83307.3423 - acc: 0.1057 146/160 [==========================>...] - ETA: 54s - loss: 82736.7598 - acc: 0.1058147/160 [==========================>...] - ETA: 50s - loss: 82173.9404 - acc: 0.1057148/160 [==========================>...] - ETA: 46s - loss: 81618.7266 - acc: 0.1061149/160 [==========================>...] - ETA: 42s - loss: 81070.9650 - acc: 0.1063150/160 [===========================>..] - ETA: 38s - loss: 80530.5493 - acc: 0.1064151/160 [===========================>..] - ETA: 34s - loss: 79997.2554 - acc: 0.1062152/160 [===========================>..] - ETA: 31s - loss: 79470.9728 - acc: 0.1062153/160 [===========================>..] - ETA: 27s - loss: 78951.5697 - acc: 0.1062154/160 [===========================>..] - ETA: 23s - loss: 78438.9122 - acc: 0.1060155/160 [============================>.] - ETA: 19s - loss: 77932.8695 - acc: 0.1059156/160 [============================>.] - ETA: 15s - loss: 77433.3146 - acc: 0.1058157/160 [============================>.] - ETA: 11s - loss: 76940.1235 - acc: 0.1060158/160 [============================>.] - ETA: 7s - loss: 76453.1752 - acc: 0.1059 159/160 [============================>.] - ETA: 3s - loss: 75972.3522 - acc: 0.1059  1/160 [..............................] - ETA: 3:51 - loss: 2.3042 - acc: 0.0760  2/160 [..............................] - ETA: 3:19 - loss: 2.3034 - acc: 0.0800  3/160 [..............................] - ETA: 3:08 - loss: 2.3022 - acc: 0.0893  4/160 [..............................] - ETA: 3:03 - loss: 2.3023 - acc: 0.0900  5/160 [..............................] - ETA: 2:54 - loss: 2.3028 - acc: 0.0864  6/160 [>.............................] - ETA: 2:48 - loss: 2.3025 - acc: 0.0913  7/160 [>.............................] - ETA: 2:43 - loss: 2.3022 - acc: 0.0994  8/160 [>.............................] - ETA: 2:40 - loss: 2.3022 - acc: 0.0990  9/160 [>.............................] - ETA: 2:36 - loss: 2.3020 - acc: 0.0978 10/160 [>.............................] - ETA: 2:34 - loss: 2.3021 - acc: 0.0956 11/160 [=>............................] - ETA: 2:32 - loss: 2.3020 - acc: 0.0985 12/160 [=>............................] - ETA: 2:31 - loss: 2.3018 - acc: 0.0997 13/160 [=>............................] - ETA: 2:29 - loss: 2.3019 - acc: 0.0985 14/160 [=>............................] - ETA: 2:27 - loss: 2.3017 - acc: 0.1000 15/160 [=>............................] - ETA: 2:25 - loss: 2.3015 - acc: 0.1011 16/160 [==>...........................] - ETA: 2:23 - loss: 2.3015 - acc: 0.1000 17/160 [==>...........................] - ETA: 2:22 - loss: 2.3015 - acc: 0.1019 18/160 [==>...........................] - ETA: 2:20 - loss: 2.3017 - acc: 0.1013 19/160 [==>...........................] - ETA: 2:19 - loss: 2.3015 - acc: 0.1032 20/160 [==>...........................] - ETA: 2:17 - loss: 2.3014 - acc: 0.1014 21/160 [==>...........................] - ETA: 2:16 - loss: 2.3014 - acc: 0.1017 22/160 [===>..........................] - ETA: 2:15 - loss: 2.3013 - acc: 0.1018 23/160 [===>..........................] - ETA: 2:13 - loss: 2.3013 - acc: 0.1019 24/160 [===>..........................] - ETA: 2:11 - loss: 2.3012 - acc: 0.1040 25/160 [===>..........................] - ETA: 2:10 - loss: 2.3012 - acc: 0.1038 26/160 [===>..........................] - ETA: 2:07 - loss: 2.3013 - acc: 0.1037 27/160 [====>.........................] - ETA: 2:06 - loss: 2.3013 - acc: 0.1036 28/160 [====>.........................] - ETA: 2:05 - loss: 2.3014 - acc: 0.1031 29/160 [====>.........................] - ETA: 2:04 - loss: 2.3013 - acc: 0.1034 30/160 [====>.........................] - ETA: 2:02 - loss: 2.3013 - acc: 0.1041 31/160 [====>.........................] - ETA: 2:01 - loss: 2.3013 - acc: 0.1031 32/160 [=====>........................] - ETA: 2:00 - loss: 2.3013 - acc: 0.1020 33/160 [=====>........................] - ETA: 1:58 - loss: 2.3015 - acc: 0.1015 34/160 [=====>........................] - ETA: 1:57 - loss: 2.3015 - acc: 0.1013 35/160 [=====>........................] - ETA: 1:56 - loss: 2.3015 - acc: 0.1008 36/160 [=====>........................] - ETA: 1:55 - loss: 2.3015 - acc: 0.1010 37/160 [=====>........................] - ETA: 1:54 - loss: 2.3016 - acc: 0.1008 38/160 [======>.......................] - ETA: 1:53 - loss: 2.3016 - acc: 0.0999 39/160 [======>.......................] - ETA: 1:53 - loss: 2.3015 - acc: 0.1001 40/160 [======>.......................] - ETA: 1:52 - loss: 2.3016 - acc: 0.1000160/160 [==============================] - 659s 4s/step - loss: 75497.5394 - acc: 0.1058 - val_loss: 2.3016 - val_acc: 0.1000
